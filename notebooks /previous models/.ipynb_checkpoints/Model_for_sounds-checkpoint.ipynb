{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozqsc-u2GaWM",
    "outputId": "bd6a21f1-4702-41e4-b480-c39859f7b764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WczrEMtAy5Dm",
    "outputId": "0bc6e5c7-f1bc-4ea2-bb97-8e1d959d41bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 3s 276ms/step - loss: 1.3853 - accuracy: 0.2605 - val_loss: 1.4031 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 1.3804 - accuracy: 0.2857 - val_loss: 1.4218 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 1.3760 - accuracy: 0.2605 - val_loss: 1.4339 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 1.3686 - accuracy: 0.2773 - val_loss: 1.4740 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 1.3684 - accuracy: 0.2773 - val_loss: 1.5728 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 1.3623 - accuracy: 0.2941 - val_loss: 1.4750 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 1.3556 - accuracy: 0.3193 - val_loss: 1.4655 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 1.3448 - accuracy: 0.3109 - val_loss: 1.4986 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.3216 - accuracy: 0.3025 - val_loss: 1.5498 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2766 - accuracy: 0.4370 - val_loss: 1.5308 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.2210 - accuracy: 0.4454 - val_loss: 2.0589 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1846 - accuracy: 0.4622 - val_loss: 1.6594 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.1845 - accuracy: 0.4454 - val_loss: 1.5324 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1183 - accuracy: 0.4706 - val_loss: 1.9605 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.0871 - accuracy: 0.4874 - val_loss: 1.7420 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.0709 - accuracy: 0.5042 - val_loss: 1.6427 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0375 - accuracy: 0.5210 - val_loss: 1.7781 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.0185 - accuracy: 0.5126 - val_loss: 1.8767 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0341 - accuracy: 0.4958 - val_loss: 2.2917 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0138 - accuracy: 0.5294 - val_loss: 1.5962 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1622 - accuracy: 0.5546 - val_loss: 1.5863 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.9867 - accuracy: 0.5378 - val_loss: 2.1495 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.0328 - accuracy: 0.4958 - val_loss: 2.2166 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1080 - accuracy: 0.4790 - val_loss: 2.8165 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0661 - accuracy: 0.5042 - val_loss: 2.1401 - val_accuracy: 0.2857\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.9705 - accuracy: 0.5630 - val_loss: 1.5650 - val_accuracy: 0.4286\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0456 - accuracy: 0.4538 - val_loss: 1.5799 - val_accuracy: 0.4286\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.9451 - accuracy: 0.6387 - val_loss: 1.7417 - val_accuracy: 0.4286\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.9105 - accuracy: 0.6555 - val_loss: 2.0259 - val_accuracy: 0.4286\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.8907 - accuracy: 0.6471 - val_loss: 1.9873 - val_accuracy: 0.3571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8678 - accuracy: 0.6387 - val_loss: 2.0969 - val_accuracy: 0.3571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8264 - accuracy: 0.6723 - val_loss: 2.1420 - val_accuracy: 0.3571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.8081 - accuracy: 0.6975 - val_loss: 2.1857 - val_accuracy: 0.4286\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7851 - accuracy: 0.7143 - val_loss: 2.3962 - val_accuracy: 0.3571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7750 - accuracy: 0.7143 - val_loss: 2.3550 - val_accuracy: 0.3571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7442 - accuracy: 0.7647 - val_loss: 2.2575 - val_accuracy: 0.4286\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7406 - accuracy: 0.7647 - val_loss: 2.4556 - val_accuracy: 0.2857\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6697 - accuracy: 0.8067 - val_loss: 2.4286 - val_accuracy: 0.3571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6569 - accuracy: 0.7983 - val_loss: 2.1182 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.6171 - accuracy: 0.8151 - val_loss: 2.1269 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.5754 - accuracy: 0.8403 - val_loss: 2.2291 - val_accuracy: 0.4286\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.5455 - accuracy: 0.8487 - val_loss: 2.4704 - val_accuracy: 0.4286\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.5149 - accuracy: 0.8571 - val_loss: 2.6238 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.5955 - accuracy: 0.7983 - val_loss: 3.3319 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.6859 - accuracy: 0.7815 - val_loss: 2.5012 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6906 - accuracy: 0.7395 - val_loss: 3.8012 - val_accuracy: 0.2857\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.6858 - accuracy: 0.7479 - val_loss: 3.5989 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.6915 - accuracy: 0.7731 - val_loss: 2.6977 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.7174 - accuracy: 0.7563 - val_loss: 3.1598 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6222 - accuracy: 0.7647 - val_loss: 3.3393 - val_accuracy: 0.3571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7062 - accuracy: 0.7227 - val_loss: 3.3409 - val_accuracy: 0.2857\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7161 - accuracy: 0.7563 - val_loss: 2.3949 - val_accuracy: 0.3571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7356 - accuracy: 0.7563 - val_loss: 2.5658 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.7520 - accuracy: 0.7563 - val_loss: 2.2033 - val_accuracy: 0.2857\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7432 - accuracy: 0.7563 - val_loss: 2.0609 - val_accuracy: 0.4286\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.6346 - accuracy: 0.7983 - val_loss: 2.2974 - val_accuracy: 0.4286\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.6569 - accuracy: 0.7899 - val_loss: 2.2889 - val_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5493 - accuracy: 0.8403 - val_loss: 3.0034 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.5404 - accuracy: 0.8403 - val_loss: 3.7175 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6823 - accuracy: 0.7983 - val_loss: 3.1669 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5718 - accuracy: 0.8403 - val_loss: 2.5158 - val_accuracy: 0.2857\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6216 - accuracy: 0.8151 - val_loss: 2.5147 - val_accuracy: 0.2857\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5423 - accuracy: 0.8403 - val_loss: 2.3700 - val_accuracy: 0.3571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5439 - accuracy: 0.8403 - val_loss: 3.3972 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.6717 - accuracy: 0.7647 - val_loss: 4.1093 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7823 - accuracy: 0.7395 - val_loss: 4.0644 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.9755 - accuracy: 0.7059 - val_loss: 3.9348 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.9059 - accuracy: 0.7143 - val_loss: 3.9697 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0174 - accuracy: 0.6723 - val_loss: 3.7864 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9586 - accuracy: 0.6723 - val_loss: 3.5864 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9426 - accuracy: 0.6807 - val_loss: 3.4394 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.8960 - accuracy: 0.6891 - val_loss: 3.2194 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8403 - accuracy: 0.6975 - val_loss: 3.0225 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8282 - accuracy: 0.6975 - val_loss: 2.8555 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.8206 - accuracy: 0.6975 - val_loss: 2.7325 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8206 - accuracy: 0.6975 - val_loss: 2.6351 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8177 - accuracy: 0.6975 - val_loss: 2.5746 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8052 - accuracy: 0.7059 - val_loss: 2.5108 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.8028 - accuracy: 0.7059 - val_loss: 2.4901 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.8408 - accuracy: 0.6723 - val_loss: 2.6131 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.1880 - accuracy: 0.5210 - val_loss: 2.0889 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.4899 - accuracy: 0.3613 - val_loss: 1.8700 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.4049 - accuracy: 0.3445 - val_loss: 1.5886 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.3136 - accuracy: 0.3445 - val_loss: 1.4416 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 1.2949 - accuracy: 0.3361 - val_loss: 1.4005 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 1.2931 - accuracy: 0.3277 - val_loss: 1.4422 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 1.2992 - accuracy: 0.3025 - val_loss: 1.4916 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.2978 - accuracy: 0.3109 - val_loss: 1.5021 - val_accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 1.2894 - accuracy: 0.3613 - val_loss: 1.5076 - val_accuracy: 0.2143\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 1.2803 - accuracy: 0.3445 - val_loss: 1.5037 - val_accuracy: 0.2143\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 1.2765 - accuracy: 0.3445 - val_loss: 1.4878 - val_accuracy: 0.2143\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.2599 - accuracy: 0.3529 - val_loss: 1.4674 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2608 - accuracy: 0.3193 - val_loss: 1.4637 - val_accuracy: 0.2143\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2597 - accuracy: 0.3529 - val_loss: 1.5031 - val_accuracy: 0.2143\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.2576 - accuracy: 0.3529 - val_loss: 1.7147 - val_accuracy: 0.2143\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2580 - accuracy: 0.3529 - val_loss: 1.7465 - val_accuracy: 0.2143\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2579 - accuracy: 0.3529 - val_loss: 1.7328 - val_accuracy: 0.2143\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.2404 - accuracy: 0.3613 - val_loss: 1.7251 - val_accuracy: 0.2143\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2323 - accuracy: 0.3782 - val_loss: 1.7366 - val_accuracy: 0.2143\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2060 - accuracy: 0.3445 - val_loss: 1.8221 - val_accuracy: 0.1429\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6490 - accuracy: 0.2353\n",
      "Test accuracy: 23.53%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Conv1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import librosa\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "data_dir = '/content/drive/MyDrive/New folder/T5/sounds final'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(40,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCviXBZo_Nqy",
    "outputId": "bdcaba61-a009-4ff9-a5ad-e8907b418271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128, 256)          33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128, 256)          0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128, 192)          49344     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128, 192)          0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128, 128)          24704     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128, 64)           8256      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128, 32)           2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128, 16)           528       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128, 8)            136       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                18688     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137020 (535.23 KB)\n",
      "Trainable params: 137020 (535.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 16.8317%\n",
      "Epoch 1/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3858 - accuracy: 0.2900\n",
      "Epoch 1: val_loss improved from inf to 1.38822, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 1.3858 - accuracy: 0.2900 - val_loss: 1.3882 - val_accuracy: 0.1584\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3848 - accuracy: 0.2900\n",
      "Epoch 2: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3848 - accuracy: 0.2900 - val_loss: 1.3908 - val_accuracy: 0.1584\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3830 - accuracy: 0.2900\n",
      "Epoch 3: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.3830 - accuracy: 0.2900 - val_loss: 1.3951 - val_accuracy: 0.1584\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3817 - accuracy: 0.2900\n",
      "Epoch 4: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3817 - accuracy: 0.2900 - val_loss: 1.4021 - val_accuracy: 0.1584\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3810 - accuracy: 0.2900\n",
      "Epoch 5: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3810 - accuracy: 0.2900 - val_loss: 1.4112 - val_accuracy: 0.1584\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3802 - accuracy: 0.2900\n",
      "Epoch 6: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3802 - accuracy: 0.2900 - val_loss: 1.4109 - val_accuracy: 0.1584\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3778 - accuracy: 0.2900\n",
      "Epoch 7: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3778 - accuracy: 0.2900 - val_loss: 1.4090 - val_accuracy: 0.1584\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3759 - accuracy: 0.2900\n",
      "Epoch 8: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3759 - accuracy: 0.2900 - val_loss: 1.4061 - val_accuracy: 0.1584\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3718 - accuracy: 0.2900\n",
      "Epoch 9: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3718 - accuracy: 0.2900 - val_loss: 1.4154 - val_accuracy: 0.1584\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3645 - accuracy: 0.2900\n",
      "Epoch 10: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.3645 - accuracy: 0.2900 - val_loss: 1.4167 - val_accuracy: 0.1584\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3589 - accuracy: 0.2900\n",
      "Epoch 11: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.3589 - accuracy: 0.2900 - val_loss: 1.4133 - val_accuracy: 0.1584\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3522 - accuracy: 0.2900\n",
      "Epoch 12: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3522 - accuracy: 0.2900 - val_loss: 1.4115 - val_accuracy: 0.1584\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3437 - accuracy: 0.2875\n",
      "Epoch 13: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.3437 - accuracy: 0.2875 - val_loss: 1.4041 - val_accuracy: 0.2079\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3334 - accuracy: 0.3025\n",
      "Epoch 14: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.3334 - accuracy: 0.3025 - val_loss: 1.4145 - val_accuracy: 0.2178\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3220 - accuracy: 0.3125\n",
      "Epoch 15: val_loss did not improve from 1.38822\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3220 - accuracy: 0.3125 - val_loss: 1.3903 - val_accuracy: 0.2178\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3213 - accuracy: 0.3125\n",
      "Epoch 16: val_loss improved from 1.38822 to 1.38279, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.3213 - accuracy: 0.3125 - val_loss: 1.3828 - val_accuracy: 0.2277\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3022 - accuracy: 0.3225\n",
      "Epoch 17: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3022 - accuracy: 0.3225 - val_loss: 1.4762 - val_accuracy: 0.2277\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3105 - accuracy: 0.3300\n",
      "Epoch 18: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.3105 - accuracy: 0.3300 - val_loss: 1.3955 - val_accuracy: 0.2475\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2769 - accuracy: 0.3350\n",
      "Epoch 19: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.2769 - accuracy: 0.3350 - val_loss: 1.3949 - val_accuracy: 0.2574\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2662 - accuracy: 0.3450\n",
      "Epoch 20: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.2662 - accuracy: 0.3450 - val_loss: 1.4564 - val_accuracy: 0.2673\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2485 - accuracy: 0.3400\n",
      "Epoch 21: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.2485 - accuracy: 0.3400 - val_loss: 1.4325 - val_accuracy: 0.2772\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.3550\n",
      "Epoch 22: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.2383 - accuracy: 0.3550 - val_loss: 1.4126 - val_accuracy: 0.2970\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2303 - accuracy: 0.3650\n",
      "Epoch 23: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.2303 - accuracy: 0.3650 - val_loss: 1.5005 - val_accuracy: 0.2574\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2227 - accuracy: 0.3750\n",
      "Epoch 24: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.2227 - accuracy: 0.3750 - val_loss: 1.4157 - val_accuracy: 0.2772\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2223 - accuracy: 0.3425\n",
      "Epoch 25: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.2223 - accuracy: 0.3425 - val_loss: 1.4368 - val_accuracy: 0.3168\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2020 - accuracy: 0.3750\n",
      "Epoch 26: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.2020 - accuracy: 0.3750 - val_loss: 1.4535 - val_accuracy: 0.2871\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1925 - accuracy: 0.3850\n",
      "Epoch 27: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.1925 - accuracy: 0.3850 - val_loss: 1.4284 - val_accuracy: 0.3267\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1746 - accuracy: 0.4075\n",
      "Epoch 28: val_loss did not improve from 1.38279\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.1746 - accuracy: 0.4075 - val_loss: 1.5316 - val_accuracy: 0.3564\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1980 - accuracy: 0.3775\n",
      "Epoch 29: val_loss improved from 1.38279 to 1.37010, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.1980 - accuracy: 0.3775 - val_loss: 1.3701 - val_accuracy: 0.3762\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.3825\n",
      "Epoch 30: val_loss did not improve from 1.37010\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.2017 - accuracy: 0.3825 - val_loss: 1.4275 - val_accuracy: 0.3762\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1807 - accuracy: 0.3875\n",
      "Epoch 31: val_loss did not improve from 1.37010\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 1.1807 - accuracy: 0.3875 - val_loss: 1.4655 - val_accuracy: 0.3762\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1665 - accuracy: 0.4075\n",
      "Epoch 32: val_loss improved from 1.37010 to 1.36799, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.1665 - accuracy: 0.4075 - val_loss: 1.3680 - val_accuracy: 0.3861\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1748 - accuracy: 0.4050\n",
      "Epoch 33: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.1748 - accuracy: 0.4050 - val_loss: 1.4192 - val_accuracy: 0.3960\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1458 - accuracy: 0.4150\n",
      "Epoch 34: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.1458 - accuracy: 0.4150 - val_loss: 1.4213 - val_accuracy: 0.4059\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1374 - accuracy: 0.4225\n",
      "Epoch 35: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.1374 - accuracy: 0.4225 - val_loss: 1.3996 - val_accuracy: 0.4257\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1104 - accuracy: 0.4450\n",
      "Epoch 36: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.1104 - accuracy: 0.4450 - val_loss: 1.3786 - val_accuracy: 0.4554\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.4575\n",
      "Epoch 37: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.1063 - accuracy: 0.4575 - val_loss: 1.4074 - val_accuracy: 0.4257\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1020 - accuracy: 0.4950\n",
      "Epoch 38: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.1020 - accuracy: 0.4950 - val_loss: 1.4166 - val_accuracy: 0.3960\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.5050\n",
      "Epoch 39: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.0743 - accuracy: 0.5050 - val_loss: 1.4073 - val_accuracy: 0.3564\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0639 - accuracy: 0.4975\n",
      "Epoch 40: val_loss did not improve from 1.36799\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 1.0639 - accuracy: 0.4975 - val_loss: 1.4777 - val_accuracy: 0.3663\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0809 - accuracy: 0.4550\n",
      "Epoch 41: val_loss improved from 1.36799 to 1.35706, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.0809 - accuracy: 0.4550 - val_loss: 1.3571 - val_accuracy: 0.3366\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0677 - accuracy: 0.4625\n",
      "Epoch 42: val_loss did not improve from 1.35706\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.0677 - accuracy: 0.4625 - val_loss: 1.3844 - val_accuracy: 0.3762\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0269 - accuracy: 0.5125\n",
      "Epoch 43: val_loss improved from 1.35706 to 1.35144, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.0269 - accuracy: 0.5125 - val_loss: 1.3514 - val_accuracy: 0.4158\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.5325\n",
      "Epoch 44: val_loss improved from 1.35144 to 1.33715, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.0028 - accuracy: 0.5325 - val_loss: 1.3371 - val_accuracy: 0.3960\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0181 - accuracy: 0.5275\n",
      "Epoch 45: val_loss improved from 1.33715 to 1.33503, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.0181 - accuracy: 0.5275 - val_loss: 1.3350 - val_accuracy: 0.3960\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.5525\n",
      "Epoch 46: val_loss did not improve from 1.33503\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.9851 - accuracy: 0.5525 - val_loss: 1.3364 - val_accuracy: 0.4554\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.5450\n",
      "Epoch 47: val_loss did not improve from 1.33503\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.9642 - accuracy: 0.5450 - val_loss: 1.3619 - val_accuracy: 0.3960\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9575 - accuracy: 0.5625\n",
      "Epoch 48: val_loss improved from 1.33503 to 1.33224, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.9575 - accuracy: 0.5625 - val_loss: 1.3322 - val_accuracy: 0.4653\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9138 - accuracy: 0.5850\n",
      "Epoch 49: val_loss did not improve from 1.33224\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.9138 - accuracy: 0.5850 - val_loss: 1.3542 - val_accuracy: 0.4356\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9020 - accuracy: 0.5725\n",
      "Epoch 50: val_loss did not improve from 1.33224\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.9020 - accuracy: 0.5725 - val_loss: 1.4075 - val_accuracy: 0.4257\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8885 - accuracy: 0.5900\n",
      "Epoch 51: val_loss did not improve from 1.33224\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.8885 - accuracy: 0.5900 - val_loss: 1.4695 - val_accuracy: 0.3564\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.5750\n",
      "Epoch 52: val_loss did not improve from 1.33224\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.9238 - accuracy: 0.5750 - val_loss: 1.3971 - val_accuracy: 0.5050\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0554 - accuracy: 0.5075\n",
      "Epoch 53: val_loss did not improve from 1.33224\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.0554 - accuracy: 0.5075 - val_loss: 1.5175 - val_accuracy: 0.3465\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.5375\n",
      "Epoch 54: val_loss improved from 1.33224 to 1.32655, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.0288 - accuracy: 0.5375 - val_loss: 1.3265 - val_accuracy: 0.5347\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9708 - accuracy: 0.5200\n",
      "Epoch 55: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.9708 - accuracy: 0.5200 - val_loss: 1.3592 - val_accuracy: 0.4158\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8496 - accuracy: 0.6125\n",
      "Epoch 56: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.8496 - accuracy: 0.6125 - val_loss: 1.4808 - val_accuracy: 0.3861\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8442 - accuracy: 0.6150\n",
      "Epoch 57: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.8442 - accuracy: 0.6150 - val_loss: 1.4898 - val_accuracy: 0.3564\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8311 - accuracy: 0.6225\n",
      "Epoch 58: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.8311 - accuracy: 0.6225 - val_loss: 1.4142 - val_accuracy: 0.4851\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.6200\n",
      "Epoch 59: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.8050 - accuracy: 0.6200 - val_loss: 1.3290 - val_accuracy: 0.4257\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.6400\n",
      "Epoch 60: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7998 - accuracy: 0.6400 - val_loss: 1.3346 - val_accuracy: 0.4356\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8047 - accuracy: 0.6375\n",
      "Epoch 61: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.8047 - accuracy: 0.6375 - val_loss: 1.4915 - val_accuracy: 0.3762\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8084 - accuracy: 0.6225\n",
      "Epoch 62: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.8084 - accuracy: 0.6225 - val_loss: 1.4705 - val_accuracy: 0.4554\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8606 - accuracy: 0.6125\n",
      "Epoch 63: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.8606 - accuracy: 0.6125 - val_loss: 1.7416 - val_accuracy: 0.3168\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9545 - accuracy: 0.5550\n",
      "Epoch 64: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9545 - accuracy: 0.5550 - val_loss: 1.3981 - val_accuracy: 0.4851\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.5400\n",
      "Epoch 65: val_loss did not improve from 1.32655\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.9902 - accuracy: 0.5400 - val_loss: 1.5730 - val_accuracy: 0.3663\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.5325\n",
      "Epoch 66: val_loss improved from 1.32655 to 1.23695, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.0290 - accuracy: 0.5325 - val_loss: 1.2369 - val_accuracy: 0.4950\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9300 - accuracy: 0.5500\n",
      "Epoch 67: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.9300 - accuracy: 0.5500 - val_loss: 1.3174 - val_accuracy: 0.5149\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8894 - accuracy: 0.5625\n",
      "Epoch 68: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.8894 - accuracy: 0.5625 - val_loss: 1.4225 - val_accuracy: 0.3663\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9447 - accuracy: 0.5650\n",
      "Epoch 69: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.9447 - accuracy: 0.5650 - val_loss: 1.3112 - val_accuracy: 0.4257\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.6100\n",
      "Epoch 70: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7976 - accuracy: 0.6100 - val_loss: 1.4156 - val_accuracy: 0.4950\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.6250\n",
      "Epoch 71: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8397 - accuracy: 0.6250 - val_loss: 1.4489 - val_accuracy: 0.3861\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.6250\n",
      "Epoch 72: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.8304 - accuracy: 0.6250 - val_loss: 1.3974 - val_accuracy: 0.4455\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.6475\n",
      "Epoch 73: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7911 - accuracy: 0.6475 - val_loss: 1.3313 - val_accuracy: 0.5050\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7477 - accuracy: 0.6700\n",
      "Epoch 74: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7477 - accuracy: 0.6700 - val_loss: 1.4143 - val_accuracy: 0.3762\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7754 - accuracy: 0.6475\n",
      "Epoch 75: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7754 - accuracy: 0.6475 - val_loss: 1.3405 - val_accuracy: 0.4059\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.6600\n",
      "Epoch 76: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7381 - accuracy: 0.6600 - val_loss: 1.3566 - val_accuracy: 0.5050\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8057 - accuracy: 0.6075\n",
      "Epoch 77: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.8057 - accuracy: 0.6075 - val_loss: 1.4506 - val_accuracy: 0.3960\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7534 - accuracy: 0.6525\n",
      "Epoch 78: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7534 - accuracy: 0.6525 - val_loss: 1.4452 - val_accuracy: 0.4257\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.6900\n",
      "Epoch 79: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6868 - accuracy: 0.6900 - val_loss: 1.4174 - val_accuracy: 0.4851\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7236 - accuracy: 0.6550\n",
      "Epoch 80: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7236 - accuracy: 0.6550 - val_loss: 1.3934 - val_accuracy: 0.4158\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.6825\n",
      "Epoch 81: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6993 - accuracy: 0.6825 - val_loss: 1.3386 - val_accuracy: 0.4356\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6566 - accuracy: 0.7200\n",
      "Epoch 82: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6566 - accuracy: 0.7200 - val_loss: 1.3557 - val_accuracy: 0.5347\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.6950\n",
      "Epoch 83: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6995 - accuracy: 0.6950 - val_loss: 1.4647 - val_accuracy: 0.4257\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7262 - accuracy: 0.6750\n",
      "Epoch 84: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7262 - accuracy: 0.6750 - val_loss: 1.3725 - val_accuracy: 0.4356\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.7100\n",
      "Epoch 85: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6385 - accuracy: 0.7100 - val_loss: 1.3755 - val_accuracy: 0.4851\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7521 - accuracy: 0.6400\n",
      "Epoch 86: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7521 - accuracy: 0.6400 - val_loss: 1.4873 - val_accuracy: 0.3960\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.6675\n",
      "Epoch 87: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7076 - accuracy: 0.6675 - val_loss: 1.4569 - val_accuracy: 0.4257\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.6825\n",
      "Epoch 88: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6573 - accuracy: 0.6825 - val_loss: 1.5038 - val_accuracy: 0.4356\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.7050\n",
      "Epoch 89: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6385 - accuracy: 0.7050 - val_loss: 1.5067 - val_accuracy: 0.4059\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.7000\n",
      "Epoch 90: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6596 - accuracy: 0.7000 - val_loss: 1.3991 - val_accuracy: 0.5050\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7050\n",
      "Epoch 91: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6545 - accuracy: 0.7050 - val_loss: 1.4050 - val_accuracy: 0.5050\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7000\n",
      "Epoch 92: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6381 - accuracy: 0.7000 - val_loss: 1.4466 - val_accuracy: 0.4356\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.7050\n",
      "Epoch 93: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6579 - accuracy: 0.7050 - val_loss: 1.3506 - val_accuracy: 0.4851\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.7350\n",
      "Epoch 94: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6349 - accuracy: 0.7350 - val_loss: 1.4017 - val_accuracy: 0.4950\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.6900\n",
      "Epoch 95: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6563 - accuracy: 0.6900 - val_loss: 1.4558 - val_accuracy: 0.4158\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.6825\n",
      "Epoch 96: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6605 - accuracy: 0.6825 - val_loss: 1.2705 - val_accuracy: 0.5248\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.7400\n",
      "Epoch 97: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6053 - accuracy: 0.7400 - val_loss: 1.2793 - val_accuracy: 0.5248\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5858 - accuracy: 0.7500\n",
      "Epoch 98: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 1.4434 - val_accuracy: 0.4653\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.7450\n",
      "Epoch 99: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5747 - accuracy: 0.7450 - val_loss: 1.5019 - val_accuracy: 0.4554\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.7400\n",
      "Epoch 100: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6210 - accuracy: 0.7400 - val_loss: 1.4866 - val_accuracy: 0.4653\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7175\n",
      "Epoch 101: val_loss did not improve from 1.23695\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.6013 - accuracy: 0.7175 - val_loss: 1.3454 - val_accuracy: 0.4554\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7500\n",
      "Epoch 102: val_loss improved from 1.23695 to 1.17734, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 1.1773 - val_accuracy: 0.5347\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.6900\n",
      "Epoch 103: val_loss did not improve from 1.17734\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6648 - accuracy: 0.6900 - val_loss: 1.5217 - val_accuracy: 0.4653\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7150\n",
      "Epoch 104: val_loss did not improve from 1.17734\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.6290 - accuracy: 0.7150 - val_loss: 1.4885 - val_accuracy: 0.4653\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.7075\n",
      "Epoch 105: val_loss did not improve from 1.17734\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6200 - accuracy: 0.7075 - val_loss: 1.2862 - val_accuracy: 0.4950\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.7075\n",
      "Epoch 106: val_loss did not improve from 1.17734\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6147 - accuracy: 0.7075 - val_loss: 1.3159 - val_accuracy: 0.4950\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7350\n",
      "Epoch 107: val_loss improved from 1.17734 to 1.05413, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.5902 - accuracy: 0.7350 - val_loss: 1.0541 - val_accuracy: 0.5347\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.7650\n",
      "Epoch 108: val_loss did not improve from 1.05413\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5738 - accuracy: 0.7650 - val_loss: 1.1407 - val_accuracy: 0.5446\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.7200\n",
      "Epoch 109: val_loss did not improve from 1.05413\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5840 - accuracy: 0.7200 - val_loss: 1.5132 - val_accuracy: 0.4455\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7500\n",
      "Epoch 110: val_loss did not improve from 1.05413\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 1.3689 - val_accuracy: 0.4752\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.7475\n",
      "Epoch 111: val_loss did not improve from 1.05413\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.5546 - accuracy: 0.7475 - val_loss: 1.2118 - val_accuracy: 0.5149\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7675\n",
      "Epoch 112: val_loss did not improve from 1.05413\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.5270 - accuracy: 0.7675 - val_loss: 1.1187 - val_accuracy: 0.5644\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.7700\n",
      "Epoch 113: val_loss improved from 1.05413 to 1.03454, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.5281 - accuracy: 0.7700 - val_loss: 1.0345 - val_accuracy: 0.5347\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7700\n",
      "Epoch 114: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.5379 - accuracy: 0.7700 - val_loss: 1.2492 - val_accuracy: 0.5149\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.7800\n",
      "Epoch 115: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4992 - accuracy: 0.7800 - val_loss: 1.5086 - val_accuracy: 0.4554\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.7575\n",
      "Epoch 116: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.5377 - accuracy: 0.7575 - val_loss: 1.3277 - val_accuracy: 0.5050\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7925\n",
      "Epoch 117: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.4937 - accuracy: 0.7925 - val_loss: 1.3301 - val_accuracy: 0.5248\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7675\n",
      "Epoch 118: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5550 - accuracy: 0.7675 - val_loss: 1.0535 - val_accuracy: 0.5743\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7675\n",
      "Epoch 119: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.5072 - accuracy: 0.7675 - val_loss: 1.2043 - val_accuracy: 0.5545\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.7875\n",
      "Epoch 120: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4934 - accuracy: 0.7875 - val_loss: 1.6560 - val_accuracy: 0.4158\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7850\n",
      "Epoch 121: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5288 - accuracy: 0.7850 - val_loss: 1.3890 - val_accuracy: 0.5149\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7525\n",
      "Epoch 122: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5446 - accuracy: 0.7525 - val_loss: 1.3380 - val_accuracy: 0.4950\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.7550\n",
      "Epoch 123: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.5256 - accuracy: 0.7550 - val_loss: 1.1145 - val_accuracy: 0.5347\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7675\n",
      "Epoch 124: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5269 - accuracy: 0.7675 - val_loss: 1.0680 - val_accuracy: 0.5842\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8025\n",
      "Epoch 125: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.4867 - accuracy: 0.8025 - val_loss: 1.4162 - val_accuracy: 0.5149\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8000\n",
      "Epoch 126: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.4648 - accuracy: 0.8000 - val_loss: 1.4240 - val_accuracy: 0.5050\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8125\n",
      "Epoch 127: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.4744 - accuracy: 0.8125 - val_loss: 1.4160 - val_accuracy: 0.5050\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8225\n",
      "Epoch 128: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.4421 - accuracy: 0.8225 - val_loss: 1.1188 - val_accuracy: 0.5347\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.7725\n",
      "Epoch 129: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4796 - accuracy: 0.7725 - val_loss: 1.1895 - val_accuracy: 0.5248\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.8000\n",
      "Epoch 130: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4550 - accuracy: 0.8000 - val_loss: 1.1394 - val_accuracy: 0.5446\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8350\n",
      "Epoch 131: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4388 - accuracy: 0.8350 - val_loss: 1.3816 - val_accuracy: 0.5149\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4299 - accuracy: 0.8300\n",
      "Epoch 132: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.4299 - accuracy: 0.8300 - val_loss: 1.4547 - val_accuracy: 0.5149\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8450\n",
      "Epoch 133: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.4316 - accuracy: 0.8450 - val_loss: 1.1202 - val_accuracy: 0.5842\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8400\n",
      "Epoch 134: val_loss did not improve from 1.03454\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.4293 - accuracy: 0.8400 - val_loss: 1.1773 - val_accuracy: 0.5644\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.8100\n",
      "Epoch 135: val_loss improved from 1.03454 to 0.96933, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4438 - accuracy: 0.8100 - val_loss: 0.9693 - val_accuracy: 0.6832\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.8300\n",
      "Epoch 136: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4353 - accuracy: 0.8300 - val_loss: 1.1812 - val_accuracy: 0.5842\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3962 - accuracy: 0.8675\n",
      "Epoch 137: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3962 - accuracy: 0.8675 - val_loss: 1.2835 - val_accuracy: 0.5347\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8475\n",
      "Epoch 138: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4077 - accuracy: 0.8475 - val_loss: 1.3527 - val_accuracy: 0.5446\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8625\n",
      "Epoch 139: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3783 - accuracy: 0.8625 - val_loss: 1.2819 - val_accuracy: 0.6139\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8750\n",
      "Epoch 140: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3707 - accuracy: 0.8750 - val_loss: 1.2291 - val_accuracy: 0.6634\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.8650\n",
      "Epoch 141: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3919 - accuracy: 0.8650 - val_loss: 1.3416 - val_accuracy: 0.5842\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.8575\n",
      "Epoch 142: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3929 - accuracy: 0.8575 - val_loss: 1.3770 - val_accuracy: 0.5545\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.8550\n",
      "Epoch 143: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3687 - accuracy: 0.8550 - val_loss: 1.2986 - val_accuracy: 0.6040\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8975\n",
      "Epoch 144: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.3460 - accuracy: 0.8975 - val_loss: 1.3064 - val_accuracy: 0.5941\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8875\n",
      "Epoch 145: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.3372 - accuracy: 0.8875 - val_loss: 1.2469 - val_accuracy: 0.6139\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8900\n",
      "Epoch 146: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3262 - accuracy: 0.8900 - val_loss: 1.1367 - val_accuracy: 0.6733\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8900\n",
      "Epoch 147: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3270 - accuracy: 0.8900 - val_loss: 1.3164 - val_accuracy: 0.6238\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.8875\n",
      "Epoch 148: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.3214 - accuracy: 0.8875 - val_loss: 1.6605 - val_accuracy: 0.4851\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8575\n",
      "Epoch 149: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3721 - accuracy: 0.8575 - val_loss: 1.0642 - val_accuracy: 0.6931\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8600\n",
      "Epoch 150: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3766 - accuracy: 0.8600 - val_loss: 1.4287 - val_accuracy: 0.4851\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8375\n",
      "Epoch 151: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3927 - accuracy: 0.8375 - val_loss: 0.9871 - val_accuracy: 0.7030\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.8125\n",
      "Epoch 152: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4474 - accuracy: 0.8125 - val_loss: 1.4430 - val_accuracy: 0.5149\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8750\n",
      "Epoch 153: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3711 - accuracy: 0.8750 - val_loss: 1.1910 - val_accuracy: 0.6535\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9025\n",
      "Epoch 154: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2957 - accuracy: 0.9025 - val_loss: 1.2790 - val_accuracy: 0.6139\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9325\n",
      "Epoch 155: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2435 - accuracy: 0.9325 - val_loss: 1.1370 - val_accuracy: 0.6634\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.9025\n",
      "Epoch 156: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.2933 - accuracy: 0.9025 - val_loss: 1.3519 - val_accuracy: 0.6040\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9175\n",
      "Epoch 157: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2832 - accuracy: 0.9175 - val_loss: 1.0912 - val_accuracy: 0.6931\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8800\n",
      "Epoch 158: val_loss did not improve from 0.96933\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3438 - accuracy: 0.8800 - val_loss: 1.3934 - val_accuracy: 0.5941\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9075\n",
      "Epoch 159: val_loss improved from 0.96933 to 0.96571, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.2751 - accuracy: 0.9075 - val_loss: 0.9657 - val_accuracy: 0.7426\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9225\n",
      "Epoch 160: val_loss did not improve from 0.96571\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2544 - accuracy: 0.9225 - val_loss: 1.5597 - val_accuracy: 0.5743\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9075\n",
      "Epoch 161: val_loss did not improve from 0.96571\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2699 - accuracy: 0.9075 - val_loss: 1.1498 - val_accuracy: 0.6832\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9375\n",
      "Epoch 162: val_loss did not improve from 0.96571\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2259 - accuracy: 0.9375 - val_loss: 1.5072 - val_accuracy: 0.5743\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9175\n",
      "Epoch 163: val_loss improved from 0.96571 to 0.94683, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2525 - accuracy: 0.9175 - val_loss: 0.9468 - val_accuracy: 0.7921\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.8950\n",
      "Epoch 164: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2687 - accuracy: 0.8950 - val_loss: 1.4861 - val_accuracy: 0.5545\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8975\n",
      "Epoch 165: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2581 - accuracy: 0.8975 - val_loss: 0.9908 - val_accuracy: 0.7624\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9050\n",
      "Epoch 166: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.2644 - accuracy: 0.9050 - val_loss: 1.6728 - val_accuracy: 0.5050\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8825\n",
      "Epoch 167: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3167 - accuracy: 0.8825 - val_loss: 1.1060 - val_accuracy: 0.7129\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9350\n",
      "Epoch 168: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1974 - accuracy: 0.9350 - val_loss: 1.2787 - val_accuracy: 0.6139\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9250\n",
      "Epoch 169: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.2438 - accuracy: 0.9250 - val_loss: 0.9615 - val_accuracy: 0.7426\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9400\n",
      "Epoch 170: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2077 - accuracy: 0.9400 - val_loss: 1.5049 - val_accuracy: 0.5842\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9400\n",
      "Epoch 171: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1939 - accuracy: 0.9400 - val_loss: 1.2446 - val_accuracy: 0.6634\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9450\n",
      "Epoch 172: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2003 - accuracy: 0.9450 - val_loss: 1.3109 - val_accuracy: 0.6436\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9525\n",
      "Epoch 173: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1829 - accuracy: 0.9525 - val_loss: 0.9755 - val_accuracy: 0.7426\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9300\n",
      "Epoch 174: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2094 - accuracy: 0.9300 - val_loss: 1.3108 - val_accuracy: 0.6238\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9450\n",
      "Epoch 175: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1817 - accuracy: 0.9450 - val_loss: 1.1625 - val_accuracy: 0.6832\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9525\n",
      "Epoch 176: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.1959 - accuracy: 0.9525 - val_loss: 1.6633 - val_accuracy: 0.5446\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9075\n",
      "Epoch 177: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2443 - accuracy: 0.9075 - val_loss: 0.9881 - val_accuracy: 0.7327\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.8850\n",
      "Epoch 178: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.3088 - accuracy: 0.8850 - val_loss: 1.6197 - val_accuracy: 0.5644\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.8900\n",
      "Epoch 179: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2865 - accuracy: 0.8900 - val_loss: 1.0252 - val_accuracy: 0.7129\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8225\n",
      "Epoch 180: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4072 - accuracy: 0.8225 - val_loss: 1.7479 - val_accuracy: 0.5248\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8575\n",
      "Epoch 181: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3559 - accuracy: 0.8575 - val_loss: 1.0040 - val_accuracy: 0.7228\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8475\n",
      "Epoch 182: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4119 - accuracy: 0.8475 - val_loss: 1.8181 - val_accuracy: 0.5248\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8750\n",
      "Epoch 183: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3249 - accuracy: 0.8750 - val_loss: 1.1092 - val_accuracy: 0.7228\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9000\n",
      "Epoch 184: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2650 - accuracy: 0.9000 - val_loss: 1.4655 - val_accuracy: 0.6337\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9450\n",
      "Epoch 185: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1863 - accuracy: 0.9450 - val_loss: 1.2671 - val_accuracy: 0.6832\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9500\n",
      "Epoch 186: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.1661 - accuracy: 0.9500 - val_loss: 1.0566 - val_accuracy: 0.7525\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9550\n",
      "Epoch 187: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1450 - accuracy: 0.9550 - val_loss: 1.6062 - val_accuracy: 0.5743\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9350\n",
      "Epoch 188: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1911 - accuracy: 0.9350 - val_loss: 1.1803 - val_accuracy: 0.7129\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9500\n",
      "Epoch 189: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1596 - accuracy: 0.9500 - val_loss: 1.2478 - val_accuracy: 0.6832\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9675\n",
      "Epoch 190: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1309 - accuracy: 0.9675 - val_loss: 1.2132 - val_accuracy: 0.6733\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9800\n",
      "Epoch 191: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1235 - accuracy: 0.9800 - val_loss: 1.0122 - val_accuracy: 0.7525\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9650\n",
      "Epoch 192: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1351 - accuracy: 0.9650 - val_loss: 1.2749 - val_accuracy: 0.6634\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9700\n",
      "Epoch 193: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1260 - accuracy: 0.9700 - val_loss: 1.0722 - val_accuracy: 0.7129\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9475\n",
      "Epoch 194: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1490 - accuracy: 0.9475 - val_loss: 1.3912 - val_accuracy: 0.6337\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9525\n",
      "Epoch 195: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1466 - accuracy: 0.9525 - val_loss: 1.1557 - val_accuracy: 0.6733\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9550\n",
      "Epoch 196: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1273 - accuracy: 0.9550 - val_loss: 0.9513 - val_accuracy: 0.7525\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9625\n",
      "Epoch 197: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1377 - accuracy: 0.9625 - val_loss: 1.5743 - val_accuracy: 0.6139\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.9425\n",
      "Epoch 198: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1878 - accuracy: 0.9425 - val_loss: 0.9829 - val_accuracy: 0.7426\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9650\n",
      "Epoch 199: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1430 - accuracy: 0.9650 - val_loss: 1.0167 - val_accuracy: 0.7030\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9750\n",
      "Epoch 200: val_loss did not improve from 0.94683\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1072 - accuracy: 0.9750 - val_loss: 1.5236 - val_accuracy: 0.6139\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9625\n",
      "Epoch 201: val_loss improved from 0.94683 to 0.91382, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1276 - accuracy: 0.9625 - val_loss: 0.9138 - val_accuracy: 0.7525\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9675\n",
      "Epoch 202: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1300 - accuracy: 0.9675 - val_loss: 1.1041 - val_accuracy: 0.7030\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9750\n",
      "Epoch 203: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1062 - accuracy: 0.9750 - val_loss: 1.2372 - val_accuracy: 0.6634\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9800\n",
      "Epoch 204: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0856 - accuracy: 0.9800 - val_loss: 0.9804 - val_accuracy: 0.7426\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9700\n",
      "Epoch 205: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.1070 - accuracy: 0.9700 - val_loss: 1.1865 - val_accuracy: 0.7030\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9825\n",
      "Epoch 206: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0901 - accuracy: 0.9825 - val_loss: 1.1985 - val_accuracy: 0.6931\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9750\n",
      "Epoch 207: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0886 - accuracy: 0.9750 - val_loss: 1.1435 - val_accuracy: 0.7030\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9775\n",
      "Epoch 208: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0967 - accuracy: 0.9775 - val_loss: 0.9868 - val_accuracy: 0.7228\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9825\n",
      "Epoch 209: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0892 - accuracy: 0.9825 - val_loss: 0.9236 - val_accuracy: 0.7426\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9775\n",
      "Epoch 210: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0900 - accuracy: 0.9775 - val_loss: 1.3524 - val_accuracy: 0.6436\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9750\n",
      "Epoch 211: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1032 - accuracy: 0.9750 - val_loss: 1.2932 - val_accuracy: 0.6832\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9850\n",
      "Epoch 212: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0784 - accuracy: 0.9850 - val_loss: 1.3451 - val_accuracy: 0.6634\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9775\n",
      "Epoch 213: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1028 - accuracy: 0.9775 - val_loss: 1.4096 - val_accuracy: 0.6733\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9800\n",
      "Epoch 214: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0848 - accuracy: 0.9800 - val_loss: 1.2113 - val_accuracy: 0.6832\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9800\n",
      "Epoch 215: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0838 - accuracy: 0.9800 - val_loss: 1.1547 - val_accuracy: 0.6931\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9875\n",
      "Epoch 216: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0725 - accuracy: 0.9875 - val_loss: 1.0799 - val_accuracy: 0.7030\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9875\n",
      "Epoch 217: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0683 - accuracy: 0.9875 - val_loss: 1.1827 - val_accuracy: 0.6832\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9850\n",
      "Epoch 218: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0693 - accuracy: 0.9850 - val_loss: 1.1644 - val_accuracy: 0.6931\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9900\n",
      "Epoch 219: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0667 - accuracy: 0.9900 - val_loss: 1.1663 - val_accuracy: 0.7030\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9825\n",
      "Epoch 220: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0825 - accuracy: 0.9825 - val_loss: 1.3181 - val_accuracy: 0.6733\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9850\n",
      "Epoch 221: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0704 - accuracy: 0.9850 - val_loss: 1.0803 - val_accuracy: 0.7426\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9800\n",
      "Epoch 222: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0815 - accuracy: 0.9800 - val_loss: 1.1009 - val_accuracy: 0.7525\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9800\n",
      "Epoch 223: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0783 - accuracy: 0.9800 - val_loss: 1.4099 - val_accuracy: 0.6634\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9825\n",
      "Epoch 224: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 1.2314 - val_accuracy: 0.7030\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9875\n",
      "Epoch 225: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0665 - accuracy: 0.9875 - val_loss: 1.2714 - val_accuracy: 0.6832\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9875\n",
      "Epoch 226: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0677 - accuracy: 0.9875 - val_loss: 1.5649 - val_accuracy: 0.6436\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9750\n",
      "Epoch 227: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 1.0786 - val_accuracy: 0.7426\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9750\n",
      "Epoch 228: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 1.1215 - val_accuracy: 0.7030\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9800\n",
      "Epoch 229: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0754 - accuracy: 0.9800 - val_loss: 1.4028 - val_accuracy: 0.6337\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9800\n",
      "Epoch 230: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0931 - accuracy: 0.9800 - val_loss: 1.1133 - val_accuracy: 0.7525\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9800\n",
      "Epoch 231: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0937 - accuracy: 0.9800 - val_loss: 1.5056 - val_accuracy: 0.6436\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9700\n",
      "Epoch 232: val_loss did not improve from 0.91382\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0983 - accuracy: 0.9700 - val_loss: 1.0474 - val_accuracy: 0.7525\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9875\n",
      "Epoch 233: val_loss improved from 0.91382 to 0.87342, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0685 - accuracy: 0.9875 - val_loss: 0.8734 - val_accuracy: 0.7822\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9850\n",
      "Epoch 234: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0809 - accuracy: 0.9850 - val_loss: 1.0995 - val_accuracy: 0.7327\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9875\n",
      "Epoch 235: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0692 - accuracy: 0.9875 - val_loss: 1.1409 - val_accuracy: 0.7228\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9900\n",
      "Epoch 236: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0535 - accuracy: 0.9900 - val_loss: 1.0657 - val_accuracy: 0.7327\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9800\n",
      "Epoch 237: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0732 - accuracy: 0.9800 - val_loss: 1.4992 - val_accuracy: 0.6436\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9775\n",
      "Epoch 238: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0879 - accuracy: 0.9775 - val_loss: 0.9349 - val_accuracy: 0.7822\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9725\n",
      "Epoch 239: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.8965 - val_accuracy: 0.7723\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9850\n",
      "Epoch 240: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0631 - accuracy: 0.9850 - val_loss: 1.4133 - val_accuracy: 0.6535\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9775\n",
      "Epoch 241: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0804 - accuracy: 0.9775 - val_loss: 1.2582 - val_accuracy: 0.6733\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9650\n",
      "Epoch 242: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1247 - accuracy: 0.9650 - val_loss: 1.4452 - val_accuracy: 0.6535\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9775\n",
      "Epoch 243: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0837 - accuracy: 0.9775 - val_loss: 1.0086 - val_accuracy: 0.7525\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9725\n",
      "Epoch 244: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0934 - accuracy: 0.9725 - val_loss: 1.2274 - val_accuracy: 0.6832\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9700\n",
      "Epoch 245: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0965 - accuracy: 0.9700 - val_loss: 1.0572 - val_accuracy: 0.7228\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9825\n",
      "Epoch 246: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0642 - accuracy: 0.9825 - val_loss: 0.9227 - val_accuracy: 0.7426\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9850\n",
      "Epoch 247: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0719 - accuracy: 0.9850 - val_loss: 1.4607 - val_accuracy: 0.6634\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9775\n",
      "Epoch 248: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0927 - accuracy: 0.9775 - val_loss: 1.2577 - val_accuracy: 0.6733\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9825\n",
      "Epoch 249: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0828 - accuracy: 0.9825 - val_loss: 0.9655 - val_accuracy: 0.7327\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9700\n",
      "Epoch 250: val_loss did not improve from 0.87342\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.1117 - accuracy: 0.9700 - val_loss: 1.5969 - val_accuracy: 0.6139\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9375\n",
      "Epoch 251: val_loss improved from 0.87342 to 0.80397, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1610 - accuracy: 0.9375 - val_loss: 0.8040 - val_accuracy: 0.7921\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9600\n",
      "Epoch 252: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1126 - accuracy: 0.9600 - val_loss: 1.3918 - val_accuracy: 0.6931\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9775\n",
      "Epoch 253: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0857 - accuracy: 0.9775 - val_loss: 1.5676 - val_accuracy: 0.6634\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9850\n",
      "Epoch 254: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0700 - accuracy: 0.9850 - val_loss: 1.2478 - val_accuracy: 0.6931\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9875\n",
      "Epoch 255: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0674 - accuracy: 0.9875 - val_loss: 1.2807 - val_accuracy: 0.7030\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9925\n",
      "Epoch 256: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0488 - accuracy: 0.9925 - val_loss: 1.3934 - val_accuracy: 0.6931\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9875\n",
      "Epoch 257: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0688 - accuracy: 0.9875 - val_loss: 1.1948 - val_accuracy: 0.7129\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9850\n",
      "Epoch 258: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0712 - accuracy: 0.9850 - val_loss: 1.1384 - val_accuracy: 0.7426\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9925\n",
      "Epoch 259: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0493 - accuracy: 0.9925 - val_loss: 1.3441 - val_accuracy: 0.6832\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9850\n",
      "Epoch 260: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0672 - accuracy: 0.9850 - val_loss: 1.2424 - val_accuracy: 0.7228\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9850\n",
      "Epoch 261: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0622 - accuracy: 0.9850 - val_loss: 1.1663 - val_accuracy: 0.7426\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9825\n",
      "Epoch 262: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 1.4964 - val_accuracy: 0.6733\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9850\n",
      "Epoch 263: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0584 - accuracy: 0.9850 - val_loss: 1.3125 - val_accuracy: 0.7129\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9900\n",
      "Epoch 264: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0493 - accuracy: 0.9900 - val_loss: 1.0636 - val_accuracy: 0.7525\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9775\n",
      "Epoch 265: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 1.2306 - val_accuracy: 0.7228\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9900\n",
      "Epoch 266: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 1s 247ms/step - loss: 0.0495 - accuracy: 0.9900 - val_loss: 1.2640 - val_accuracy: 0.7030\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9900\n",
      "Epoch 267: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0476 - accuracy: 0.9900 - val_loss: 1.0723 - val_accuracy: 0.7624\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9850\n",
      "Epoch 268: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0625 - accuracy: 0.9850 - val_loss: 1.3763 - val_accuracy: 0.7030\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9875\n",
      "Epoch 269: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 1.2192 - val_accuracy: 0.7327\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9900\n",
      "Epoch 270: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.0414 - accuracy: 0.9900 - val_loss: 1.0636 - val_accuracy: 0.7624\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9875\n",
      "Epoch 271: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0525 - accuracy: 0.9875 - val_loss: 1.3576 - val_accuracy: 0.6832\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9800\n",
      "Epoch 272: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 1.0383 - val_accuracy: 0.7822\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9750\n",
      "Epoch 273: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 1.1252 - val_accuracy: 0.7525\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9850\n",
      "Epoch 274: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0518 - accuracy: 0.9850 - val_loss: 1.6555 - val_accuracy: 0.6535\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9775\n",
      "Epoch 275: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 1.0826 - val_accuracy: 0.7327\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9800\n",
      "Epoch 276: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0807 - accuracy: 0.9800 - val_loss: 1.0661 - val_accuracy: 0.7723\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9575\n",
      "Epoch 277: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1197 - accuracy: 0.9575 - val_loss: 1.1382 - val_accuracy: 0.7525\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 278: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0592 - accuracy: 0.9825 - val_loss: 1.0896 - val_accuracy: 0.7624\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9800\n",
      "Epoch 279: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0689 - accuracy: 0.9800 - val_loss: 1.5579 - val_accuracy: 0.6733\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9775\n",
      "Epoch 280: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0739 - accuracy: 0.9775 - val_loss: 1.2025 - val_accuracy: 0.7426\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9900\n",
      "Epoch 281: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.9698 - val_accuracy: 0.7723\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9725\n",
      "Epoch 282: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0923 - accuracy: 0.9725 - val_loss: 1.1537 - val_accuracy: 0.7327\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9850\n",
      "Epoch 283: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 1.0522 - val_accuracy: 0.7525\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9900\n",
      "Epoch 284: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 1.1094 - val_accuracy: 0.7426\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 285: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 1.2445 - val_accuracy: 0.7228\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9925\n",
      "Epoch 286: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0479 - accuracy: 0.9925 - val_loss: 1.3613 - val_accuracy: 0.7030\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9900\n",
      "Epoch 287: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 1.2191 - val_accuracy: 0.7426\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9900\n",
      "Epoch 288: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0471 - accuracy: 0.9900 - val_loss: 1.2153 - val_accuracy: 0.7426\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9850\n",
      "Epoch 289: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 1.4487 - val_accuracy: 0.7129\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9825\n",
      "Epoch 290: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0606 - accuracy: 0.9825 - val_loss: 1.2544 - val_accuracy: 0.7327\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9850\n",
      "Epoch 291: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0537 - accuracy: 0.9850 - val_loss: 1.2428 - val_accuracy: 0.7525\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9875\n",
      "Epoch 292: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0547 - accuracy: 0.9875 - val_loss: 1.5821 - val_accuracy: 0.6535\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9750\n",
      "Epoch 293: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0665 - accuracy: 0.9750 - val_loss: 1.2868 - val_accuracy: 0.7525\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9825\n",
      "Epoch 294: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0826 - accuracy: 0.9825 - val_loss: 1.3468 - val_accuracy: 0.7030\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9850\n",
      "Epoch 295: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0601 - accuracy: 0.9850 - val_loss: 1.3054 - val_accuracy: 0.7129\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9925\n",
      "Epoch 296: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0361 - accuracy: 0.9925 - val_loss: 0.9466 - val_accuracy: 0.7723\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9875\n",
      "Epoch 297: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0616 - accuracy: 0.9875 - val_loss: 1.1381 - val_accuracy: 0.7030\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9925\n",
      "Epoch 298: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 1.2338 - val_accuracy: 0.6733\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9850\n",
      "Epoch 299: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 1.1233 - val_accuracy: 0.7228\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9925\n",
      "Epoch 300: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0411 - accuracy: 0.9925 - val_loss: 1.2104 - val_accuracy: 0.7030\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 301: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 1.3069 - val_accuracy: 0.7030\n",
      "Epoch 302/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 302: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 1.1457 - val_accuracy: 0.7129\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9925\n",
      "Epoch 303: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0389 - accuracy: 0.9925 - val_loss: 0.9610 - val_accuracy: 0.7723\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 304: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 0.9897 - val_accuracy: 0.7723\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9925\n",
      "Epoch 305: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0357 - accuracy: 0.9925 - val_loss: 1.2482 - val_accuracy: 0.7129\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9850\n",
      "Epoch 306: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0448 - accuracy: 0.9850 - val_loss: 1.0979 - val_accuracy: 0.7723\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9925\n",
      "Epoch 307: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 0.9676 - val_accuracy: 0.7525\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 308: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 1.0726 - val_accuracy: 0.7525\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9900\n",
      "Epoch 309: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 1.2419 - val_accuracy: 0.7228\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9875\n",
      "Epoch 310: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.0397 - accuracy: 0.9875 - val_loss: 1.1879 - val_accuracy: 0.7228\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9900\n",
      "Epoch 311: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.9810 - val_accuracy: 0.7723\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9925\n",
      "Epoch 312: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0338 - accuracy: 0.9925 - val_loss: 1.0036 - val_accuracy: 0.7624\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9850\n",
      "Epoch 313: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 1.1504 - val_accuracy: 0.7129\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9875\n",
      "Epoch 314: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.9777 - val_accuracy: 0.7723\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9875\n",
      "Epoch 315: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 1.1884 - val_accuracy: 0.7129\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9925\n",
      "Epoch 316: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 1.4645 - val_accuracy: 0.6733\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9850\n",
      "Epoch 317: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0647 - accuracy: 0.9850 - val_loss: 1.1045 - val_accuracy: 0.7426\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9925\n",
      "Epoch 318: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0301 - accuracy: 0.9925 - val_loss: 1.0466 - val_accuracy: 0.7723\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9925\n",
      "Epoch 319: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0384 - accuracy: 0.9925 - val_loss: 1.1087 - val_accuracy: 0.7426\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9925\n",
      "Epoch 320: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 1.2686 - val_accuracy: 0.7129\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9875\n",
      "Epoch 321: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 1.0661 - val_accuracy: 0.7525\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9825\n",
      "Epoch 322: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0449 - accuracy: 0.9825 - val_loss: 1.2883 - val_accuracy: 0.7327\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9850\n",
      "Epoch 323: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0586 - accuracy: 0.9850 - val_loss: 1.2499 - val_accuracy: 0.7327\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9850\n",
      "Epoch 324: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0427 - accuracy: 0.9850 - val_loss: 1.0314 - val_accuracy: 0.7822\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9875\n",
      "Epoch 325: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 1.1326 - val_accuracy: 0.7525\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9925\n",
      "Epoch 326: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 1.2824 - val_accuracy: 0.7129\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9900\n",
      "Epoch 327: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0534 - accuracy: 0.9900 - val_loss: 1.2830 - val_accuracy: 0.7228\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9925\n",
      "Epoch 328: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0348 - accuracy: 0.9925 - val_loss: 1.2035 - val_accuracy: 0.7228\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 329: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 1.1596 - val_accuracy: 0.7327\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9850\n",
      "Epoch 330: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0445 - accuracy: 0.9850 - val_loss: 1.3120 - val_accuracy: 0.7129\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9925\n",
      "Epoch 331: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 1.4572 - val_accuracy: 0.6931\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9900\n",
      "Epoch 332: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0437 - accuracy: 0.9900 - val_loss: 1.3729 - val_accuracy: 0.7129\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9925\n",
      "Epoch 333: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 1.3043 - val_accuracy: 0.7228\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 334: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 1.3486 - val_accuracy: 0.7228\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9900\n",
      "Epoch 335: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 1.4358 - val_accuracy: 0.7030\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9900\n",
      "Epoch 336: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 1.4079 - val_accuracy: 0.7327\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9900\n",
      "Epoch 337: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 1.2882 - val_accuracy: 0.7426\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 338: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 1.1112 - val_accuracy: 0.7723\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9925\n",
      "Epoch 339: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0326 - accuracy: 0.9925 - val_loss: 1.1912 - val_accuracy: 0.7624\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9925\n",
      "Epoch 340: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 1.4655 - val_accuracy: 0.6832\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9900\n",
      "Epoch 341: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 1.2230 - val_accuracy: 0.7426\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9900\n",
      "Epoch 342: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 1.1106 - val_accuracy: 0.7723\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9800\n",
      "Epoch 343: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 1.4771 - val_accuracy: 0.6733\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9800\n",
      "Epoch 344: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.9977 - val_accuracy: 0.7723\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9675\n",
      "Epoch 345: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1096 - accuracy: 0.9675 - val_loss: 1.1226 - val_accuracy: 0.7525\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9850\n",
      "Epoch 346: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 1.6979 - val_accuracy: 0.6436\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9900\n",
      "Epoch 347: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0427 - accuracy: 0.9900 - val_loss: 1.3428 - val_accuracy: 0.6931\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9850\n",
      "Epoch 348: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 1.4481 - val_accuracy: 0.6832\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9875\n",
      "Epoch 349: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 1.5181 - val_accuracy: 0.6832\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9900\n",
      "Epoch 350: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 1.3075 - val_accuracy: 0.7129\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 351: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 1.1577 - val_accuracy: 0.7624\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9900\n",
      "Epoch 352: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 1.2555 - val_accuracy: 0.7327\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 353: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 1.3055 - val_accuracy: 0.7129\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9900\n",
      "Epoch 354: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 1.3458 - val_accuracy: 0.7030\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9900\n",
      "Epoch 355: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 1.4084 - val_accuracy: 0.7129\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9875\n",
      "Epoch 356: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0521 - accuracy: 0.9875 - val_loss: 1.5019 - val_accuracy: 0.6832\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9875\n",
      "Epoch 357: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0345 - accuracy: 0.9875 - val_loss: 1.3118 - val_accuracy: 0.7030\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9900\n",
      "Epoch 358: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 1.1696 - val_accuracy: 0.7129\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9875\n",
      "Epoch 359: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 1.4147 - val_accuracy: 0.6733\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9850\n",
      "Epoch 360: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 1.2833 - val_accuracy: 0.7129\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 361: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 1.2645 - val_accuracy: 0.7129\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9875\n",
      "Epoch 362: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 1.4155 - val_accuracy: 0.7030\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9925\n",
      "Epoch 363: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 1.5775 - val_accuracy: 0.6733\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9875\n",
      "Epoch 364: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 1.2233 - val_accuracy: 0.7327\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9900\n",
      "Epoch 365: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.0252 - accuracy: 0.9900 - val_loss: 0.8529 - val_accuracy: 0.8119\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9825\n",
      "Epoch 366: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0599 - accuracy: 0.9825 - val_loss: 1.3243 - val_accuracy: 0.7030\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9875\n",
      "Epoch 367: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 1.4732 - val_accuracy: 0.7030\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9875\n",
      "Epoch 368: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 1.2706 - val_accuracy: 0.7129\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9850\n",
      "Epoch 369: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 1.2228 - val_accuracy: 0.7129\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9850\n",
      "Epoch 370: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0367 - accuracy: 0.9850 - val_loss: 1.1310 - val_accuracy: 0.7426\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9900\n",
      "Epoch 371: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0432 - accuracy: 0.9900 - val_loss: 1.1760 - val_accuracy: 0.7624\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9900\n",
      "Epoch 372: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 1.4165 - val_accuracy: 0.7228\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9900\n",
      "Epoch 373: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 1.7278 - val_accuracy: 0.6634\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9925\n",
      "Epoch 374: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0420 - accuracy: 0.9925 - val_loss: 1.5381 - val_accuracy: 0.6931\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9925\n",
      "Epoch 375: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 1.2650 - val_accuracy: 0.7426\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9875\n",
      "Epoch 376: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 1.3228 - val_accuracy: 0.7327\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9875\n",
      "Epoch 377: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 1.3412 - val_accuracy: 0.7030\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9925\n",
      "Epoch 378: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 1.1957 - val_accuracy: 0.7525\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 379: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 1.2676 - val_accuracy: 0.7624\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9925\n",
      "Epoch 380: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 1.5852 - val_accuracy: 0.6832\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 381: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 1.7167 - val_accuracy: 0.6733\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9900\n",
      "Epoch 382: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 1.3434 - val_accuracy: 0.7228\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9850\n",
      "Epoch 383: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0417 - accuracy: 0.9850 - val_loss: 1.3256 - val_accuracy: 0.7426\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9925\n",
      "Epoch 384: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 1.2910 - val_accuracy: 0.7426\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9850\n",
      "Epoch 385: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 1.2321 - val_accuracy: 0.7624\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9725\n",
      "Epoch 386: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0746 - accuracy: 0.9725 - val_loss: 1.3430 - val_accuracy: 0.7426\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9800\n",
      "Epoch 387: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 1.2221 - val_accuracy: 0.7327\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9875\n",
      "Epoch 388: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 1.0326 - val_accuracy: 0.7921\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9850\n",
      "Epoch 389: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 1.3775 - val_accuracy: 0.7129\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 390: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 1.5628 - val_accuracy: 0.6832\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9925\n",
      "Epoch 391: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 1.1759 - val_accuracy: 0.7426\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9825\n",
      "Epoch 392: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 1.4073 - val_accuracy: 0.7030\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9725\n",
      "Epoch 393: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0741 - accuracy: 0.9725 - val_loss: 1.0503 - val_accuracy: 0.7822\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9775\n",
      "Epoch 394: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0466 - accuracy: 0.9775 - val_loss: 0.9008 - val_accuracy: 0.8020\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9825\n",
      "Epoch 395: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0421 - accuracy: 0.9825 - val_loss: 1.7693 - val_accuracy: 0.6634\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9675\n",
      "Epoch 396: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0961 - accuracy: 0.9675 - val_loss: 1.0634 - val_accuracy: 0.7426\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9775\n",
      "Epoch 397: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0625 - accuracy: 0.9775 - val_loss: 1.2208 - val_accuracy: 0.7327\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9925\n",
      "Epoch 398: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 1.6582 - val_accuracy: 0.6634\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9400\n",
      "Epoch 399: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1474 - accuracy: 0.9400 - val_loss: 1.2664 - val_accuracy: 0.7723\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.8325\n",
      "Epoch 400: val_loss did not improve from 0.80397\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.4613 - accuracy: 0.8325 - val_loss: 1.5411 - val_accuracy: 0.6535\n",
      "Training completed in time:  0:02:08.739629\n",
      "Training Accuracy:  0.8075000047683716\n",
      "Testing Accuracy:  0.6534653306007385\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = '/Users/irk2w/Desktop/T5/sounds_final '\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "def extract_features(file_path, target_shape=(128, 128)):\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Data Augmentation\n",
    "    pitch_shifted = librosa.effects.pitch_shift(audio_data, sr=sample_rate, n_steps=4)\n",
    "    time_stretched = librosa.effects.time_stretch(audio_data, rate=1.5)\n",
    "\n",
    "    # Original Features\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    # Augmented Features\n",
    "    mel_spectrogram_pitch = librosa.feature.melspectrogram(y=pitch_shifted, sr=sample_rate)\n",
    "    mel_spectrogram_stretch = librosa.feature.melspectrogram(y=time_stretched, sr=sample_rate)\n",
    "\n",
    "    # Resizing\n",
    "    mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "    mel_spectrogram_pitch_resized = resize(mel_spectrogram_pitch, target_shape)\n",
    "    mel_spectrogram_stretch_resized = resize(mel_spectrogram_stretch, target_shape)\n",
    "\n",
    "    return mel_spectrogram_resized, mel_spectrogram_pitch_resized, mel_spectrogram_stretch_resized\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                original, pitch, stretch = extract_features(file_path, target_shape)\n",
    "                # Append original features\n",
    "                data.append(original)\n",
    "                labels.append(i)\n",
    "                # Append augmented features\n",
    "                data.append(pitch)\n",
    "                labels.append(i)\n",
    "                data.append(stretch)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=400, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('911_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "The model predicts that the audio file is a Police sound.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_audio_class(file_path, model, classes):\n",
    "    # Assuming the extract_features function is defined as above\n",
    "    features = extract_features(file_path)[0]  # Use the original features for prediction\n",
    "    features = np.expand_dims(features, axis=0)  # Reshaping to match model input\n",
    "\n",
    "    # Make the prediction\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return classes[predicted_class[0]]\n",
    "\n",
    "# Usage\n",
    "model = load_model(\"/Users/irk2w/Desktop/T5/911_model_don't_touch/911_class.h5\")  # Load your model\n",
    "audio_file_path = '/Users/irk2w/Downloads/1.wav'\n",
    "predicted_class_name = predict_audio_class(audio_file_path, model, classes)\n",
    "print(f\"The model predicts that the audio file is a {predicted_class_name} sound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6U_HCDih1DjD",
    "outputId": "f2ba3d9e-8859-4794-e17e-0765cd3f9fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXUI739bOx7b"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "gtts = gTTS('           ', lang='ar')\n",
    "gtts.save('police-10.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlkFZaog1Dr7"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cm5TBP6LRPil",
    "outputId": "3bb694cd-e65b-4623-e1be-cd087620700f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 442ms/step - loss: 1.6455 - accuracy: 0.2353 - val_loss: 2.0695 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.8984 - accuracy: 0.7143 - val_loss: 2.0566 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.6367 - accuracy: 0.7899 - val_loss: 2.0225 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.5065 - accuracy: 0.9076 - val_loss: 2.2557 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.4022 - accuracy: 0.9328 - val_loss: 2.3901 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.3839 - accuracy: 0.9160 - val_loss: 2.6047 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.2956 - accuracy: 0.9664 - val_loss: 2.7975 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.2842 - accuracy: 0.9664 - val_loss: 2.9052 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.2399 - accuracy: 0.9832 - val_loss: 2.9519 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.3002 - accuracy: 0.9412 - val_loss: 3.0533 - val_accuracy: 0.2143 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7af2f24222c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# ... Your data loading and preprocessing code ...\n",
    "\n",
    "# Normalization (example using global mean and std)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Improved model architecture\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Consider adding Conv2D layers here if you want to use CNN features\n",
    "\n",
    "# Using bidirectional LSTM and adding dropout\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5))(input_layer)\n",
    "x = Flatten()(x)  # Flatten needed if return_sequences=True\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)  # Regularized dense layer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile and fit the model with some form of learning rate scheduler or reduction on plateau\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_2-WodI2DEN",
    "outputId": "566db597-49f1-4d7a-b0c6-254db4c09044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128)]        0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49668 (194.02 KB)\n",
      "Trainable params: 49668 (194.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 14.7059%\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.2556\n",
      "Epoch 1: val_loss improved from inf to 1.38667, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3862 - accuracy: 0.2556 - val_loss: 1.3867 - val_accuracy: 0.2059\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3854 - accuracy: 0.2857\n",
      "Epoch 2: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3854 - accuracy: 0.2857 - val_loss: 1.3869 - val_accuracy: 0.2353\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.3233\n",
      "Epoch 3: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 1.3847 - accuracy: 0.3233 - val_loss: 1.3872 - val_accuracy: 0.2647\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3838 - accuracy: 0.3308\n",
      "Epoch 4: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.3838 - accuracy: 0.3308 - val_loss: 1.3875 - val_accuracy: 0.2353\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3829 - accuracy: 0.3083\n",
      "Epoch 5: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.3829 - accuracy: 0.3083 - val_loss: 1.3879 - val_accuracy: 0.2353\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.3383\n",
      "Epoch 6: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3819 - accuracy: 0.3383 - val_loss: 1.3884 - val_accuracy: 0.2647\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3808 - accuracy: 0.3233\n",
      "Epoch 7: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.3808 - accuracy: 0.3233 - val_loss: 1.3890 - val_accuracy: 0.2647\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3795 - accuracy: 0.2932\n",
      "Epoch 8: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.3795 - accuracy: 0.2932 - val_loss: 1.3898 - val_accuracy: 0.2647\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3779 - accuracy: 0.2857\n",
      "Epoch 9: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3779 - accuracy: 0.2857 - val_loss: 1.3909 - val_accuracy: 0.2647\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760 - accuracy: 0.2707\n",
      "Epoch 10: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.3760 - accuracy: 0.2707 - val_loss: 1.3922 - val_accuracy: 0.2647\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3735 - accuracy: 0.2707\n",
      "Epoch 11: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3735 - accuracy: 0.2707 - val_loss: 1.3937 - val_accuracy: 0.2647\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.2707\n",
      "Epoch 12: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3702 - accuracy: 0.2707 - val_loss: 1.3954 - val_accuracy: 0.2647\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.2857\n",
      "Epoch 13: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.3657 - accuracy: 0.2857 - val_loss: 1.3976 - val_accuracy: 0.2647\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.3008\n",
      "Epoch 14: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3596 - accuracy: 0.3008 - val_loss: 1.4007 - val_accuracy: 0.2647\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3513 - accuracy: 0.3083\n",
      "Epoch 15: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.3513 - accuracy: 0.3083 - val_loss: 1.4060 - val_accuracy: 0.2647\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.3383\n",
      "Epoch 16: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.3415 - accuracy: 0.3383 - val_loss: 1.4141 - val_accuracy: 0.2941\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3314 - accuracy: 0.3158\n",
      "Epoch 17: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3314 - accuracy: 0.3158 - val_loss: 1.4147 - val_accuracy: 0.2647\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3173 - accuracy: 0.3459\n",
      "Epoch 18: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.3173 - accuracy: 0.3459 - val_loss: 1.4091 - val_accuracy: 0.2647\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.3609\n",
      "Epoch 19: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.3025 - accuracy: 0.3609 - val_loss: 1.4205 - val_accuracy: 0.2941\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2844 - accuracy: 0.3835\n",
      "Epoch 20: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2844 - accuracy: 0.3835 - val_loss: 1.4332 - val_accuracy: 0.2353\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.3910\n",
      "Epoch 21: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.2684 - accuracy: 0.3910 - val_loss: 1.4467 - val_accuracy: 0.2353\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.4060\n",
      "Epoch 22: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.2526 - accuracy: 0.4060 - val_loss: 1.4942 - val_accuracy: 0.2353\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.4436\n",
      "Epoch 23: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2347 - accuracy: 0.4436 - val_loss: 1.5379 - val_accuracy: 0.3235\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.4060\n",
      "Epoch 24: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.2199 - accuracy: 0.4060 - val_loss: 1.5558 - val_accuracy: 0.3235\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2063 - accuracy: 0.4060\n",
      "Epoch 25: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2063 - accuracy: 0.4060 - val_loss: 1.5546 - val_accuracy: 0.2941\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.4361\n",
      "Epoch 26: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.1852 - accuracy: 0.4361 - val_loss: 1.5662 - val_accuracy: 0.2353\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1632 - accuracy: 0.4511\n",
      "Epoch 27: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.1632 - accuracy: 0.4511 - val_loss: 1.5502 - val_accuracy: 0.2353\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1407 - accuracy: 0.4436\n",
      "Epoch 28: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.1407 - accuracy: 0.4436 - val_loss: 1.6185 - val_accuracy: 0.2353\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1132 - accuracy: 0.4586\n",
      "Epoch 29: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.1132 - accuracy: 0.4586 - val_loss: 1.6707 - val_accuracy: 0.2059\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.5038\n",
      "Epoch 30: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.0870 - accuracy: 0.5038 - val_loss: 1.7512 - val_accuracy: 0.2059\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0602 - accuracy: 0.5113\n",
      "Epoch 31: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.0602 - accuracy: 0.5113 - val_loss: 1.7159 - val_accuracy: 0.2059\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.5338\n",
      "Epoch 32: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.0474 - accuracy: 0.5338 - val_loss: 1.8227 - val_accuracy: 0.1471\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.5489\n",
      "Epoch 33: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.0299 - accuracy: 0.5489 - val_loss: 1.9081 - val_accuracy: 0.2059\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.5263\n",
      "Epoch 34: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.0045 - accuracy: 0.5263 - val_loss: 1.9237 - val_accuracy: 0.1471\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9977 - accuracy: 0.5564\n",
      "Epoch 35: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.9977 - accuracy: 0.5564 - val_loss: 1.9086 - val_accuracy: 0.2059\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.5940\n",
      "Epoch 36: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.9643 - accuracy: 0.5940 - val_loss: 1.9747 - val_accuracy: 0.1471\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6090\n",
      "Epoch 37: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.9505 - accuracy: 0.6090 - val_loss: 2.0074 - val_accuracy: 0.2059\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9158 - accuracy: 0.5865\n",
      "Epoch 38: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.9158 - accuracy: 0.5865 - val_loss: 1.9506 - val_accuracy: 0.2647\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.6617\n",
      "Epoch 39: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.9104 - accuracy: 0.6617 - val_loss: 1.9521 - val_accuracy: 0.2059\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.6692\n",
      "Epoch 40: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8917 - accuracy: 0.6692 - val_loss: 2.1640 - val_accuracy: 0.2059\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.6165\n",
      "Epoch 41: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8838 - accuracy: 0.6165 - val_loss: 2.0018 - val_accuracy: 0.2353\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8336 - accuracy: 0.7293\n",
      "Epoch 42: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8336 - accuracy: 0.7293 - val_loss: 1.9636 - val_accuracy: 0.2647\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7143\n",
      "Epoch 43: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8414 - accuracy: 0.7143 - val_loss: 2.0193 - val_accuracy: 0.2353\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.7368\n",
      "Epoch 44: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8038 - accuracy: 0.7368 - val_loss: 2.1758 - val_accuracy: 0.2059\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.7669\n",
      "Epoch 45: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7573 - accuracy: 0.7669 - val_loss: 2.2976 - val_accuracy: 0.2647\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.7669\n",
      "Epoch 46: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.7665 - accuracy: 0.7669 - val_loss: 2.2293 - val_accuracy: 0.2059\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.8421\n",
      "Epoch 47: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7066 - accuracy: 0.8421 - val_loss: 2.1931 - val_accuracy: 0.2353\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.8346\n",
      "Epoch 48: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7153 - accuracy: 0.8346 - val_loss: 2.1434 - val_accuracy: 0.1765\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.8195\n",
      "Epoch 49: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7170 - accuracy: 0.8195 - val_loss: 2.2306 - val_accuracy: 0.1765\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.8722\n",
      "Epoch 50: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6571 - accuracy: 0.8722 - val_loss: 2.3553 - val_accuracy: 0.2353\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.8195\n",
      "Epoch 51: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.6594 - accuracy: 0.8195 - val_loss: 2.3235 - val_accuracy: 0.2353\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.8947\n",
      "Epoch 52: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5927 - accuracy: 0.8947 - val_loss: 2.2728 - val_accuracy: 0.2647\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.9098\n",
      "Epoch 53: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.5841 - accuracy: 0.9098 - val_loss: 2.2972 - val_accuracy: 0.2647\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.9098\n",
      "Epoch 54: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5615 - accuracy: 0.9098 - val_loss: 2.3908 - val_accuracy: 0.2941\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.9023\n",
      "Epoch 55: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5605 - accuracy: 0.9023 - val_loss: 2.3741 - val_accuracy: 0.2647\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.9023\n",
      "Epoch 56: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5525 - accuracy: 0.9023 - val_loss: 2.4029 - val_accuracy: 0.2647\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8797\n",
      "Epoch 57: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5424 - accuracy: 0.8797 - val_loss: 2.4052 - val_accuracy: 0.2941\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.9323\n",
      "Epoch 58: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4746 - accuracy: 0.9323 - val_loss: 2.4799 - val_accuracy: 0.2647\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8722\n",
      "Epoch 59: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5463 - accuracy: 0.8722 - val_loss: 2.3664 - val_accuracy: 0.2941\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.9248\n",
      "Epoch 60: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4703 - accuracy: 0.9248 - val_loss: 2.4319 - val_accuracy: 0.2059\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8947\n",
      "Epoch 61: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5069 - accuracy: 0.8947 - val_loss: 2.4673 - val_accuracy: 0.3235\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.8797\n",
      "Epoch 62: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4676 - accuracy: 0.8797 - val_loss: 2.4229 - val_accuracy: 0.3235\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.9173\n",
      "Epoch 63: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4233 - accuracy: 0.9173 - val_loss: 2.4113 - val_accuracy: 0.2941\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.9098\n",
      "Epoch 64: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4505 - accuracy: 0.9098 - val_loss: 2.3929 - val_accuracy: 0.3235\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.9248\n",
      "Epoch 65: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4261 - accuracy: 0.9248 - val_loss: 2.4613 - val_accuracy: 0.3235\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.9173\n",
      "Epoch 66: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4006 - accuracy: 0.9173 - val_loss: 2.5181 - val_accuracy: 0.3235\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.9023\n",
      "Epoch 67: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4235 - accuracy: 0.9023 - val_loss: 2.4628 - val_accuracy: 0.2941\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9323\n",
      "Epoch 68: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3838 - accuracy: 0.9323 - val_loss: 2.4461 - val_accuracy: 0.2941\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.9323\n",
      "Epoch 69: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.3948 - accuracy: 0.9323 - val_loss: 2.4778 - val_accuracy: 0.3235\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9323\n",
      "Epoch 70: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3742 - accuracy: 0.9323 - val_loss: 2.5474 - val_accuracy: 0.3529\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9248\n",
      "Epoch 71: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3570 - accuracy: 0.9248 - val_loss: 2.5681 - val_accuracy: 0.3235\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.9323\n",
      "Epoch 72: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3482 - accuracy: 0.9323 - val_loss: 2.5904 - val_accuracy: 0.3235\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9323\n",
      "Epoch 73: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3346 - accuracy: 0.9323 - val_loss: 2.5863 - val_accuracy: 0.3235\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9323\n",
      "Epoch 74: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3288 - accuracy: 0.9323 - val_loss: 2.5843 - val_accuracy: 0.3235\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9323\n",
      "Epoch 75: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3182 - accuracy: 0.9323 - val_loss: 2.6054 - val_accuracy: 0.2941\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9323\n",
      "Epoch 76: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3132 - accuracy: 0.9323 - val_loss: 2.6191 - val_accuracy: 0.2941\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9323\n",
      "Epoch 77: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.3092 - accuracy: 0.9323 - val_loss: 2.6153 - val_accuracy: 0.2647\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9398\n",
      "Epoch 78: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2954 - accuracy: 0.9398 - val_loss: 2.6234 - val_accuracy: 0.2941\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.9398\n",
      "Epoch 79: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2874 - accuracy: 0.9398 - val_loss: 2.6340 - val_accuracy: 0.3235\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9398\n",
      "Epoch 80: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.2869 - accuracy: 0.9398 - val_loss: 2.6492 - val_accuracy: 0.3235\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.9398\n",
      "Epoch 81: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2791 - accuracy: 0.9398 - val_loss: 2.6674 - val_accuracy: 0.2941\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9398\n",
      "Epoch 82: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2679 - accuracy: 0.9398 - val_loss: 2.6840 - val_accuracy: 0.2941\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9398\n",
      "Epoch 83: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2622 - accuracy: 0.9398 - val_loss: 2.7037 - val_accuracy: 0.2941\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9398\n",
      "Epoch 84: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2583 - accuracy: 0.9398 - val_loss: 2.7289 - val_accuracy: 0.2941\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9474\n",
      "Epoch 85: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2499 - accuracy: 0.9474 - val_loss: 2.7515 - val_accuracy: 0.2941\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9474\n",
      "Epoch 86: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2393 - accuracy: 0.9474 - val_loss: 2.7633 - val_accuracy: 0.2941\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9474\n",
      "Epoch 87: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2312 - accuracy: 0.9474 - val_loss: 2.7771 - val_accuracy: 0.2941\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9474\n",
      "Epoch 88: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2279 - accuracy: 0.9474 - val_loss: 2.7971 - val_accuracy: 0.2941\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9474\n",
      "Epoch 89: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2219 - accuracy: 0.9474 - val_loss: 2.8169 - val_accuracy: 0.2941\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9474\n",
      "Epoch 90: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2135 - accuracy: 0.9474 - val_loss: 2.8545 - val_accuracy: 0.2647\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9549\n",
      "Epoch 91: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2067 - accuracy: 0.9549 - val_loss: 2.8874 - val_accuracy: 0.2647\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9549\n",
      "Epoch 92: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2027 - accuracy: 0.9549 - val_loss: 2.8899 - val_accuracy: 0.2647\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9549\n",
      "Epoch 93: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1948 - accuracy: 0.9549 - val_loss: 2.9026 - val_accuracy: 0.2647\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9549\n",
      "Epoch 94: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1899 - accuracy: 0.9549 - val_loss: 2.9296 - val_accuracy: 0.2941\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9549\n",
      "Epoch 95: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1850 - accuracy: 0.9549 - val_loss: 2.9581 - val_accuracy: 0.2941\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9624\n",
      "Epoch 96: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1814 - accuracy: 0.9624 - val_loss: 2.9777 - val_accuracy: 0.2941\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9549\n",
      "Epoch 97: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1750 - accuracy: 0.9549 - val_loss: 3.0070 - val_accuracy: 0.2941\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9549\n",
      "Epoch 98: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1708 - accuracy: 0.9549 - val_loss: 3.0403 - val_accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9624\n",
      "Epoch 99: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1663 - accuracy: 0.9624 - val_loss: 3.0475 - val_accuracy: 0.2941\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9624\n",
      "Epoch 100: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1618 - accuracy: 0.9624 - val_loss: 3.0489 - val_accuracy: 0.2647\n",
      "Training completed in time:  0:00:42.935128\n",
      "Training Accuracy:  0.9624060392379761\n",
      "Testing Accuracy:  0.2647058963775635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional , Input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a function to extract MFCC features from audio files\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    return mfccs_processed\n",
    "\n",
    "# Define the dataset directory and the labels\n",
    "data_dir = '/content/drive/MyDrive/New folder/T5/sounds final'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Encode the labels to integers\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(64))\n",
    "#model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPSMHvMm3Y99"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
