{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbc7192-9233-4e1d-b0ee-a72326827987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT THE LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\"\n",
    "                         )\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9189ff0e-8b51-46e3-9d10-8a1bfee8185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data= \"../input/speech-emotion-recognition-for-emergency-calls/CUSTOM_DATASET/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a81e0-5be3-40f8-9245-cccf1d5cee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_num_split(item):\n",
    "    for index, letter in enumerate(item, 0):\n",
    "        if letter.isdigit():\n",
    "            return [item[:index],item[index:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d4289-4639-47e8-9bb8-6a442d01bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(Data)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(Data + i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('_')\n",
    "        emotion.append(int(part[0]))\n",
    "        path.append(Data + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addf784-b196-40cd-80e6-1d86e3f55800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(emotion)\n",
    "map_dict = {1:'angry', 2:'drunk', 3:'painful', 4:'stressful'}\n",
    "df.columns = ['Emotion']\n",
    "df[\"Emotion\"] = df['Emotion'].map(map_dict)\n",
    "df = pd.concat([df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "df.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7906cf-a9ab-4672-a298-249c9e9fdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(df.Emotion)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb3d35-396f-47bc-a916-ddb17cb85181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6f6a9-5630-433f-97d7-5389dd9c77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different functions above\n",
    "path = np.array(df['path'])[217]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91e3d8-25eb-4078-896b-2ad572b43c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL AUDIO\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=data, sr=sample_rate)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7140608-693d-444f-bc53-6ff3db130f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO WITH NOISE\n",
    "x = noise(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c650db-1850-4719-8668-97beda67f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRETCHED AUDIO\n",
    "x = stretch(data)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9eedc-d11c-48a6-9a3c-df85c087d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHIFTED AUDIO\n",
    "x = shift(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337b0c-1c21-4d05-8981-c0d81eca0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO WITH PITCH\n",
    "x = pitch(data, sample_rate)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8195b2-e699-422f-ab4d-f6d938f024dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_ext(data):\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    return mfcc\n",
    "\n",
    "def get_feat(path):\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    # normal data\n",
    "    res1 = feat_ext(data)\n",
    "    result = np.array(res1)\n",
    "    #data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = feat_ext(noise_data)\n",
    "    result = np.vstack((result, res2))\n",
    "    #data with stretch and pitch\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = feat_ext(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e74b93-03df-43e7-b8d1-693af84f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53f7f3-4b42-48cd-af4d-acae4e80526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(df['path'], df['Emotion']):\n",
    "    feature = get_feat(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1220f10-80c7-431b-b005-c9436a2ba031",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee65ecb-e397-49f2-94c9-f6ec446a7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8733-7cc2-4f38-970d-b494b0e2b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y.\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be706886-8d4e-46f3-bcc9-275eb147570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ec09d-2d73-427c-aaa4-9fb067aee966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1=KNeighborsClassifier(n_neighbors=3)\n",
    "clf1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d71088-d5b0-47f3-804a-90f68a659aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66670a-46fc-4603-a2d4-b796868322c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.3f}\".format(clf1.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf1.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f70ead-18a5-437e-9cdf-c9be5a5ab4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(n_estimators=25,objective=\"binary:logistic\", colsample_bytree=0.8,max_depth=5,reg_lambda= 7,scale_pos_weight=3, subsample=1)\n",
    "\n",
    "xgb_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d5ff0-b7ff-4f1b-aab2-1acf8144ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl.fit(x_train,y_train)\n",
    "\n",
    "y_pred=xgb_cl.predict(x_test)\n",
    "print(\"Training set score: {:.3f}\".format(xgb_cl.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(xgb_cl.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4792a-df4c-4de8-b08e-98a3cc53045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf2=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=400)\n",
    "clf2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac97f1e-3e8b-4bcd-a108-0fe1def6c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec7371-dfdb-4078-af0a-180250fe8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.3f}\".format(clf2.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf2.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de38aad-3e84-4aa9-ba36-a23e0bcfafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e06242-8242-4938-ba46-9651d95b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(2048, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(1024, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0480833-887a-4b3e-9375-4d69f2a85fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc879ba8-9ada-4568-bdcf-02b4011a9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_traincnn, y_train, batch_size=64, epochs=1500, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e214aa-8db3-46f5-b5f1-677a824334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bac2fb-e5cf-4a64-acb8-3665f199faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1500)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca684a6f-33aa-484e-9c26-2d79c271ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_testcnn)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "y_test = encoder.inverse_transform(y_test)\n",
    "\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()\n",
    "\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67ac2f-65d7-4505-8aee-38d92ca2e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a585756-eba0-417b-84f9-43bdcd38a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Emotion_Emergency.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4db86-b836-4c3a-9e3a-bcb44af0730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bf88d-aa2d-4d0f-9449-cef0a2fdae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/kaggle/working/saved_models/Emotion_Emergency.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f803ea6-79b2-4c9d-aa42-341cca2070ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('../input/dataset-ec/RAW_DATA/NOT_STRESSFUL/not_stressful61.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6551d01-ea7a-480f-bb17-40f792fda49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"../input/customdata/CUSTOM_DATASET/Speaker3/02_03_01_01_03.wav\"\n",
    "feature = get_feat(sample)\n",
    "test =np.expand_dims(feature, axis=2)\n",
    "livepreds = loaded_model.predict(test)\n",
    "livepredictions = (encoder.inverse_transform((livepreds)))\n",
    "livepredictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
