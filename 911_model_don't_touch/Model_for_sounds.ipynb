{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozqsc-u2GaWM",
    "outputId": "bd6a21f1-4702-41e4-b480-c39859f7b764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WczrEMtAy5Dm",
    "outputId": "0bc6e5c7-f1bc-4ea2-bb97-8e1d959d41bc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 4s 262ms/step - loss: 1.3857 - accuracy: 0.2269 - val_loss: 1.3946 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.3825 - accuracy: 0.2773 - val_loss: 1.4035 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1.3803 - accuracy: 0.2857 - val_loss: 1.4174 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.3760 - accuracy: 0.3277 - val_loss: 1.4331 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.3674 - accuracy: 0.2857 - val_loss: 1.4664 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.3578 - accuracy: 0.2857 - val_loss: 1.4782 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.3491 - accuracy: 0.2857 - val_loss: 1.4794 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.3341 - accuracy: 0.3109 - val_loss: 1.4604 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.3263 - accuracy: 0.3697 - val_loss: 1.4606 - val_accuracy: 0.2143\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.2973 - accuracy: 0.3782 - val_loss: 1.5011 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.2510 - accuracy: 0.4034 - val_loss: 1.4749 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.2291 - accuracy: 0.4202 - val_loss: 1.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.1756 - accuracy: 0.4790 - val_loss: 1.6643 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.1150 - accuracy: 0.5210 - val_loss: 1.7577 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.2336 - accuracy: 0.4370 - val_loss: 1.4756 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.2643 - accuracy: 0.4118 - val_loss: 1.5001 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.2543 - accuracy: 0.4034 - val_loss: 1.5609 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 1.1992 - accuracy: 0.4370 - val_loss: 1.4183 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 1.1534 - accuracy: 0.4706 - val_loss: 1.4419 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.1104 - accuracy: 0.4958 - val_loss: 1.4444 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 1.0601 - accuracy: 0.5546 - val_loss: 1.7434 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.0456 - accuracy: 0.5210 - val_loss: 2.2410 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.0515 - accuracy: 0.5042 - val_loss: 2.1564 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.9311 - accuracy: 0.5625"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Conv1D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import librosa\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "data_dir = '/Users/fahad/Desktop/sounds final  2'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(40,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCviXBZo_Nqy",
    "outputId": "bdcaba61-a009-4ff9-a5ad-e8907b418271",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = '/Users/irk2w/Desktop/T5/sounds_final '\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "def extract_features(file_path, target_shape=(128, 128)):\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Data Augmentation\n",
    "    pitch_shifted = librosa.effects.pitch_shift(audio_data, sr=sample_rate, n_steps=4)\n",
    "    time_stretched = librosa.effects.time_stretch(audio_data, rate=1.5)\n",
    "\n",
    "    # Original Features\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    # Augmented Features\n",
    "    mel_spectrogram_pitch = librosa.feature.melspectrogram(y=pitch_shifted, sr=sample_rate)\n",
    "    mel_spectrogram_stretch = librosa.feature.melspectrogram(y=time_stretched, sr=sample_rate)\n",
    "\n",
    "    # Resizing\n",
    "    mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "    mel_spectrogram_pitch_resized = resize(mel_spectrogram_pitch, target_shape)\n",
    "    mel_spectrogram_stretch_resized = resize(mel_spectrogram_stretch, target_shape)\n",
    "\n",
    "    return mel_spectrogram_resized, mel_spectrogram_pitch_resized, mel_spectrogram_stretch_resized\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                original, pitch, stretch = extract_features(file_path, target_shape)\n",
    "                # Append original features\n",
    "                data.append(original)\n",
    "                labels.append(i)\n",
    "                # Append augmented features\n",
    "                data.append(pitch)\n",
    "                labels.append(i)\n",
    "                data.append(stretch)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=400, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('911_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "The model predicts that the audio file is a Police sound.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_audio_class(file_path, model, classes):\n",
    "    # Assuming the extract_features function is defined as above\n",
    "    features = extract_features(file_path)[0]  # Use the original features for prediction\n",
    "    features = np.expand_dims(features, axis=0)  # Reshaping to match model input\n",
    "\n",
    "    # Make the prediction\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return classes[predicted_class[0]]\n",
    "\n",
    "# Usage\n",
    "model = load_model(\"Desktop/T5/911_model_don't_touch/911_class_test.h5\")  # Load your model\n",
    "audio_file_path = '/Users/irk2w/Downloads/1.wav'\n",
    "predicted_class_name = predict_audio_class(audio_file_path, model, classes)\n",
    "print(f\"The model predicts that the audio file is a {predicted_class_name} sound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6U_HCDih1DjD",
    "outputId": "f2ba3d9e-8859-4794-e17e-0765cd3f9fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXUI739bOx7b"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "gtts = gTTS('مرحبًا، أود الإبلاغ عن رصد حقيبة مشبوهة تُترك بمفردها في محطة القطار', lang='ar')\n",
    "gtts.save('police-10.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlkFZaog1Dr7"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cm5TBP6LRPil",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3bb694cd-e65b-4623-e1be-cd087620700f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 442ms/step - loss: 1.6455 - accuracy: 0.2353 - val_loss: 2.0695 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.8984 - accuracy: 0.7143 - val_loss: 2.0566 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.6367 - accuracy: 0.7899 - val_loss: 2.0225 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.5065 - accuracy: 0.9076 - val_loss: 2.2557 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.4022 - accuracy: 0.9328 - val_loss: 2.3901 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.3839 - accuracy: 0.9160 - val_loss: 2.6047 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.2956 - accuracy: 0.9664 - val_loss: 2.7975 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.2842 - accuracy: 0.9664 - val_loss: 2.9052 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.2399 - accuracy: 0.9832 - val_loss: 2.9519 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.3002 - accuracy: 0.9412 - val_loss: 3.0533 - val_accuracy: 0.2143 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7af2f24222c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# ... Your data loading and preprocessing code ...\n",
    "\n",
    "# Normalization (example using global mean and std)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Improved model architecture\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Consider adding Conv2D layers here if you want to use CNN features\n",
    "\n",
    "# Using bidirectional LSTM and adding dropout\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5))(input_layer)\n",
    "x = Flatten()(x)  # Flatten needed if return_sequences=True\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)  # Regularized dense layer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile and fit the model with some form of learning rate scheduler or reduction on plateau\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1_2-WodI2DEN",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "566db597-49f1-4d7a-b0c6-254db4c09044",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128)]        0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49668 (194.02 KB)\n",
      "Trainable params: 49668 (194.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 14.7059%\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.2556\n",
      "Epoch 1: val_loss improved from inf to 1.38667, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3862 - accuracy: 0.2556 - val_loss: 1.3867 - val_accuracy: 0.2059\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3854 - accuracy: 0.2857\n",
      "Epoch 2: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3854 - accuracy: 0.2857 - val_loss: 1.3869 - val_accuracy: 0.2353\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.3233\n",
      "Epoch 3: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 1.3847 - accuracy: 0.3233 - val_loss: 1.3872 - val_accuracy: 0.2647\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3838 - accuracy: 0.3308\n",
      "Epoch 4: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.3838 - accuracy: 0.3308 - val_loss: 1.3875 - val_accuracy: 0.2353\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3829 - accuracy: 0.3083\n",
      "Epoch 5: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.3829 - accuracy: 0.3083 - val_loss: 1.3879 - val_accuracy: 0.2353\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.3383\n",
      "Epoch 6: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3819 - accuracy: 0.3383 - val_loss: 1.3884 - val_accuracy: 0.2647\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3808 - accuracy: 0.3233\n",
      "Epoch 7: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.3808 - accuracy: 0.3233 - val_loss: 1.3890 - val_accuracy: 0.2647\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3795 - accuracy: 0.2932\n",
      "Epoch 8: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.3795 - accuracy: 0.2932 - val_loss: 1.3898 - val_accuracy: 0.2647\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3779 - accuracy: 0.2857\n",
      "Epoch 9: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3779 - accuracy: 0.2857 - val_loss: 1.3909 - val_accuracy: 0.2647\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760 - accuracy: 0.2707\n",
      "Epoch 10: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.3760 - accuracy: 0.2707 - val_loss: 1.3922 - val_accuracy: 0.2647\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3735 - accuracy: 0.2707\n",
      "Epoch 11: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3735 - accuracy: 0.2707 - val_loss: 1.3937 - val_accuracy: 0.2647\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.2707\n",
      "Epoch 12: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3702 - accuracy: 0.2707 - val_loss: 1.3954 - val_accuracy: 0.2647\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.2857\n",
      "Epoch 13: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.3657 - accuracy: 0.2857 - val_loss: 1.3976 - val_accuracy: 0.2647\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.3008\n",
      "Epoch 14: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3596 - accuracy: 0.3008 - val_loss: 1.4007 - val_accuracy: 0.2647\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3513 - accuracy: 0.3083\n",
      "Epoch 15: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.3513 - accuracy: 0.3083 - val_loss: 1.4060 - val_accuracy: 0.2647\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.3383\n",
      "Epoch 16: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.3415 - accuracy: 0.3383 - val_loss: 1.4141 - val_accuracy: 0.2941\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3314 - accuracy: 0.3158\n",
      "Epoch 17: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3314 - accuracy: 0.3158 - val_loss: 1.4147 - val_accuracy: 0.2647\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3173 - accuracy: 0.3459\n",
      "Epoch 18: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.3173 - accuracy: 0.3459 - val_loss: 1.4091 - val_accuracy: 0.2647\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.3609\n",
      "Epoch 19: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.3025 - accuracy: 0.3609 - val_loss: 1.4205 - val_accuracy: 0.2941\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2844 - accuracy: 0.3835\n",
      "Epoch 20: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2844 - accuracy: 0.3835 - val_loss: 1.4332 - val_accuracy: 0.2353\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.3910\n",
      "Epoch 21: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.2684 - accuracy: 0.3910 - val_loss: 1.4467 - val_accuracy: 0.2353\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.4060\n",
      "Epoch 22: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.2526 - accuracy: 0.4060 - val_loss: 1.4942 - val_accuracy: 0.2353\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.4436\n",
      "Epoch 23: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2347 - accuracy: 0.4436 - val_loss: 1.5379 - val_accuracy: 0.3235\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.4060\n",
      "Epoch 24: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.2199 - accuracy: 0.4060 - val_loss: 1.5558 - val_accuracy: 0.3235\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2063 - accuracy: 0.4060\n",
      "Epoch 25: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2063 - accuracy: 0.4060 - val_loss: 1.5546 - val_accuracy: 0.2941\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.4361\n",
      "Epoch 26: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.1852 - accuracy: 0.4361 - val_loss: 1.5662 - val_accuracy: 0.2353\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1632 - accuracy: 0.4511\n",
      "Epoch 27: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.1632 - accuracy: 0.4511 - val_loss: 1.5502 - val_accuracy: 0.2353\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1407 - accuracy: 0.4436\n",
      "Epoch 28: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.1407 - accuracy: 0.4436 - val_loss: 1.6185 - val_accuracy: 0.2353\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1132 - accuracy: 0.4586\n",
      "Epoch 29: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.1132 - accuracy: 0.4586 - val_loss: 1.6707 - val_accuracy: 0.2059\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.5038\n",
      "Epoch 30: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.0870 - accuracy: 0.5038 - val_loss: 1.7512 - val_accuracy: 0.2059\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0602 - accuracy: 0.5113\n",
      "Epoch 31: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.0602 - accuracy: 0.5113 - val_loss: 1.7159 - val_accuracy: 0.2059\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.5338\n",
      "Epoch 32: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.0474 - accuracy: 0.5338 - val_loss: 1.8227 - val_accuracy: 0.1471\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.5489\n",
      "Epoch 33: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.0299 - accuracy: 0.5489 - val_loss: 1.9081 - val_accuracy: 0.2059\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.5263\n",
      "Epoch 34: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.0045 - accuracy: 0.5263 - val_loss: 1.9237 - val_accuracy: 0.1471\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9977 - accuracy: 0.5564\n",
      "Epoch 35: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.9977 - accuracy: 0.5564 - val_loss: 1.9086 - val_accuracy: 0.2059\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.5940\n",
      "Epoch 36: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.9643 - accuracy: 0.5940 - val_loss: 1.9747 - val_accuracy: 0.1471\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6090\n",
      "Epoch 37: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.9505 - accuracy: 0.6090 - val_loss: 2.0074 - val_accuracy: 0.2059\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9158 - accuracy: 0.5865\n",
      "Epoch 38: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.9158 - accuracy: 0.5865 - val_loss: 1.9506 - val_accuracy: 0.2647\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.6617\n",
      "Epoch 39: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.9104 - accuracy: 0.6617 - val_loss: 1.9521 - val_accuracy: 0.2059\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.6692\n",
      "Epoch 40: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8917 - accuracy: 0.6692 - val_loss: 2.1640 - val_accuracy: 0.2059\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.6165\n",
      "Epoch 41: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8838 - accuracy: 0.6165 - val_loss: 2.0018 - val_accuracy: 0.2353\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8336 - accuracy: 0.7293\n",
      "Epoch 42: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8336 - accuracy: 0.7293 - val_loss: 1.9636 - val_accuracy: 0.2647\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7143\n",
      "Epoch 43: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8414 - accuracy: 0.7143 - val_loss: 2.0193 - val_accuracy: 0.2353\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.7368\n",
      "Epoch 44: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8038 - accuracy: 0.7368 - val_loss: 2.1758 - val_accuracy: 0.2059\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.7669\n",
      "Epoch 45: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7573 - accuracy: 0.7669 - val_loss: 2.2976 - val_accuracy: 0.2647\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.7669\n",
      "Epoch 46: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.7665 - accuracy: 0.7669 - val_loss: 2.2293 - val_accuracy: 0.2059\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.8421\n",
      "Epoch 47: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7066 - accuracy: 0.8421 - val_loss: 2.1931 - val_accuracy: 0.2353\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.8346\n",
      "Epoch 48: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7153 - accuracy: 0.8346 - val_loss: 2.1434 - val_accuracy: 0.1765\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.8195\n",
      "Epoch 49: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7170 - accuracy: 0.8195 - val_loss: 2.2306 - val_accuracy: 0.1765\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.8722\n",
      "Epoch 50: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6571 - accuracy: 0.8722 - val_loss: 2.3553 - val_accuracy: 0.2353\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.8195\n",
      "Epoch 51: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.6594 - accuracy: 0.8195 - val_loss: 2.3235 - val_accuracy: 0.2353\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.8947\n",
      "Epoch 52: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5927 - accuracy: 0.8947 - val_loss: 2.2728 - val_accuracy: 0.2647\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.9098\n",
      "Epoch 53: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.5841 - accuracy: 0.9098 - val_loss: 2.2972 - val_accuracy: 0.2647\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.9098\n",
      "Epoch 54: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5615 - accuracy: 0.9098 - val_loss: 2.3908 - val_accuracy: 0.2941\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.9023\n",
      "Epoch 55: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5605 - accuracy: 0.9023 - val_loss: 2.3741 - val_accuracy: 0.2647\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.9023\n",
      "Epoch 56: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5525 - accuracy: 0.9023 - val_loss: 2.4029 - val_accuracy: 0.2647\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8797\n",
      "Epoch 57: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5424 - accuracy: 0.8797 - val_loss: 2.4052 - val_accuracy: 0.2941\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.9323\n",
      "Epoch 58: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4746 - accuracy: 0.9323 - val_loss: 2.4799 - val_accuracy: 0.2647\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8722\n",
      "Epoch 59: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5463 - accuracy: 0.8722 - val_loss: 2.3664 - val_accuracy: 0.2941\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.9248\n",
      "Epoch 60: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4703 - accuracy: 0.9248 - val_loss: 2.4319 - val_accuracy: 0.2059\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8947\n",
      "Epoch 61: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5069 - accuracy: 0.8947 - val_loss: 2.4673 - val_accuracy: 0.3235\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.8797\n",
      "Epoch 62: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4676 - accuracy: 0.8797 - val_loss: 2.4229 - val_accuracy: 0.3235\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.9173\n",
      "Epoch 63: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4233 - accuracy: 0.9173 - val_loss: 2.4113 - val_accuracy: 0.2941\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.9098\n",
      "Epoch 64: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4505 - accuracy: 0.9098 - val_loss: 2.3929 - val_accuracy: 0.3235\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.9248\n",
      "Epoch 65: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4261 - accuracy: 0.9248 - val_loss: 2.4613 - val_accuracy: 0.3235\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.9173\n",
      "Epoch 66: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4006 - accuracy: 0.9173 - val_loss: 2.5181 - val_accuracy: 0.3235\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.9023\n",
      "Epoch 67: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4235 - accuracy: 0.9023 - val_loss: 2.4628 - val_accuracy: 0.2941\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9323\n",
      "Epoch 68: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3838 - accuracy: 0.9323 - val_loss: 2.4461 - val_accuracy: 0.2941\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.9323\n",
      "Epoch 69: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.3948 - accuracy: 0.9323 - val_loss: 2.4778 - val_accuracy: 0.3235\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9323\n",
      "Epoch 70: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3742 - accuracy: 0.9323 - val_loss: 2.5474 - val_accuracy: 0.3529\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9248\n",
      "Epoch 71: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3570 - accuracy: 0.9248 - val_loss: 2.5681 - val_accuracy: 0.3235\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.9323\n",
      "Epoch 72: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3482 - accuracy: 0.9323 - val_loss: 2.5904 - val_accuracy: 0.3235\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9323\n",
      "Epoch 73: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3346 - accuracy: 0.9323 - val_loss: 2.5863 - val_accuracy: 0.3235\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9323\n",
      "Epoch 74: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3288 - accuracy: 0.9323 - val_loss: 2.5843 - val_accuracy: 0.3235\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9323\n",
      "Epoch 75: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3182 - accuracy: 0.9323 - val_loss: 2.6054 - val_accuracy: 0.2941\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9323\n",
      "Epoch 76: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3132 - accuracy: 0.9323 - val_loss: 2.6191 - val_accuracy: 0.2941\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9323\n",
      "Epoch 77: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.3092 - accuracy: 0.9323 - val_loss: 2.6153 - val_accuracy: 0.2647\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9398\n",
      "Epoch 78: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2954 - accuracy: 0.9398 - val_loss: 2.6234 - val_accuracy: 0.2941\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.9398\n",
      "Epoch 79: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2874 - accuracy: 0.9398 - val_loss: 2.6340 - val_accuracy: 0.3235\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9398\n",
      "Epoch 80: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.2869 - accuracy: 0.9398 - val_loss: 2.6492 - val_accuracy: 0.3235\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.9398\n",
      "Epoch 81: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2791 - accuracy: 0.9398 - val_loss: 2.6674 - val_accuracy: 0.2941\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9398\n",
      "Epoch 82: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2679 - accuracy: 0.9398 - val_loss: 2.6840 - val_accuracy: 0.2941\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9398\n",
      "Epoch 83: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2622 - accuracy: 0.9398 - val_loss: 2.7037 - val_accuracy: 0.2941\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9398\n",
      "Epoch 84: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2583 - accuracy: 0.9398 - val_loss: 2.7289 - val_accuracy: 0.2941\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9474\n",
      "Epoch 85: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2499 - accuracy: 0.9474 - val_loss: 2.7515 - val_accuracy: 0.2941\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9474\n",
      "Epoch 86: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2393 - accuracy: 0.9474 - val_loss: 2.7633 - val_accuracy: 0.2941\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9474\n",
      "Epoch 87: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2312 - accuracy: 0.9474 - val_loss: 2.7771 - val_accuracy: 0.2941\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9474\n",
      "Epoch 88: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2279 - accuracy: 0.9474 - val_loss: 2.7971 - val_accuracy: 0.2941\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9474\n",
      "Epoch 89: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2219 - accuracy: 0.9474 - val_loss: 2.8169 - val_accuracy: 0.2941\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9474\n",
      "Epoch 90: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2135 - accuracy: 0.9474 - val_loss: 2.8545 - val_accuracy: 0.2647\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9549\n",
      "Epoch 91: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2067 - accuracy: 0.9549 - val_loss: 2.8874 - val_accuracy: 0.2647\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9549\n",
      "Epoch 92: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2027 - accuracy: 0.9549 - val_loss: 2.8899 - val_accuracy: 0.2647\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9549\n",
      "Epoch 93: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1948 - accuracy: 0.9549 - val_loss: 2.9026 - val_accuracy: 0.2647\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9549\n",
      "Epoch 94: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1899 - accuracy: 0.9549 - val_loss: 2.9296 - val_accuracy: 0.2941\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9549\n",
      "Epoch 95: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1850 - accuracy: 0.9549 - val_loss: 2.9581 - val_accuracy: 0.2941\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9624\n",
      "Epoch 96: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1814 - accuracy: 0.9624 - val_loss: 2.9777 - val_accuracy: 0.2941\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9549\n",
      "Epoch 97: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1750 - accuracy: 0.9549 - val_loss: 3.0070 - val_accuracy: 0.2941\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9549\n",
      "Epoch 98: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1708 - accuracy: 0.9549 - val_loss: 3.0403 - val_accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9624\n",
      "Epoch 99: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1663 - accuracy: 0.9624 - val_loss: 3.0475 - val_accuracy: 0.2941\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9624\n",
      "Epoch 100: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1618 - accuracy: 0.9624 - val_loss: 3.0489 - val_accuracy: 0.2647\n",
      "Training completed in time:  0:00:42.935128\n",
      "Training Accuracy:  0.9624060392379761\n",
      "Testing Accuracy:  0.2647058963775635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional , Input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a function to extract MFCC features from audio files\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    return mfccs_processed\n",
    "\n",
    "# Define the dataset directory and the labels\n",
    "data_dir = '/content/drive/MyDrive/New folder/T5/sounds final'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Encode the labels to integers\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(64))\n",
    "#model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPSMHvMm3Y99"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
