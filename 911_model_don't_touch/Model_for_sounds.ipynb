{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozqsc-u2GaWM",
    "outputId": "bd6a21f1-4702-41e4-b480-c39859f7b764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WczrEMtAy5Dm",
    "outputId": "0bc6e5c7-f1bc-4ea2-bb97-8e1d959d41bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 3s 276ms/step - loss: 1.3853 - accuracy: 0.2605 - val_loss: 1.4031 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 1.3804 - accuracy: 0.2857 - val_loss: 1.4218 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 1.3760 - accuracy: 0.2605 - val_loss: 1.4339 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 1.3686 - accuracy: 0.2773 - val_loss: 1.4740 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 1.3684 - accuracy: 0.2773 - val_loss: 1.5728 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 1.3623 - accuracy: 0.2941 - val_loss: 1.4750 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 1.3556 - accuracy: 0.3193 - val_loss: 1.4655 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 1.3448 - accuracy: 0.3109 - val_loss: 1.4986 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.3216 - accuracy: 0.3025 - val_loss: 1.5498 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2766 - accuracy: 0.4370 - val_loss: 1.5308 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.2210 - accuracy: 0.4454 - val_loss: 2.0589 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1846 - accuracy: 0.4622 - val_loss: 1.6594 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.1845 - accuracy: 0.4454 - val_loss: 1.5324 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1183 - accuracy: 0.4706 - val_loss: 1.9605 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.0871 - accuracy: 0.4874 - val_loss: 1.7420 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.0709 - accuracy: 0.5042 - val_loss: 1.6427 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0375 - accuracy: 0.5210 - val_loss: 1.7781 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.0185 - accuracy: 0.5126 - val_loss: 1.8767 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0341 - accuracy: 0.4958 - val_loss: 2.2917 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0138 - accuracy: 0.5294 - val_loss: 1.5962 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1622 - accuracy: 0.5546 - val_loss: 1.5863 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.9867 - accuracy: 0.5378 - val_loss: 2.1495 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.0328 - accuracy: 0.4958 - val_loss: 2.2166 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1080 - accuracy: 0.4790 - val_loss: 2.8165 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0661 - accuracy: 0.5042 - val_loss: 2.1401 - val_accuracy: 0.2857\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.9705 - accuracy: 0.5630 - val_loss: 1.5650 - val_accuracy: 0.4286\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0456 - accuracy: 0.4538 - val_loss: 1.5799 - val_accuracy: 0.4286\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.9451 - accuracy: 0.6387 - val_loss: 1.7417 - val_accuracy: 0.4286\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.9105 - accuracy: 0.6555 - val_loss: 2.0259 - val_accuracy: 0.4286\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.8907 - accuracy: 0.6471 - val_loss: 1.9873 - val_accuracy: 0.3571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8678 - accuracy: 0.6387 - val_loss: 2.0969 - val_accuracy: 0.3571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8264 - accuracy: 0.6723 - val_loss: 2.1420 - val_accuracy: 0.3571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.8081 - accuracy: 0.6975 - val_loss: 2.1857 - val_accuracy: 0.4286\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7851 - accuracy: 0.7143 - val_loss: 2.3962 - val_accuracy: 0.3571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7750 - accuracy: 0.7143 - val_loss: 2.3550 - val_accuracy: 0.3571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7442 - accuracy: 0.7647 - val_loss: 2.2575 - val_accuracy: 0.4286\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7406 - accuracy: 0.7647 - val_loss: 2.4556 - val_accuracy: 0.2857\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6697 - accuracy: 0.8067 - val_loss: 2.4286 - val_accuracy: 0.3571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6569 - accuracy: 0.7983 - val_loss: 2.1182 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.6171 - accuracy: 0.8151 - val_loss: 2.1269 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.5754 - accuracy: 0.8403 - val_loss: 2.2291 - val_accuracy: 0.4286\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.5455 - accuracy: 0.8487 - val_loss: 2.4704 - val_accuracy: 0.4286\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.5149 - accuracy: 0.8571 - val_loss: 2.6238 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.5955 - accuracy: 0.7983 - val_loss: 3.3319 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.6859 - accuracy: 0.7815 - val_loss: 2.5012 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6906 - accuracy: 0.7395 - val_loss: 3.8012 - val_accuracy: 0.2857\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.6858 - accuracy: 0.7479 - val_loss: 3.5989 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.6915 - accuracy: 0.7731 - val_loss: 2.6977 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.7174 - accuracy: 0.7563 - val_loss: 3.1598 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6222 - accuracy: 0.7647 - val_loss: 3.3393 - val_accuracy: 0.3571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7062 - accuracy: 0.7227 - val_loss: 3.3409 - val_accuracy: 0.2857\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7161 - accuracy: 0.7563 - val_loss: 2.3949 - val_accuracy: 0.3571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7356 - accuracy: 0.7563 - val_loss: 2.5658 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.7520 - accuracy: 0.7563 - val_loss: 2.2033 - val_accuracy: 0.2857\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7432 - accuracy: 0.7563 - val_loss: 2.0609 - val_accuracy: 0.4286\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.6346 - accuracy: 0.7983 - val_loss: 2.2974 - val_accuracy: 0.4286\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.6569 - accuracy: 0.7899 - val_loss: 2.2889 - val_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5493 - accuracy: 0.8403 - val_loss: 3.0034 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.5404 - accuracy: 0.8403 - val_loss: 3.7175 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6823 - accuracy: 0.7983 - val_loss: 3.1669 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5718 - accuracy: 0.8403 - val_loss: 2.5158 - val_accuracy: 0.2857\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.6216 - accuracy: 0.8151 - val_loss: 2.5147 - val_accuracy: 0.2857\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5423 - accuracy: 0.8403 - val_loss: 2.3700 - val_accuracy: 0.3571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5439 - accuracy: 0.8403 - val_loss: 3.3972 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.6717 - accuracy: 0.7647 - val_loss: 4.1093 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7823 - accuracy: 0.7395 - val_loss: 4.0644 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.9755 - accuracy: 0.7059 - val_loss: 3.9348 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.9059 - accuracy: 0.7143 - val_loss: 3.9697 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.0174 - accuracy: 0.6723 - val_loss: 3.7864 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9586 - accuracy: 0.6723 - val_loss: 3.5864 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.9426 - accuracy: 0.6807 - val_loss: 3.4394 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.8960 - accuracy: 0.6891 - val_loss: 3.2194 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8403 - accuracy: 0.6975 - val_loss: 3.0225 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8282 - accuracy: 0.6975 - val_loss: 2.8555 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.8206 - accuracy: 0.6975 - val_loss: 2.7325 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8206 - accuracy: 0.6975 - val_loss: 2.6351 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8177 - accuracy: 0.6975 - val_loss: 2.5746 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8052 - accuracy: 0.7059 - val_loss: 2.5108 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.8028 - accuracy: 0.7059 - val_loss: 2.4901 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.8408 - accuracy: 0.6723 - val_loss: 2.6131 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.1880 - accuracy: 0.5210 - val_loss: 2.0889 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.4899 - accuracy: 0.3613 - val_loss: 1.8700 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.4049 - accuracy: 0.3445 - val_loss: 1.5886 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.3136 - accuracy: 0.3445 - val_loss: 1.4416 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 1.2949 - accuracy: 0.3361 - val_loss: 1.4005 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 1.2931 - accuracy: 0.3277 - val_loss: 1.4422 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 1.2992 - accuracy: 0.3025 - val_loss: 1.4916 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.2978 - accuracy: 0.3109 - val_loss: 1.5021 - val_accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 1.2894 - accuracy: 0.3613 - val_loss: 1.5076 - val_accuracy: 0.2143\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 1.2803 - accuracy: 0.3445 - val_loss: 1.5037 - val_accuracy: 0.2143\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 1.2765 - accuracy: 0.3445 - val_loss: 1.4878 - val_accuracy: 0.2143\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.2599 - accuracy: 0.3529 - val_loss: 1.4674 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2608 - accuracy: 0.3193 - val_loss: 1.4637 - val_accuracy: 0.2143\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2597 - accuracy: 0.3529 - val_loss: 1.5031 - val_accuracy: 0.2143\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.2576 - accuracy: 0.3529 - val_loss: 1.7147 - val_accuracy: 0.2143\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2580 - accuracy: 0.3529 - val_loss: 1.7465 - val_accuracy: 0.2143\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2579 - accuracy: 0.3529 - val_loss: 1.7328 - val_accuracy: 0.2143\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.2404 - accuracy: 0.3613 - val_loss: 1.7251 - val_accuracy: 0.2143\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2323 - accuracy: 0.3782 - val_loss: 1.7366 - val_accuracy: 0.2143\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.2060 - accuracy: 0.3445 - val_loss: 1.8221 - val_accuracy: 0.1429\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6490 - accuracy: 0.2353\n",
      "Test accuracy: 23.53%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Conv1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import librosa\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "data_dir = '/content/drive/MyDrive/New folder/T5/sounds final'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(40,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCviXBZo_Nqy",
    "outputId": "bdcaba61-a009-4ff9-a5ad-e8907b418271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128, 256)          33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 256)          0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128, 192)          49344     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 192)          0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128, 128)          24704     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128, 64)           8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128, 32)           2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128, 16)           528       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128, 8)            136       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                18688     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137020 (535.23 KB)\n",
      "Trainable params: 137020 (535.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 28.7129%\n",
      "Epoch 1/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3863 - accuracy: 0.2300\n",
      "Epoch 1: val_loss improved from inf to 1.38789, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 1.3863 - accuracy: 0.2300 - val_loss: 1.3879 - val_accuracy: 0.1584\n",
      "Epoch 2/400\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3854 - accuracy: 0.3008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.3855 - accuracy: 0.2900\n",
      "Epoch 2: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3855 - accuracy: 0.2900 - val_loss: 1.3890 - val_accuracy: 0.1584\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3849 - accuracy: 0.2900\n",
      "Epoch 3: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3849 - accuracy: 0.2900 - val_loss: 1.3908 - val_accuracy: 0.1584\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3839 - accuracy: 0.2900\n",
      "Epoch 4: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3839 - accuracy: 0.2900 - val_loss: 1.3925 - val_accuracy: 0.1584\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3834 - accuracy: 0.2900\n",
      "Epoch 5: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3834 - accuracy: 0.2900 - val_loss: 1.3951 - val_accuracy: 0.1584\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3828 - accuracy: 0.2900\n",
      "Epoch 6: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.3828 - accuracy: 0.2900 - val_loss: 1.3991 - val_accuracy: 0.1584\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3824 - accuracy: 0.2900\n",
      "Epoch 7: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3824 - accuracy: 0.2900 - val_loss: 1.4044 - val_accuracy: 0.1584\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3818 - accuracy: 0.2900\n",
      "Epoch 8: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3818 - accuracy: 0.2900 - val_loss: 1.4098 - val_accuracy: 0.1584\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3815 - accuracy: 0.2900\n",
      "Epoch 9: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3815 - accuracy: 0.2900 - val_loss: 1.4132 - val_accuracy: 0.1584\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3812 - accuracy: 0.2900\n",
      "Epoch 10: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3812 - accuracy: 0.2900 - val_loss: 1.4151 - val_accuracy: 0.1584\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3806 - accuracy: 0.2900\n",
      "Epoch 11: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3806 - accuracy: 0.2900 - val_loss: 1.4142 - val_accuracy: 0.1584\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3791 - accuracy: 0.2900\n",
      "Epoch 12: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.3791 - accuracy: 0.2900 - val_loss: 1.4144 - val_accuracy: 0.1584\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3764 - accuracy: 0.2900\n",
      "Epoch 13: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.3764 - accuracy: 0.2900 - val_loss: 1.4188 - val_accuracy: 0.1584\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3718 - accuracy: 0.2900\n",
      "Epoch 14: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.3718 - accuracy: 0.2900 - val_loss: 1.4184 - val_accuracy: 0.1584\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3661 - accuracy: 0.2900\n",
      "Epoch 15: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3661 - accuracy: 0.2900 - val_loss: 1.4199 - val_accuracy: 0.1584\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3586 - accuracy: 0.2900\n",
      "Epoch 16: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3586 - accuracy: 0.2900 - val_loss: 1.4011 - val_accuracy: 0.1584\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3527 - accuracy: 0.3025\n",
      "Epoch 17: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3527 - accuracy: 0.3025 - val_loss: 1.3969 - val_accuracy: 0.2673\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3387 - accuracy: 0.3200\n",
      "Epoch 18: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3387 - accuracy: 0.3200 - val_loss: 1.4638 - val_accuracy: 0.2673\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3421 - accuracy: 0.2850\n",
      "Epoch 19: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.3421 - accuracy: 0.2850 - val_loss: 1.4134 - val_accuracy: 0.3168\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.3125\n",
      "Epoch 20: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3243 - accuracy: 0.3125 - val_loss: 1.3989 - val_accuracy: 0.3366\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3155 - accuracy: 0.3300\n",
      "Epoch 21: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.3155 - accuracy: 0.3300 - val_loss: 1.4428 - val_accuracy: 0.3366\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3185 - accuracy: 0.3075\n",
      "Epoch 22: val_loss did not improve from 1.38789\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3185 - accuracy: 0.3075 - val_loss: 1.4228 - val_accuracy: 0.3366\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2938 - accuracy: 0.3350\n",
      "Epoch 23: val_loss improved from 1.38789 to 1.37320, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.2938 - accuracy: 0.3350 - val_loss: 1.3732 - val_accuracy: 0.3267\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3139 - accuracy: 0.3225\n",
      "Epoch 24: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3139 - accuracy: 0.3225 - val_loss: 1.3782 - val_accuracy: 0.3366\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2914 - accuracy: 0.3275\n",
      "Epoch 25: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.2914 - accuracy: 0.3275 - val_loss: 1.4571 - val_accuracy: 0.3366\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2659 - accuracy: 0.3350\n",
      "Epoch 26: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.2659 - accuracy: 0.3350 - val_loss: 1.4758 - val_accuracy: 0.3366\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2511 - accuracy: 0.3450\n",
      "Epoch 27: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.2511 - accuracy: 0.3450 - val_loss: 1.4026 - val_accuracy: 0.3465\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.3575\n",
      "Epoch 28: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.2526 - accuracy: 0.3575 - val_loss: 1.4072 - val_accuracy: 0.3762\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2388 - accuracy: 0.3650\n",
      "Epoch 29: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.2388 - accuracy: 0.3650 - val_loss: 1.5117 - val_accuracy: 0.3267\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.3475\n",
      "Epoch 30: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.2249 - accuracy: 0.3475 - val_loss: 1.4455 - val_accuracy: 0.3168\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2048 - accuracy: 0.3975\n",
      "Epoch 31: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.2048 - accuracy: 0.3975 - val_loss: 1.4565 - val_accuracy: 0.3069\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1886 - accuracy: 0.3975\n",
      "Epoch 32: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.1886 - accuracy: 0.3975 - val_loss: 1.5693 - val_accuracy: 0.3564\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1876 - accuracy: 0.4075\n",
      "Epoch 33: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 1.1876 - accuracy: 0.4075 - val_loss: 1.4690 - val_accuracy: 0.2475\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.4450\n",
      "Epoch 34: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.1682 - accuracy: 0.4450 - val_loss: 1.5807 - val_accuracy: 0.3267\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1628 - accuracy: 0.4375\n",
      "Epoch 35: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.1628 - accuracy: 0.4375 - val_loss: 1.4843 - val_accuracy: 0.2475\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.4350\n",
      "Epoch 36: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.1504 - accuracy: 0.4350 - val_loss: 1.5450 - val_accuracy: 0.3366\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1268 - accuracy: 0.4500\n",
      "Epoch 37: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.1268 - accuracy: 0.4500 - val_loss: 1.5081 - val_accuracy: 0.2673\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1153 - accuracy: 0.4625\n",
      "Epoch 38: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 1.1153 - accuracy: 0.4625 - val_loss: 1.5570 - val_accuracy: 0.3564\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1208 - accuracy: 0.4650\n",
      "Epoch 39: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.1208 - accuracy: 0.4650 - val_loss: 1.5099 - val_accuracy: 0.2574\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1369 - accuracy: 0.4425\n",
      "Epoch 40: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.1369 - accuracy: 0.4425 - val_loss: 1.4902 - val_accuracy: 0.4059\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1200 - accuracy: 0.4475\n",
      "Epoch 41: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.1200 - accuracy: 0.4475 - val_loss: 1.4600 - val_accuracy: 0.3663\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0803 - accuracy: 0.5300\n",
      "Epoch 42: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.0803 - accuracy: 0.5300 - val_loss: 1.4806 - val_accuracy: 0.2574\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1014 - accuracy: 0.4875\n",
      "Epoch 43: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.1014 - accuracy: 0.4875 - val_loss: 1.4510 - val_accuracy: 0.4158\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1272 - accuracy: 0.4300\n",
      "Epoch 44: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.1272 - accuracy: 0.4300 - val_loss: 1.4205 - val_accuracy: 0.4059\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0760 - accuracy: 0.4950\n",
      "Epoch 45: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.0760 - accuracy: 0.4950 - val_loss: 1.5585 - val_accuracy: 0.2277\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1301 - accuracy: 0.4675\n",
      "Epoch 46: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.1301 - accuracy: 0.4675 - val_loss: 1.4351 - val_accuracy: 0.3762\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0339 - accuracy: 0.5050\n",
      "Epoch 47: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.0339 - accuracy: 0.5050 - val_loss: 1.4556 - val_accuracy: 0.3861\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.5650\n",
      "Epoch 48: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9759 - accuracy: 0.5650 - val_loss: 1.6822 - val_accuracy: 0.2574\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0373 - accuracy: 0.5375\n",
      "Epoch 49: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.0373 - accuracy: 0.5375 - val_loss: 1.4931 - val_accuracy: 0.3663\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.5200\n",
      "Epoch 50: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9894 - accuracy: 0.5200 - val_loss: 1.4736 - val_accuracy: 0.3861\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.5850\n",
      "Epoch 51: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9569 - accuracy: 0.5850 - val_loss: 1.5826 - val_accuracy: 0.3168\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.5800\n",
      "Epoch 52: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.9514 - accuracy: 0.5800 - val_loss: 1.5531 - val_accuracy: 0.3564\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.5475\n",
      "Epoch 53: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9489 - accuracy: 0.5475 - val_loss: 1.6020 - val_accuracy: 0.3564\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9197 - accuracy: 0.6100\n",
      "Epoch 54: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.9197 - accuracy: 0.6100 - val_loss: 1.6049 - val_accuracy: 0.3663\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.5800\n",
      "Epoch 55: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.9072 - accuracy: 0.5800 - val_loss: 1.5576 - val_accuracy: 0.3762\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8902 - accuracy: 0.5950\n",
      "Epoch 56: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.8902 - accuracy: 0.5950 - val_loss: 1.5634 - val_accuracy: 0.3762\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.5925\n",
      "Epoch 57: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9085 - accuracy: 0.5925 - val_loss: 1.4816 - val_accuracy: 0.3960\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9020 - accuracy: 0.5700\n",
      "Epoch 58: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9020 - accuracy: 0.5700 - val_loss: 1.5710 - val_accuracy: 0.3861\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.6175\n",
      "Epoch 59: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.8749 - accuracy: 0.6175 - val_loss: 1.5284 - val_accuracy: 0.4455\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8625 - accuracy: 0.5925\n",
      "Epoch 60: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.8625 - accuracy: 0.5925 - val_loss: 1.4953 - val_accuracy: 0.4554\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8731 - accuracy: 0.6325\n",
      "Epoch 61: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.8731 - accuracy: 0.6325 - val_loss: 1.4994 - val_accuracy: 0.4455\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8704 - accuracy: 0.6125\n",
      "Epoch 62: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.8704 - accuracy: 0.6125 - val_loss: 1.4926 - val_accuracy: 0.4554\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8532 - accuracy: 0.6125\n",
      "Epoch 63: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.8532 - accuracy: 0.6125 - val_loss: 1.5755 - val_accuracy: 0.3960\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.6500\n",
      "Epoch 64: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8598 - accuracy: 0.6500 - val_loss: 1.4656 - val_accuracy: 0.4455\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.6075\n",
      "Epoch 65: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.8456 - accuracy: 0.6075 - val_loss: 1.6073 - val_accuracy: 0.4158\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8239 - accuracy: 0.6225\n",
      "Epoch 66: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.8239 - accuracy: 0.6225 - val_loss: 1.4845 - val_accuracy: 0.4455\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.6375\n",
      "Epoch 67: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7710 - accuracy: 0.6375 - val_loss: 1.5406 - val_accuracy: 0.4257\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6650\n",
      "Epoch 68: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7607 - accuracy: 0.6650 - val_loss: 1.5659 - val_accuracy: 0.4257\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.6875\n",
      "Epoch 69: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.7542 - accuracy: 0.6875 - val_loss: 1.5578 - val_accuracy: 0.4356\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.6875\n",
      "Epoch 70: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.7480 - accuracy: 0.6875 - val_loss: 1.6801 - val_accuracy: 0.4059\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.6750\n",
      "Epoch 71: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7779 - accuracy: 0.6750 - val_loss: 1.5043 - val_accuracy: 0.4257\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8345 - accuracy: 0.6300\n",
      "Epoch 72: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.8345 - accuracy: 0.6300 - val_loss: 1.6477 - val_accuracy: 0.4158\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8260 - accuracy: 0.6550\n",
      "Epoch 73: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.8260 - accuracy: 0.6550 - val_loss: 1.5658 - val_accuracy: 0.4158\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.6925\n",
      "Epoch 74: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7342 - accuracy: 0.6925 - val_loss: 1.5819 - val_accuracy: 0.4455\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.6525\n",
      "Epoch 75: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7971 - accuracy: 0.6525 - val_loss: 1.8436 - val_accuracy: 0.3465\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.5925\n",
      "Epoch 76: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.9238 - accuracy: 0.5925 - val_loss: 1.4677 - val_accuracy: 0.4455\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9118 - accuracy: 0.5725\n",
      "Epoch 77: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.9118 - accuracy: 0.5725 - val_loss: 1.3839 - val_accuracy: 0.4554\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.6800\n",
      "Epoch 78: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7802 - accuracy: 0.6800 - val_loss: 1.7924 - val_accuracy: 0.3465\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.5825\n",
      "Epoch 79: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9192 - accuracy: 0.5825 - val_loss: 1.4439 - val_accuracy: 0.4257\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.6450\n",
      "Epoch 80: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.7994 - accuracy: 0.6450 - val_loss: 1.5066 - val_accuracy: 0.4158\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.6875\n",
      "Epoch 81: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7416 - accuracy: 0.6875 - val_loss: 1.7075 - val_accuracy: 0.4158\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7773 - accuracy: 0.6525\n",
      "Epoch 82: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7773 - accuracy: 0.6525 - val_loss: 1.5536 - val_accuracy: 0.4158\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8094 - accuracy: 0.6350\n",
      "Epoch 83: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.8094 - accuracy: 0.6350 - val_loss: 1.5297 - val_accuracy: 0.4059\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7050\n",
      "Epoch 84: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7205 - accuracy: 0.7050 - val_loss: 1.7569 - val_accuracy: 0.4059\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7936 - accuracy: 0.6450\n",
      "Epoch 85: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7936 - accuracy: 0.6450 - val_loss: 1.5218 - val_accuracy: 0.4356\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7892 - accuracy: 0.6600\n",
      "Epoch 86: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7892 - accuracy: 0.6600 - val_loss: 1.5247 - val_accuracy: 0.4653\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.6875\n",
      "Epoch 87: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7207 - accuracy: 0.6875 - val_loss: 1.6993 - val_accuracy: 0.3960\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7277 - accuracy: 0.6950\n",
      "Epoch 88: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.7277 - accuracy: 0.6950 - val_loss: 1.5981 - val_accuracy: 0.4455\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.7225\n",
      "Epoch 89: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6912 - accuracy: 0.7225 - val_loss: 1.5583 - val_accuracy: 0.4851\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.7375\n",
      "Epoch 90: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6634 - accuracy: 0.7375 - val_loss: 1.5829 - val_accuracy: 0.4455\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.7275\n",
      "Epoch 91: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6659 - accuracy: 0.7275 - val_loss: 1.5719 - val_accuracy: 0.4455\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.7300\n",
      "Epoch 92: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6554 - accuracy: 0.7300 - val_loss: 1.6089 - val_accuracy: 0.4752\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7475\n",
      "Epoch 93: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.6414 - accuracy: 0.7475 - val_loss: 1.7159 - val_accuracy: 0.4356\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6389 - accuracy: 0.7675\n",
      "Epoch 94: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.6389 - accuracy: 0.7675 - val_loss: 1.6473 - val_accuracy: 0.4554\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7350\n",
      "Epoch 95: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6352 - accuracy: 0.7350 - val_loss: 1.6088 - val_accuracy: 0.4554\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.7625\n",
      "Epoch 96: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.6189 - accuracy: 0.7625 - val_loss: 1.6820 - val_accuracy: 0.4554\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7400\n",
      "Epoch 97: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.6121 - accuracy: 0.7400 - val_loss: 1.6474 - val_accuracy: 0.4752\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.7475\n",
      "Epoch 98: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6189 - accuracy: 0.7475 - val_loss: 1.6970 - val_accuracy: 0.4752\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.7650\n",
      "Epoch 99: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6275 - accuracy: 0.7650 - val_loss: 1.6363 - val_accuracy: 0.5050\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.7525\n",
      "Epoch 100: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6601 - accuracy: 0.7525 - val_loss: 1.6402 - val_accuracy: 0.4356\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.7225\n",
      "Epoch 101: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.6993 - accuracy: 0.7225 - val_loss: 1.5729 - val_accuracy: 0.4851\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.7575\n",
      "Epoch 102: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6472 - accuracy: 0.7575 - val_loss: 1.5802 - val_accuracy: 0.5248\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.7725\n",
      "Epoch 103: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6289 - accuracy: 0.7725 - val_loss: 1.8016 - val_accuracy: 0.4158\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7350\n",
      "Epoch 104: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6606 - accuracy: 0.7350 - val_loss: 1.8533 - val_accuracy: 0.4158\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7350\n",
      "Epoch 105: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6098 - accuracy: 0.7350 - val_loss: 1.7210 - val_accuracy: 0.4851\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.7900\n",
      "Epoch 106: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5993 - accuracy: 0.7900 - val_loss: 1.7613 - val_accuracy: 0.4257\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.7225\n",
      "Epoch 107: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6908 - accuracy: 0.7225 - val_loss: 1.6294 - val_accuracy: 0.4950\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.7600\n",
      "Epoch 108: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6370 - accuracy: 0.7600 - val_loss: 1.6760 - val_accuracy: 0.4851\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.7900\n",
      "Epoch 109: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6031 - accuracy: 0.7900 - val_loss: 1.8303 - val_accuracy: 0.4554\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.7750\n",
      "Epoch 110: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5918 - accuracy: 0.7750 - val_loss: 1.7641 - val_accuracy: 0.4653\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6116 - accuracy: 0.7900\n",
      "Epoch 111: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.6116 - accuracy: 0.7900 - val_loss: 1.8123 - val_accuracy: 0.4653\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.8050\n",
      "Epoch 112: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.5690 - accuracy: 0.8050 - val_loss: 1.9825 - val_accuracy: 0.4158\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.7775\n",
      "Epoch 113: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6104 - accuracy: 0.7775 - val_loss: 1.7250 - val_accuracy: 0.4950\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.7775\n",
      "Epoch 114: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5820 - accuracy: 0.7775 - val_loss: 1.7469 - val_accuracy: 0.4752\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8050\n",
      "Epoch 115: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.5502 - accuracy: 0.8050 - val_loss: 1.7462 - val_accuracy: 0.4653\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.7875\n",
      "Epoch 116: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5591 - accuracy: 0.7875 - val_loss: 1.7057 - val_accuracy: 0.4851\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.8000\n",
      "Epoch 117: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5366 - accuracy: 0.8000 - val_loss: 1.7636 - val_accuracy: 0.4554\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.8150\n",
      "Epoch 118: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5282 - accuracy: 0.8150 - val_loss: 1.8476 - val_accuracy: 0.4554\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8225\n",
      "Epoch 119: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.5078 - accuracy: 0.8225 - val_loss: 1.7856 - val_accuracy: 0.4653\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8125\n",
      "Epoch 120: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.5185 - accuracy: 0.8125 - val_loss: 1.7812 - val_accuracy: 0.4653\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.8400\n",
      "Epoch 121: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.4942 - accuracy: 0.8400 - val_loss: 1.7521 - val_accuracy: 0.4752\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8400\n",
      "Epoch 122: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4915 - accuracy: 0.8400 - val_loss: 1.7824 - val_accuracy: 0.4752\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.8200\n",
      "Epoch 123: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4917 - accuracy: 0.8200 - val_loss: 1.8321 - val_accuracy: 0.4752\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8450\n",
      "Epoch 124: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4725 - accuracy: 0.8450 - val_loss: 1.8934 - val_accuracy: 0.4851\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.8325\n",
      "Epoch 125: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4781 - accuracy: 0.8325 - val_loss: 1.7568 - val_accuracy: 0.5149\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8450\n",
      "Epoch 126: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4849 - accuracy: 0.8450 - val_loss: 1.7762 - val_accuracy: 0.4950\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8400\n",
      "Epoch 127: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4655 - accuracy: 0.8400 - val_loss: 1.8632 - val_accuracy: 0.4653\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8425\n",
      "Epoch 128: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.4674 - accuracy: 0.8425 - val_loss: 1.8721 - val_accuracy: 0.5050\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.8100\n",
      "Epoch 129: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5285 - accuracy: 0.8100 - val_loss: 1.8474 - val_accuracy: 0.4851\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8425\n",
      "Epoch 130: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4641 - accuracy: 0.8425 - val_loss: 1.7963 - val_accuracy: 0.5050\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8500\n",
      "Epoch 131: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4742 - accuracy: 0.8500 - val_loss: 1.8853 - val_accuracy: 0.5050\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.8150\n",
      "Epoch 132: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.4993 - accuracy: 0.8150 - val_loss: 1.9036 - val_accuracy: 0.4554\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.8400\n",
      "Epoch 133: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.5048 - accuracy: 0.8400 - val_loss: 1.8248 - val_accuracy: 0.4851\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.8450\n",
      "Epoch 134: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4771 - accuracy: 0.8450 - val_loss: 1.8294 - val_accuracy: 0.4950\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.8400\n",
      "Epoch 135: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4829 - accuracy: 0.8400 - val_loss: 1.9687 - val_accuracy: 0.4455\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8500\n",
      "Epoch 136: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.4426 - accuracy: 0.8500 - val_loss: 1.7965 - val_accuracy: 0.4950\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.8200\n",
      "Epoch 137: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.5133 - accuracy: 0.8200 - val_loss: 1.8838 - val_accuracy: 0.4752\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7850\n",
      "Epoch 138: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5650 - accuracy: 0.7850 - val_loss: 1.7142 - val_accuracy: 0.4752\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.7975\n",
      "Epoch 139: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.5815 - accuracy: 0.7975 - val_loss: 1.9356 - val_accuracy: 0.4554\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.8075\n",
      "Epoch 140: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.5355 - accuracy: 0.8075 - val_loss: 1.8323 - val_accuracy: 0.5050\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7950\n",
      "Epoch 141: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.5652 - accuracy: 0.7950 - val_loss: 1.8503 - val_accuracy: 0.4752\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8050\n",
      "Epoch 142: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.5011 - accuracy: 0.8050 - val_loss: 1.6296 - val_accuracy: 0.5050\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8325\n",
      "Epoch 143: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.4980 - accuracy: 0.8325 - val_loss: 1.6996 - val_accuracy: 0.4950\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8600\n",
      "Epoch 144: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4132 - accuracy: 0.8600 - val_loss: 1.8799 - val_accuracy: 0.4950\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8500\n",
      "Epoch 145: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4921 - accuracy: 0.8500 - val_loss: 1.9237 - val_accuracy: 0.4653\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8600\n",
      "Epoch 146: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.4206 - accuracy: 0.8600 - val_loss: 1.6445 - val_accuracy: 0.5149\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8550\n",
      "Epoch 147: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.4289 - accuracy: 0.8550 - val_loss: 1.6849 - val_accuracy: 0.5050\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.8375\n",
      "Epoch 148: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.4495 - accuracy: 0.8375 - val_loss: 1.7366 - val_accuracy: 0.4752\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8475\n",
      "Epoch 149: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4230 - accuracy: 0.8475 - val_loss: 1.7344 - val_accuracy: 0.4554\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8725\n",
      "Epoch 150: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3918 - accuracy: 0.8725 - val_loss: 1.8848 - val_accuracy: 0.4257\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8600\n",
      "Epoch 151: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.4077 - accuracy: 0.8600 - val_loss: 1.8115 - val_accuracy: 0.4950\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8525\n",
      "Epoch 152: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4390 - accuracy: 0.8525 - val_loss: 1.8792 - val_accuracy: 0.4554\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8575\n",
      "Epoch 153: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.4103 - accuracy: 0.8575 - val_loss: 1.6695 - val_accuracy: 0.5248\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8600\n",
      "Epoch 154: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4167 - accuracy: 0.8600 - val_loss: 1.7803 - val_accuracy: 0.4752\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.8525\n",
      "Epoch 155: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4152 - accuracy: 0.8525 - val_loss: 1.7612 - val_accuracy: 0.4653\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8950\n",
      "Epoch 156: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.3704 - accuracy: 0.8950 - val_loss: 1.8034 - val_accuracy: 0.4950\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8700\n",
      "Epoch 157: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3988 - accuracy: 0.8700 - val_loss: 1.9956 - val_accuracy: 0.4752\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.8450\n",
      "Epoch 158: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.4530 - accuracy: 0.8450 - val_loss: 1.7880 - val_accuracy: 0.5149\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8525\n",
      "Epoch 159: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.4257 - accuracy: 0.8525 - val_loss: 1.8552 - val_accuracy: 0.4950\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8575\n",
      "Epoch 160: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.3945 - accuracy: 0.8575 - val_loss: 1.7125 - val_accuracy: 0.5248\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8750\n",
      "Epoch 161: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3648 - accuracy: 0.8750 - val_loss: 1.7433 - val_accuracy: 0.5248\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8825\n",
      "Epoch 162: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3493 - accuracy: 0.8825 - val_loss: 1.9170 - val_accuracy: 0.4851\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8725\n",
      "Epoch 163: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3777 - accuracy: 0.8725 - val_loss: 1.8049 - val_accuracy: 0.5149\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8675\n",
      "Epoch 164: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3792 - accuracy: 0.8675 - val_loss: 1.8537 - val_accuracy: 0.4851\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8850\n",
      "Epoch 165: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3623 - accuracy: 0.8850 - val_loss: 1.7013 - val_accuracy: 0.4950\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8875\n",
      "Epoch 166: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3547 - accuracy: 0.8875 - val_loss: 1.7994 - val_accuracy: 0.4950\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8875\n",
      "Epoch 167: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3466 - accuracy: 0.8875 - val_loss: 1.7641 - val_accuracy: 0.5347\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8800\n",
      "Epoch 168: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.3388 - accuracy: 0.8800 - val_loss: 1.7804 - val_accuracy: 0.5149\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8850\n",
      "Epoch 169: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3489 - accuracy: 0.8850 - val_loss: 1.8040 - val_accuracy: 0.5248\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8850\n",
      "Epoch 170: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3373 - accuracy: 0.8850 - val_loss: 1.7058 - val_accuracy: 0.4950\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.8900\n",
      "Epoch 171: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3342 - accuracy: 0.8900 - val_loss: 1.8876 - val_accuracy: 0.5149\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.9025\n",
      "Epoch 172: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3207 - accuracy: 0.9025 - val_loss: 1.8024 - val_accuracy: 0.5347\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8950\n",
      "Epoch 173: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3505 - accuracy: 0.8950 - val_loss: 1.8419 - val_accuracy: 0.4950\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.9000\n",
      "Epoch 174: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3344 - accuracy: 0.9000 - val_loss: 1.7510 - val_accuracy: 0.5248\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8950\n",
      "Epoch 175: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3228 - accuracy: 0.8950 - val_loss: 1.7926 - val_accuracy: 0.5248\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8925\n",
      "Epoch 176: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3144 - accuracy: 0.8925 - val_loss: 1.8041 - val_accuracy: 0.5347\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.9125\n",
      "Epoch 177: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3126 - accuracy: 0.9125 - val_loss: 1.8139 - val_accuracy: 0.5446\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8900\n",
      "Epoch 178: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3151 - accuracy: 0.8900 - val_loss: 1.9070 - val_accuracy: 0.5248\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9000\n",
      "Epoch 179: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3357 - accuracy: 0.9000 - val_loss: 1.8161 - val_accuracy: 0.5545\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.8900\n",
      "Epoch 180: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3248 - accuracy: 0.8900 - val_loss: 1.9163 - val_accuracy: 0.5347\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8925\n",
      "Epoch 181: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3309 - accuracy: 0.8925 - val_loss: 1.7225 - val_accuracy: 0.5842\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.9050\n",
      "Epoch 182: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2972 - accuracy: 0.9050 - val_loss: 1.7974 - val_accuracy: 0.5545\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9050\n",
      "Epoch 183: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.3060 - accuracy: 0.9050 - val_loss: 1.7891 - val_accuracy: 0.6040\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.9000\n",
      "Epoch 184: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2963 - accuracy: 0.9000 - val_loss: 1.8742 - val_accuracy: 0.5446\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.9125\n",
      "Epoch 185: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3050 - accuracy: 0.9125 - val_loss: 1.7687 - val_accuracy: 0.6040\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.9225\n",
      "Epoch 186: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2953 - accuracy: 0.9225 - val_loss: 1.6859 - val_accuracy: 0.5842\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.9100\n",
      "Epoch 187: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2806 - accuracy: 0.9100 - val_loss: 1.8081 - val_accuracy: 0.5347\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.9300\n",
      "Epoch 188: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2668 - accuracy: 0.9300 - val_loss: 1.6850 - val_accuracy: 0.5941\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.9150\n",
      "Epoch 189: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2854 - accuracy: 0.9150 - val_loss: 1.8533 - val_accuracy: 0.5446\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.9200\n",
      "Epoch 190: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2847 - accuracy: 0.9200 - val_loss: 1.6531 - val_accuracy: 0.5842\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9200\n",
      "Epoch 191: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2878 - accuracy: 0.9200 - val_loss: 1.7645 - val_accuracy: 0.5644\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.9075\n",
      "Epoch 192: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2916 - accuracy: 0.9075 - val_loss: 1.7803 - val_accuracy: 0.5545\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8975\n",
      "Epoch 193: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3077 - accuracy: 0.8975 - val_loss: 1.8825 - val_accuracy: 0.5446\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8950\n",
      "Epoch 194: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.3417 - accuracy: 0.8950 - val_loss: 1.8039 - val_accuracy: 0.5347\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.9025\n",
      "Epoch 195: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3041 - accuracy: 0.9025 - val_loss: 1.8824 - val_accuracy: 0.5347\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9125\n",
      "Epoch 196: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2795 - accuracy: 0.9125 - val_loss: 1.9625 - val_accuracy: 0.5248\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.9000\n",
      "Epoch 197: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2994 - accuracy: 0.9000 - val_loss: 1.9219 - val_accuracy: 0.5347\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.8900\n",
      "Epoch 198: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3138 - accuracy: 0.8900 - val_loss: 2.0296 - val_accuracy: 0.4950\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.9075\n",
      "Epoch 199: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3024 - accuracy: 0.9075 - val_loss: 1.8627 - val_accuracy: 0.5446\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9050\n",
      "Epoch 200: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2835 - accuracy: 0.9050 - val_loss: 1.9505 - val_accuracy: 0.5347\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.9300\n",
      "Epoch 201: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2819 - accuracy: 0.9300 - val_loss: 1.8774 - val_accuracy: 0.5248\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9250\n",
      "Epoch 202: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2465 - accuracy: 0.9250 - val_loss: 1.8429 - val_accuracy: 0.5545\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.9125\n",
      "Epoch 203: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2634 - accuracy: 0.9125 - val_loss: 1.8501 - val_accuracy: 0.5545\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.9200\n",
      "Epoch 204: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2570 - accuracy: 0.9200 - val_loss: 1.8236 - val_accuracy: 0.5545\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9125\n",
      "Epoch 205: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2650 - accuracy: 0.9125 - val_loss: 1.7877 - val_accuracy: 0.5545\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9050\n",
      "Epoch 206: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2612 - accuracy: 0.9050 - val_loss: 1.9019 - val_accuracy: 0.5248\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9150\n",
      "Epoch 207: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2799 - accuracy: 0.9150 - val_loss: 1.8711 - val_accuracy: 0.5842\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.9100\n",
      "Epoch 208: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2914 - accuracy: 0.9100 - val_loss: 1.9522 - val_accuracy: 0.5149\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9050\n",
      "Epoch 209: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3064 - accuracy: 0.9050 - val_loss: 1.6780 - val_accuracy: 0.5644\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.9225\n",
      "Epoch 210: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2865 - accuracy: 0.9225 - val_loss: 1.8198 - val_accuracy: 0.5743\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9275\n",
      "Epoch 211: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2632 - accuracy: 0.9275 - val_loss: 1.7459 - val_accuracy: 0.6040\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.9125\n",
      "Epoch 212: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2744 - accuracy: 0.9125 - val_loss: 1.8965 - val_accuracy: 0.5446\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.9150\n",
      "Epoch 213: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.2906 - accuracy: 0.9150 - val_loss: 1.8339 - val_accuracy: 0.5842\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9275\n",
      "Epoch 214: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2525 - accuracy: 0.9275 - val_loss: 1.8973 - val_accuracy: 0.5446\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9225\n",
      "Epoch 215: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2626 - accuracy: 0.9225 - val_loss: 1.7444 - val_accuracy: 0.5446\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.9125\n",
      "Epoch 216: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2714 - accuracy: 0.9125 - val_loss: 1.9537 - val_accuracy: 0.5347\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.9100\n",
      "Epoch 217: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2735 - accuracy: 0.9100 - val_loss: 1.8349 - val_accuracy: 0.5644\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8725\n",
      "Epoch 218: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3653 - accuracy: 0.8725 - val_loss: 2.3528 - val_accuracy: 0.4356\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8225\n",
      "Epoch 219: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4807 - accuracy: 0.8225 - val_loss: 1.7717 - val_accuracy: 0.6040\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.7900\n",
      "Epoch 220: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5516 - accuracy: 0.7900 - val_loss: 2.6903 - val_accuracy: 0.3762\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.7700\n",
      "Epoch 221: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6840 - accuracy: 0.7700 - val_loss: 1.9070 - val_accuracy: 0.5941\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.7900\n",
      "Epoch 222: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.5917 - accuracy: 0.7900 - val_loss: 1.8796 - val_accuracy: 0.5149\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.8175\n",
      "Epoch 223: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4493 - accuracy: 0.8175 - val_loss: 1.7430 - val_accuracy: 0.5644\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.8750\n",
      "Epoch 224: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.3233 - accuracy: 0.8750 - val_loss: 1.8338 - val_accuracy: 0.5743\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.8925\n",
      "Epoch 225: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3141 - accuracy: 0.8925 - val_loss: 2.2938 - val_accuracy: 0.4950\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8600\n",
      "Epoch 226: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3810 - accuracy: 0.8600 - val_loss: 1.8149 - val_accuracy: 0.6337\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9050\n",
      "Epoch 227: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2895 - accuracy: 0.9050 - val_loss: 1.6879 - val_accuracy: 0.6040\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8675\n",
      "Epoch 228: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3609 - accuracy: 0.8675 - val_loss: 2.1270 - val_accuracy: 0.4752\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8500\n",
      "Epoch 229: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3906 - accuracy: 0.8500 - val_loss: 1.7624 - val_accuracy: 0.5941\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8825\n",
      "Epoch 230: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.3322 - accuracy: 0.8825 - val_loss: 1.8188 - val_accuracy: 0.6040\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9100\n",
      "Epoch 231: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2612 - accuracy: 0.9100 - val_loss: 2.5582 - val_accuracy: 0.3960\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5402 - accuracy: 0.8075\n",
      "Epoch 232: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.5402 - accuracy: 0.8075 - val_loss: 1.8039 - val_accuracy: 0.5941\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7825\n",
      "Epoch 233: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.5448 - accuracy: 0.7825 - val_loss: 2.0427 - val_accuracy: 0.5050\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8225\n",
      "Epoch 234: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.5621 - accuracy: 0.8225 - val_loss: 1.9069 - val_accuracy: 0.5347\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8700\n",
      "Epoch 235: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3587 - accuracy: 0.8700 - val_loss: 1.6861 - val_accuracy: 0.5842\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.8850\n",
      "Epoch 236: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3379 - accuracy: 0.8850 - val_loss: 1.9861 - val_accuracy: 0.5050\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.8975\n",
      "Epoch 237: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3099 - accuracy: 0.8975 - val_loss: 1.9229 - val_accuracy: 0.5545\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9150\n",
      "Epoch 238: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2797 - accuracy: 0.9150 - val_loss: 1.7104 - val_accuracy: 0.6040\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.9125\n",
      "Epoch 239: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2692 - accuracy: 0.9125 - val_loss: 1.8864 - val_accuracy: 0.4950\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.9025\n",
      "Epoch 240: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2913 - accuracy: 0.9025 - val_loss: 1.6295 - val_accuracy: 0.5347\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8975\n",
      "Epoch 241: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3143 - accuracy: 0.8975 - val_loss: 1.6036 - val_accuracy: 0.5842\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9075\n",
      "Epoch 242: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2778 - accuracy: 0.9075 - val_loss: 1.9191 - val_accuracy: 0.4950\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.9125\n",
      "Epoch 243: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.2990 - accuracy: 0.9125 - val_loss: 1.7608 - val_accuracy: 0.5545\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.8925\n",
      "Epoch 244: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.3050 - accuracy: 0.8925 - val_loss: 1.7257 - val_accuracy: 0.5644\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9200\n",
      "Epoch 245: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2477 - accuracy: 0.9200 - val_loss: 1.8565 - val_accuracy: 0.5347\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9175\n",
      "Epoch 246: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.2726 - accuracy: 0.9175 - val_loss: 1.7022 - val_accuracy: 0.5545\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9000\n",
      "Epoch 247: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2503 - accuracy: 0.9000 - val_loss: 1.7605 - val_accuracy: 0.5842\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9350\n",
      "Epoch 248: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2024 - accuracy: 0.9350 - val_loss: 1.9563 - val_accuracy: 0.5149\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9250\n",
      "Epoch 249: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2454 - accuracy: 0.9250 - val_loss: 1.7917 - val_accuracy: 0.5347\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9300\n",
      "Epoch 250: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2163 - accuracy: 0.9300 - val_loss: 1.7787 - val_accuracy: 0.5545\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9400\n",
      "Epoch 251: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2209 - accuracy: 0.9400 - val_loss: 1.8757 - val_accuracy: 0.5149\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9300\n",
      "Epoch 252: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2354 - accuracy: 0.9300 - val_loss: 1.7262 - val_accuracy: 0.5545\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9300\n",
      "Epoch 253: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2151 - accuracy: 0.9300 - val_loss: 1.6831 - val_accuracy: 0.5545\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9275\n",
      "Epoch 254: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.2070 - accuracy: 0.9275 - val_loss: 1.9704 - val_accuracy: 0.5050\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.9375\n",
      "Epoch 255: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2101 - accuracy: 0.9375 - val_loss: 1.8635 - val_accuracy: 0.5248\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9425\n",
      "Epoch 256: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1927 - accuracy: 0.9425 - val_loss: 1.6253 - val_accuracy: 0.5545\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9400\n",
      "Epoch 257: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1928 - accuracy: 0.9400 - val_loss: 1.7705 - val_accuracy: 0.5644\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9400\n",
      "Epoch 258: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2049 - accuracy: 0.9400 - val_loss: 1.6079 - val_accuracy: 0.5842\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9375\n",
      "Epoch 259: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2065 - accuracy: 0.9375 - val_loss: 1.6303 - val_accuracy: 0.5941\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9425\n",
      "Epoch 260: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1796 - accuracy: 0.9425 - val_loss: 1.7573 - val_accuracy: 0.5347\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9375\n",
      "Epoch 261: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1858 - accuracy: 0.9375 - val_loss: 1.6713 - val_accuracy: 0.6040\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9500\n",
      "Epoch 262: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1707 - accuracy: 0.9500 - val_loss: 1.6396 - val_accuracy: 0.5743\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9550\n",
      "Epoch 263: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1613 - accuracy: 0.9550 - val_loss: 1.7840 - val_accuracy: 0.5347\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9400\n",
      "Epoch 264: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1792 - accuracy: 0.9400 - val_loss: 1.6671 - val_accuracy: 0.5842\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9450\n",
      "Epoch 265: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1717 - accuracy: 0.9450 - val_loss: 1.6120 - val_accuracy: 0.5941\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9450\n",
      "Epoch 266: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1762 - accuracy: 0.9450 - val_loss: 1.8104 - val_accuracy: 0.5545\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9525\n",
      "Epoch 267: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1609 - accuracy: 0.9525 - val_loss: 1.7465 - val_accuracy: 0.5743\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9550\n",
      "Epoch 268: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1555 - accuracy: 0.9550 - val_loss: 1.5528 - val_accuracy: 0.6238\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9550\n",
      "Epoch 269: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1459 - accuracy: 0.9550 - val_loss: 1.8139 - val_accuracy: 0.5545\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9525\n",
      "Epoch 270: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.1614 - accuracy: 0.9525 - val_loss: 1.5970 - val_accuracy: 0.6139\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9575\n",
      "Epoch 271: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1612 - accuracy: 0.9575 - val_loss: 1.6172 - val_accuracy: 0.6238\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9575\n",
      "Epoch 272: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1395 - accuracy: 0.9575 - val_loss: 1.7827 - val_accuracy: 0.5743\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9550\n",
      "Epoch 273: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1626 - accuracy: 0.9550 - val_loss: 1.8859 - val_accuracy: 0.5743\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9450\n",
      "Epoch 274: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1644 - accuracy: 0.9450 - val_loss: 1.7536 - val_accuracy: 0.5941\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9500\n",
      "Epoch 275: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1503 - accuracy: 0.9500 - val_loss: 1.8443 - val_accuracy: 0.5743\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9575\n",
      "Epoch 276: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.1499 - accuracy: 0.9575 - val_loss: 1.8630 - val_accuracy: 0.5842\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9400\n",
      "Epoch 277: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1695 - accuracy: 0.9400 - val_loss: 1.7677 - val_accuracy: 0.5842\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9375\n",
      "Epoch 278: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1688 - accuracy: 0.9375 - val_loss: 1.9773 - val_accuracy: 0.5347\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9500\n",
      "Epoch 279: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1464 - accuracy: 0.9500 - val_loss: 1.8657 - val_accuracy: 0.6040\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9525\n",
      "Epoch 280: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1562 - accuracy: 0.9525 - val_loss: 1.7719 - val_accuracy: 0.5941\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9550\n",
      "Epoch 281: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1355 - accuracy: 0.9550 - val_loss: 1.9457 - val_accuracy: 0.5149\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9350\n",
      "Epoch 282: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.1929 - accuracy: 0.9350 - val_loss: 1.6270 - val_accuracy: 0.6436\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9400\n",
      "Epoch 283: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1790 - accuracy: 0.9400 - val_loss: 1.9469 - val_accuracy: 0.5644\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9575\n",
      "Epoch 284: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.1497 - accuracy: 0.9575 - val_loss: 1.7983 - val_accuracy: 0.6139\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9375\n",
      "Epoch 285: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1865 - accuracy: 0.9375 - val_loss: 2.1241 - val_accuracy: 0.4950\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9450\n",
      "Epoch 286: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1700 - accuracy: 0.9450 - val_loss: 1.7549 - val_accuracy: 0.5941\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9400\n",
      "Epoch 287: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1798 - accuracy: 0.9400 - val_loss: 1.9603 - val_accuracy: 0.5446\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9525\n",
      "Epoch 288: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1293 - accuracy: 0.9525 - val_loss: 1.9319 - val_accuracy: 0.5545\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9500\n",
      "Epoch 289: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1522 - accuracy: 0.9500 - val_loss: 1.8194 - val_accuracy: 0.5842\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9575\n",
      "Epoch 290: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1354 - accuracy: 0.9575 - val_loss: 2.0084 - val_accuracy: 0.5248\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9500\n",
      "Epoch 291: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.1375 - accuracy: 0.9500 - val_loss: 1.7222 - val_accuracy: 0.6436\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9600\n",
      "Epoch 292: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1381 - accuracy: 0.9600 - val_loss: 1.8445 - val_accuracy: 0.5941\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9550\n",
      "Epoch 293: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1228 - accuracy: 0.9550 - val_loss: 1.9530 - val_accuracy: 0.5545\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9575\n",
      "Epoch 294: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1221 - accuracy: 0.9575 - val_loss: 1.7490 - val_accuracy: 0.6139\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9550\n",
      "Epoch 295: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1292 - accuracy: 0.9550 - val_loss: 1.9215 - val_accuracy: 0.5644\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9600\n",
      "Epoch 296: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1221 - accuracy: 0.9600 - val_loss: 1.6579 - val_accuracy: 0.6337\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9550\n",
      "Epoch 297: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1132 - accuracy: 0.9550 - val_loss: 1.6635 - val_accuracy: 0.6238\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9475\n",
      "Epoch 298: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.1273 - accuracy: 0.9475 - val_loss: 1.6330 - val_accuracy: 0.6436\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9525\n",
      "Epoch 299: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1159 - accuracy: 0.9525 - val_loss: 1.6394 - val_accuracy: 0.6436\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9675\n",
      "Epoch 300: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1003 - accuracy: 0.9675 - val_loss: 1.8686 - val_accuracy: 0.5644\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9500\n",
      "Epoch 301: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1185 - accuracy: 0.9500 - val_loss: 1.5896 - val_accuracy: 0.6634\n",
      "Epoch 302/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9550\n",
      "Epoch 302: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1252 - accuracy: 0.9550 - val_loss: 1.5807 - val_accuracy: 0.6733\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9650\n",
      "Epoch 303: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1026 - accuracy: 0.9650 - val_loss: 2.0456 - val_accuracy: 0.5644\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9425\n",
      "Epoch 304: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1807 - accuracy: 0.9425 - val_loss: 1.5325 - val_accuracy: 0.6832\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9475\n",
      "Epoch 305: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1437 - accuracy: 0.9475 - val_loss: 1.8349 - val_accuracy: 0.5644\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9425\n",
      "Epoch 306: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1777 - accuracy: 0.9425 - val_loss: 1.6694 - val_accuracy: 0.6139\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9575\n",
      "Epoch 307: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1314 - accuracy: 0.9575 - val_loss: 1.7864 - val_accuracy: 0.5842\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9500\n",
      "Epoch 308: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1421 - accuracy: 0.9500 - val_loss: 2.0115 - val_accuracy: 0.5545\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9550\n",
      "Epoch 309: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1338 - accuracy: 0.9550 - val_loss: 1.5336 - val_accuracy: 0.6436\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.9475\n",
      "Epoch 310: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1366 - accuracy: 0.9475 - val_loss: 2.0870 - val_accuracy: 0.5347\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9575\n",
      "Epoch 311: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1317 - accuracy: 0.9575 - val_loss: 1.9700 - val_accuracy: 0.5644\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9575\n",
      "Epoch 312: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1336 - accuracy: 0.9575 - val_loss: 1.7461 - val_accuracy: 0.5842\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9550\n",
      "Epoch 313: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1250 - accuracy: 0.9550 - val_loss: 2.0078 - val_accuracy: 0.5941\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9575\n",
      "Epoch 314: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1205 - accuracy: 0.9575 - val_loss: 1.6965 - val_accuracy: 0.6139\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9425\n",
      "Epoch 315: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1614 - accuracy: 0.9425 - val_loss: 2.0382 - val_accuracy: 0.5446\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9500\n",
      "Epoch 316: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.1605 - accuracy: 0.9500 - val_loss: 1.7350 - val_accuracy: 0.6238\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9475\n",
      "Epoch 317: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1626 - accuracy: 0.9475 - val_loss: 1.6407 - val_accuracy: 0.6535\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9250\n",
      "Epoch 318: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2097 - accuracy: 0.9250 - val_loss: 2.4710 - val_accuracy: 0.4752\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9125\n",
      "Epoch 319: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2602 - accuracy: 0.9125 - val_loss: 1.6095 - val_accuracy: 0.6733\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.8950\n",
      "Epoch 320: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2784 - accuracy: 0.8950 - val_loss: 2.2847 - val_accuracy: 0.5347\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9225\n",
      "Epoch 321: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1809 - accuracy: 0.9225 - val_loss: 1.6639 - val_accuracy: 0.5842\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9475\n",
      "Epoch 322: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1548 - accuracy: 0.9475 - val_loss: 1.7635 - val_accuracy: 0.5941\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9575\n",
      "Epoch 323: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1139 - accuracy: 0.9575 - val_loss: 2.2383 - val_accuracy: 0.5050\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9350\n",
      "Epoch 324: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1792 - accuracy: 0.9350 - val_loss: 1.7329 - val_accuracy: 0.5842\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9625\n",
      "Epoch 325: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1377 - accuracy: 0.9625 - val_loss: 1.8722 - val_accuracy: 0.5941\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9575\n",
      "Epoch 326: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1374 - accuracy: 0.9575 - val_loss: 2.3643 - val_accuracy: 0.5050\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9400\n",
      "Epoch 327: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1537 - accuracy: 0.9400 - val_loss: 1.8590 - val_accuracy: 0.6238\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9375\n",
      "Epoch 328: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1748 - accuracy: 0.9375 - val_loss: 2.0772 - val_accuracy: 0.5743\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9650\n",
      "Epoch 329: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1132 - accuracy: 0.9650 - val_loss: 2.0014 - val_accuracy: 0.5941\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9750\n",
      "Epoch 330: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0953 - accuracy: 0.9750 - val_loss: 1.8636 - val_accuracy: 0.6436\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9550\n",
      "Epoch 331: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1403 - accuracy: 0.9550 - val_loss: 2.3554 - val_accuracy: 0.5050\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9450\n",
      "Epoch 332: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1697 - accuracy: 0.9450 - val_loss: 1.6929 - val_accuracy: 0.5941\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9450\n",
      "Epoch 333: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.1344 - accuracy: 0.9450 - val_loss: 1.8414 - val_accuracy: 0.5842\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9575\n",
      "Epoch 334: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1164 - accuracy: 0.9575 - val_loss: 2.4010 - val_accuracy: 0.5149\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9600\n",
      "Epoch 335: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1017 - accuracy: 0.9600 - val_loss: 1.8484 - val_accuracy: 0.5941\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9675\n",
      "Epoch 336: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1051 - accuracy: 0.9675 - val_loss: 1.8473 - val_accuracy: 0.5842\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9625\n",
      "Epoch 337: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0969 - accuracy: 0.9625 - val_loss: 1.8752 - val_accuracy: 0.5743\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9700\n",
      "Epoch 338: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0893 - accuracy: 0.9700 - val_loss: 1.8811 - val_accuracy: 0.5743\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9725\n",
      "Epoch 339: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0694 - accuracy: 0.9725 - val_loss: 1.7557 - val_accuracy: 0.5941\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9700\n",
      "Epoch 340: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0864 - accuracy: 0.9700 - val_loss: 1.8226 - val_accuracy: 0.5743\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9725\n",
      "Epoch 341: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0748 - accuracy: 0.9725 - val_loss: 1.8919 - val_accuracy: 0.5743\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9725\n",
      "Epoch 342: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0744 - accuracy: 0.9725 - val_loss: 1.8499 - val_accuracy: 0.5743\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9625\n",
      "Epoch 343: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0917 - accuracy: 0.9625 - val_loss: 1.8020 - val_accuracy: 0.6040\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9775\n",
      "Epoch 344: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 1.9201 - val_accuracy: 0.5842\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9800\n",
      "Epoch 345: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 1.7136 - val_accuracy: 0.6238\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9750\n",
      "Epoch 346: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 1.8166 - val_accuracy: 0.5743\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9800\n",
      "Epoch 347: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0718 - accuracy: 0.9800 - val_loss: 1.9874 - val_accuracy: 0.5941\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9875\n",
      "Epoch 348: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0633 - accuracy: 0.9875 - val_loss: 1.9635 - val_accuracy: 0.6040\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9850\n",
      "Epoch 349: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0740 - accuracy: 0.9850 - val_loss: 2.0657 - val_accuracy: 0.5743\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9750\n",
      "Epoch 350: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0790 - accuracy: 0.9750 - val_loss: 2.0313 - val_accuracy: 0.5545\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9800\n",
      "Epoch 351: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0688 - accuracy: 0.9800 - val_loss: 1.6646 - val_accuracy: 0.6436\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9725\n",
      "Epoch 352: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0802 - accuracy: 0.9725 - val_loss: 1.7404 - val_accuracy: 0.6040\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9925\n",
      "Epoch 353: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0543 - accuracy: 0.9925 - val_loss: 2.0680 - val_accuracy: 0.5842\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9825\n",
      "Epoch 354: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0632 - accuracy: 0.9825 - val_loss: 1.9694 - val_accuracy: 0.6139\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9775\n",
      "Epoch 355: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 1.9261 - val_accuracy: 0.6139\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9800\n",
      "Epoch 356: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0754 - accuracy: 0.9800 - val_loss: 1.8908 - val_accuracy: 0.5842\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9800\n",
      "Epoch 357: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0799 - accuracy: 0.9800 - val_loss: 1.8659 - val_accuracy: 0.6040\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9850\n",
      "Epoch 358: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0628 - accuracy: 0.9850 - val_loss: 2.0887 - val_accuracy: 0.5842\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9775\n",
      "Epoch 359: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 1.9188 - val_accuracy: 0.6238\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9775\n",
      "Epoch 360: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0875 - accuracy: 0.9775 - val_loss: 1.9262 - val_accuracy: 0.6040\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9800\n",
      "Epoch 361: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0751 - accuracy: 0.9800 - val_loss: 1.8401 - val_accuracy: 0.6040\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9650\n",
      "Epoch 362: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0978 - accuracy: 0.9650 - val_loss: 1.7197 - val_accuracy: 0.6238\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9725\n",
      "Epoch 363: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 2.0614 - val_accuracy: 0.5446\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9750\n",
      "Epoch 364: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 1.7076 - val_accuracy: 0.6040\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9750\n",
      "Epoch 365: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0842 - accuracy: 0.9750 - val_loss: 2.0916 - val_accuracy: 0.5545\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9800\n",
      "Epoch 366: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0778 - accuracy: 0.9800 - val_loss: 1.9718 - val_accuracy: 0.5941\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9900\n",
      "Epoch 367: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0532 - accuracy: 0.9900 - val_loss: 1.7487 - val_accuracy: 0.6238\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9775\n",
      "Epoch 368: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0748 - accuracy: 0.9775 - val_loss: 1.8960 - val_accuracy: 0.5941\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9875\n",
      "Epoch 369: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0612 - accuracy: 0.9875 - val_loss: 1.9711 - val_accuracy: 0.5842\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9750\n",
      "Epoch 370: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 1.8253 - val_accuracy: 0.6238\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9800\n",
      "Epoch 371: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 1.9870 - val_accuracy: 0.6139\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9875\n",
      "Epoch 372: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0590 - accuracy: 0.9875 - val_loss: 2.2906 - val_accuracy: 0.5644\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9850\n",
      "Epoch 373: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0563 - accuracy: 0.9850 - val_loss: 2.1410 - val_accuracy: 0.5644\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9925\n",
      "Epoch 374: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0508 - accuracy: 0.9925 - val_loss: 1.9341 - val_accuracy: 0.5842\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9750\n",
      "Epoch 375: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 2.0458 - val_accuracy: 0.5644\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9925\n",
      "Epoch 376: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0501 - accuracy: 0.9925 - val_loss: 2.0872 - val_accuracy: 0.5446\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9925\n",
      "Epoch 377: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0427 - accuracy: 0.9925 - val_loss: 1.7534 - val_accuracy: 0.6238\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9875\n",
      "Epoch 378: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0477 - accuracy: 0.9875 - val_loss: 1.8167 - val_accuracy: 0.5941\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9925\n",
      "Epoch 379: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0410 - accuracy: 0.9925 - val_loss: 1.9769 - val_accuracy: 0.5545\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9900\n",
      "Epoch 380: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0526 - accuracy: 0.9900 - val_loss: 1.8630 - val_accuracy: 0.6238\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9975\n",
      "Epoch 381: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0384 - accuracy: 0.9975 - val_loss: 1.8773 - val_accuracy: 0.6139\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9825\n",
      "Epoch 382: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 2.0907 - val_accuracy: 0.5545\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9875\n",
      "Epoch 383: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 1.8416 - val_accuracy: 0.6238\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9950\n",
      "Epoch 384: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0493 - accuracy: 0.9950 - val_loss: 2.0011 - val_accuracy: 0.5842\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9900\n",
      "Epoch 385: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0442 - accuracy: 0.9900 - val_loss: 2.2856 - val_accuracy: 0.5347\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9825\n",
      "Epoch 386: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 2.0525 - val_accuracy: 0.5842\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9850\n",
      "Epoch 387: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0625 - accuracy: 0.9850 - val_loss: 1.9388 - val_accuracy: 0.6040\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9850\n",
      "Epoch 388: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 1.7124 - val_accuracy: 0.6337\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9900\n",
      "Epoch 389: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.0502 - accuracy: 0.9900 - val_loss: 1.9990 - val_accuracy: 0.5941\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9875\n",
      "Epoch 390: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0575 - accuracy: 0.9875 - val_loss: 1.9594 - val_accuracy: 0.6238\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9950\n",
      "Epoch 391: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0369 - accuracy: 0.9950 - val_loss: 1.8528 - val_accuracy: 0.6139\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9925\n",
      "Epoch 392: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0468 - accuracy: 0.9925 - val_loss: 2.2869 - val_accuracy: 0.5347\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9925\n",
      "Epoch 393: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0469 - accuracy: 0.9925 - val_loss: 1.9026 - val_accuracy: 0.5941\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9775\n",
      "Epoch 394: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 2.1294 - val_accuracy: 0.5644\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9825\n",
      "Epoch 395: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0676 - accuracy: 0.9825 - val_loss: 2.0137 - val_accuracy: 0.6139\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9825\n",
      "Epoch 396: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0645 - accuracy: 0.9825 - val_loss: 2.0422 - val_accuracy: 0.6040\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9950\n",
      "Epoch 397: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0383 - accuracy: 0.9950 - val_loss: 2.5469 - val_accuracy: 0.4950\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9625\n",
      "Epoch 398: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.1096 - accuracy: 0.9625 - val_loss: 1.8934 - val_accuracy: 0.6238\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9600\n",
      "Epoch 399: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0964 - accuracy: 0.9600 - val_loss: 2.5165 - val_accuracy: 0.5050\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9725\n",
      "Epoch 400: val_loss did not improve from 1.37320\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0827 - accuracy: 0.9725 - val_loss: 1.8473 - val_accuracy: 0.6238\n",
      "Training completed in time:  0:02:08.892553\n",
      "Training Accuracy:  0.987500011920929\n",
      "Testing Accuracy:  0.6237623691558838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = '/Users/irk2w/Desktop/T5/sounds_final '\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "def extract_features(file_path, target_shape=(128, 128)):\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Data Augmentation\n",
    "    pitch_shifted = librosa.effects.pitch_shift(audio_data, sr=sample_rate, n_steps=4)\n",
    "    time_stretched = librosa.effects.time_stretch(audio_data, rate=1.5)\n",
    "\n",
    "    # Original Features\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    # Augmented Features\n",
    "    mel_spectrogram_pitch = librosa.feature.melspectrogram(y=pitch_shifted, sr=sample_rate)\n",
    "    mel_spectrogram_stretch = librosa.feature.melspectrogram(y=time_stretched, sr=sample_rate)\n",
    "\n",
    "    # Resizing\n",
    "    mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "    mel_spectrogram_pitch_resized = resize(mel_spectrogram_pitch, target_shape)\n",
    "    mel_spectrogram_stretch_resized = resize(mel_spectrogram_stretch, target_shape)\n",
    "\n",
    "    return mel_spectrogram_resized, mel_spectrogram_pitch_resized, mel_spectrogram_stretch_resized\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                original, pitch, stretch = extract_features(file_path, target_shape)\n",
    "                # Append original features\n",
    "                data.append(original)\n",
    "                labels.append(i)\n",
    "                # Append augmented features\n",
    "                data.append(pitch)\n",
    "                labels.append(i)\n",
    "                data.append(stretch)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=400, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('911_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/irk2w/Desktop/T5/911_model_don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_touch/911_class.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load your model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/irk2w/Desktop/T5/sounds_final /Police/police-37.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 16\u001b[0m predicted_class_name \u001b[38;5;241m=\u001b[39m predict_audio_class(audio_file_path, model, \u001b[43mclasses\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model predicts that the audio file is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_class_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sound.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_audio_class(file_path, model, classes):\n",
    "    # Assuming the extract_features function is defined as above\n",
    "    features = extract_features(file_path)[0]  # Use the original features for prediction\n",
    "    features = np.expand_dims(features, axis=0)  # Reshaping to match model input\n",
    "\n",
    "    # Make the prediction\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return classes[predicted_class[0]]\n",
    "\n",
    "# Usage\n",
    "model = load_model(\"/Users/irk2w/Desktop/T5/911_model_don't_touch/911_class.h5\")  # Load your model\n",
    "audio_file_path = '/Users/irk2w/Desktop/T5/sounds_final /Police/police-37.wav'\n",
    "predicted_class_name = predict_audio_class(audio_file_path, model, classes)\n",
    "print(f\"The model predicts that the audio file is a {predicted_class_name} sound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6U_HCDih1DjD",
    "outputId": "f2ba3d9e-8859-4794-e17e-0765cd3f9fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXUI739bOx7b"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "gtts = gTTS('           ', lang='ar')\n",
    "gtts.save('police-10.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlkFZaog1Dr7"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cm5TBP6LRPil",
    "outputId": "3bb694cd-e65b-4623-e1be-cd087620700f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 442ms/step - loss: 1.6455 - accuracy: 0.2353 - val_loss: 2.0695 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.8984 - accuracy: 0.7143 - val_loss: 2.0566 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.6367 - accuracy: 0.7899 - val_loss: 2.0225 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.5065 - accuracy: 0.9076 - val_loss: 2.2557 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.4022 - accuracy: 0.9328 - val_loss: 2.3901 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.3839 - accuracy: 0.9160 - val_loss: 2.6047 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.2956 - accuracy: 0.9664 - val_loss: 2.7975 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.2842 - accuracy: 0.9664 - val_loss: 2.9052 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.2399 - accuracy: 0.9832 - val_loss: 2.9519 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.3002 - accuracy: 0.9412 - val_loss: 3.0533 - val_accuracy: 0.2143 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7af2f24222c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# ... Your data loading and preprocessing code ...\n",
    "\n",
    "# Normalization (example using global mean and std)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Improved model architecture\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Consider adding Conv2D layers here if you want to use CNN features\n",
    "\n",
    "# Using bidirectional LSTM and adding dropout\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5))(input_layer)\n",
    "x = Flatten()(x)  # Flatten needed if return_sequences=True\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)  # Regularized dense layer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile and fit the model with some form of learning rate scheduler or reduction on plateau\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_2-WodI2DEN",
    "outputId": "566db597-49f1-4d7a-b0c6-254db4c09044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128)]        0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49668 (194.02 KB)\n",
      "Trainable params: 49668 (194.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 14.7059%\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.2556\n",
      "Epoch 1: val_loss improved from inf to 1.38667, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3862 - accuracy: 0.2556 - val_loss: 1.3867 - val_accuracy: 0.2059\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3854 - accuracy: 0.2857\n",
      "Epoch 2: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3854 - accuracy: 0.2857 - val_loss: 1.3869 - val_accuracy: 0.2353\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.3233\n",
      "Epoch 3: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 1.3847 - accuracy: 0.3233 - val_loss: 1.3872 - val_accuracy: 0.2647\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3838 - accuracy: 0.3308\n",
      "Epoch 4: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.3838 - accuracy: 0.3308 - val_loss: 1.3875 - val_accuracy: 0.2353\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3829 - accuracy: 0.3083\n",
      "Epoch 5: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.3829 - accuracy: 0.3083 - val_loss: 1.3879 - val_accuracy: 0.2353\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.3383\n",
      "Epoch 6: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3819 - accuracy: 0.3383 - val_loss: 1.3884 - val_accuracy: 0.2647\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3808 - accuracy: 0.3233\n",
      "Epoch 7: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.3808 - accuracy: 0.3233 - val_loss: 1.3890 - val_accuracy: 0.2647\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3795 - accuracy: 0.2932\n",
      "Epoch 8: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.3795 - accuracy: 0.2932 - val_loss: 1.3898 - val_accuracy: 0.2647\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3779 - accuracy: 0.2857\n",
      "Epoch 9: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3779 - accuracy: 0.2857 - val_loss: 1.3909 - val_accuracy: 0.2647\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760 - accuracy: 0.2707\n",
      "Epoch 10: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.3760 - accuracy: 0.2707 - val_loss: 1.3922 - val_accuracy: 0.2647\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3735 - accuracy: 0.2707\n",
      "Epoch 11: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3735 - accuracy: 0.2707 - val_loss: 1.3937 - val_accuracy: 0.2647\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.2707\n",
      "Epoch 12: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3702 - accuracy: 0.2707 - val_loss: 1.3954 - val_accuracy: 0.2647\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.2857\n",
      "Epoch 13: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.3657 - accuracy: 0.2857 - val_loss: 1.3976 - val_accuracy: 0.2647\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.3008\n",
      "Epoch 14: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.3596 - accuracy: 0.3008 - val_loss: 1.4007 - val_accuracy: 0.2647\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3513 - accuracy: 0.3083\n",
      "Epoch 15: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.3513 - accuracy: 0.3083 - val_loss: 1.4060 - val_accuracy: 0.2647\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.3383\n",
      "Epoch 16: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.3415 - accuracy: 0.3383 - val_loss: 1.4141 - val_accuracy: 0.2941\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3314 - accuracy: 0.3158\n",
      "Epoch 17: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3314 - accuracy: 0.3158 - val_loss: 1.4147 - val_accuracy: 0.2647\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3173 - accuracy: 0.3459\n",
      "Epoch 18: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.3173 - accuracy: 0.3459 - val_loss: 1.4091 - val_accuracy: 0.2647\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.3609\n",
      "Epoch 19: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.3025 - accuracy: 0.3609 - val_loss: 1.4205 - val_accuracy: 0.2941\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2844 - accuracy: 0.3835\n",
      "Epoch 20: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2844 - accuracy: 0.3835 - val_loss: 1.4332 - val_accuracy: 0.2353\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.3910\n",
      "Epoch 21: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.2684 - accuracy: 0.3910 - val_loss: 1.4467 - val_accuracy: 0.2353\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.4060\n",
      "Epoch 22: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.2526 - accuracy: 0.4060 - val_loss: 1.4942 - val_accuracy: 0.2353\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.4436\n",
      "Epoch 23: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2347 - accuracy: 0.4436 - val_loss: 1.5379 - val_accuracy: 0.3235\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.4060\n",
      "Epoch 24: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.2199 - accuracy: 0.4060 - val_loss: 1.5558 - val_accuracy: 0.3235\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2063 - accuracy: 0.4060\n",
      "Epoch 25: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2063 - accuracy: 0.4060 - val_loss: 1.5546 - val_accuracy: 0.2941\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.4361\n",
      "Epoch 26: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.1852 - accuracy: 0.4361 - val_loss: 1.5662 - val_accuracy: 0.2353\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1632 - accuracy: 0.4511\n",
      "Epoch 27: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.1632 - accuracy: 0.4511 - val_loss: 1.5502 - val_accuracy: 0.2353\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1407 - accuracy: 0.4436\n",
      "Epoch 28: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.1407 - accuracy: 0.4436 - val_loss: 1.6185 - val_accuracy: 0.2353\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1132 - accuracy: 0.4586\n",
      "Epoch 29: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.1132 - accuracy: 0.4586 - val_loss: 1.6707 - val_accuracy: 0.2059\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.5038\n",
      "Epoch 30: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.0870 - accuracy: 0.5038 - val_loss: 1.7512 - val_accuracy: 0.2059\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0602 - accuracy: 0.5113\n",
      "Epoch 31: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.0602 - accuracy: 0.5113 - val_loss: 1.7159 - val_accuracy: 0.2059\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.5338\n",
      "Epoch 32: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.0474 - accuracy: 0.5338 - val_loss: 1.8227 - val_accuracy: 0.1471\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.5489\n",
      "Epoch 33: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.0299 - accuracy: 0.5489 - val_loss: 1.9081 - val_accuracy: 0.2059\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.5263\n",
      "Epoch 34: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.0045 - accuracy: 0.5263 - val_loss: 1.9237 - val_accuracy: 0.1471\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9977 - accuracy: 0.5564\n",
      "Epoch 35: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.9977 - accuracy: 0.5564 - val_loss: 1.9086 - val_accuracy: 0.2059\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.5940\n",
      "Epoch 36: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.9643 - accuracy: 0.5940 - val_loss: 1.9747 - val_accuracy: 0.1471\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6090\n",
      "Epoch 37: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.9505 - accuracy: 0.6090 - val_loss: 2.0074 - val_accuracy: 0.2059\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9158 - accuracy: 0.5865\n",
      "Epoch 38: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.9158 - accuracy: 0.5865 - val_loss: 1.9506 - val_accuracy: 0.2647\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.6617\n",
      "Epoch 39: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.9104 - accuracy: 0.6617 - val_loss: 1.9521 - val_accuracy: 0.2059\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.6692\n",
      "Epoch 40: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8917 - accuracy: 0.6692 - val_loss: 2.1640 - val_accuracy: 0.2059\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.6165\n",
      "Epoch 41: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8838 - accuracy: 0.6165 - val_loss: 2.0018 - val_accuracy: 0.2353\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8336 - accuracy: 0.7293\n",
      "Epoch 42: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8336 - accuracy: 0.7293 - val_loss: 1.9636 - val_accuracy: 0.2647\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7143\n",
      "Epoch 43: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8414 - accuracy: 0.7143 - val_loss: 2.0193 - val_accuracy: 0.2353\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.7368\n",
      "Epoch 44: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8038 - accuracy: 0.7368 - val_loss: 2.1758 - val_accuracy: 0.2059\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.7669\n",
      "Epoch 45: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7573 - accuracy: 0.7669 - val_loss: 2.2976 - val_accuracy: 0.2647\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.7669\n",
      "Epoch 46: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.7665 - accuracy: 0.7669 - val_loss: 2.2293 - val_accuracy: 0.2059\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.8421\n",
      "Epoch 47: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7066 - accuracy: 0.8421 - val_loss: 2.1931 - val_accuracy: 0.2353\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.8346\n",
      "Epoch 48: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7153 - accuracy: 0.8346 - val_loss: 2.1434 - val_accuracy: 0.1765\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.8195\n",
      "Epoch 49: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7170 - accuracy: 0.8195 - val_loss: 2.2306 - val_accuracy: 0.1765\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.8722\n",
      "Epoch 50: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6571 - accuracy: 0.8722 - val_loss: 2.3553 - val_accuracy: 0.2353\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.8195\n",
      "Epoch 51: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.6594 - accuracy: 0.8195 - val_loss: 2.3235 - val_accuracy: 0.2353\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.8947\n",
      "Epoch 52: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5927 - accuracy: 0.8947 - val_loss: 2.2728 - val_accuracy: 0.2647\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.9098\n",
      "Epoch 53: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.5841 - accuracy: 0.9098 - val_loss: 2.2972 - val_accuracy: 0.2647\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.9098\n",
      "Epoch 54: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5615 - accuracy: 0.9098 - val_loss: 2.3908 - val_accuracy: 0.2941\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.9023\n",
      "Epoch 55: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5605 - accuracy: 0.9023 - val_loss: 2.3741 - val_accuracy: 0.2647\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.9023\n",
      "Epoch 56: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5525 - accuracy: 0.9023 - val_loss: 2.4029 - val_accuracy: 0.2647\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8797\n",
      "Epoch 57: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5424 - accuracy: 0.8797 - val_loss: 2.4052 - val_accuracy: 0.2941\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.9323\n",
      "Epoch 58: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4746 - accuracy: 0.9323 - val_loss: 2.4799 - val_accuracy: 0.2647\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8722\n",
      "Epoch 59: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5463 - accuracy: 0.8722 - val_loss: 2.3664 - val_accuracy: 0.2941\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.9248\n",
      "Epoch 60: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4703 - accuracy: 0.9248 - val_loss: 2.4319 - val_accuracy: 0.2059\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8947\n",
      "Epoch 61: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5069 - accuracy: 0.8947 - val_loss: 2.4673 - val_accuracy: 0.3235\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.8797\n",
      "Epoch 62: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4676 - accuracy: 0.8797 - val_loss: 2.4229 - val_accuracy: 0.3235\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.9173\n",
      "Epoch 63: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4233 - accuracy: 0.9173 - val_loss: 2.4113 - val_accuracy: 0.2941\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.9098\n",
      "Epoch 64: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4505 - accuracy: 0.9098 - val_loss: 2.3929 - val_accuracy: 0.3235\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.9248\n",
      "Epoch 65: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4261 - accuracy: 0.9248 - val_loss: 2.4613 - val_accuracy: 0.3235\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.9173\n",
      "Epoch 66: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4006 - accuracy: 0.9173 - val_loss: 2.5181 - val_accuracy: 0.3235\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.9023\n",
      "Epoch 67: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4235 - accuracy: 0.9023 - val_loss: 2.4628 - val_accuracy: 0.2941\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9323\n",
      "Epoch 68: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3838 - accuracy: 0.9323 - val_loss: 2.4461 - val_accuracy: 0.2941\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.9323\n",
      "Epoch 69: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.3948 - accuracy: 0.9323 - val_loss: 2.4778 - val_accuracy: 0.3235\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9323\n",
      "Epoch 70: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3742 - accuracy: 0.9323 - val_loss: 2.5474 - val_accuracy: 0.3529\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9248\n",
      "Epoch 71: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3570 - accuracy: 0.9248 - val_loss: 2.5681 - val_accuracy: 0.3235\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.9323\n",
      "Epoch 72: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3482 - accuracy: 0.9323 - val_loss: 2.5904 - val_accuracy: 0.3235\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9323\n",
      "Epoch 73: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3346 - accuracy: 0.9323 - val_loss: 2.5863 - val_accuracy: 0.3235\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9323\n",
      "Epoch 74: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3288 - accuracy: 0.9323 - val_loss: 2.5843 - val_accuracy: 0.3235\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9323\n",
      "Epoch 75: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3182 - accuracy: 0.9323 - val_loss: 2.6054 - val_accuracy: 0.2941\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9323\n",
      "Epoch 76: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3132 - accuracy: 0.9323 - val_loss: 2.6191 - val_accuracy: 0.2941\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9323\n",
      "Epoch 77: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.3092 - accuracy: 0.9323 - val_loss: 2.6153 - val_accuracy: 0.2647\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9398\n",
      "Epoch 78: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2954 - accuracy: 0.9398 - val_loss: 2.6234 - val_accuracy: 0.2941\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.9398\n",
      "Epoch 79: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2874 - accuracy: 0.9398 - val_loss: 2.6340 - val_accuracy: 0.3235\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9398\n",
      "Epoch 80: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.2869 - accuracy: 0.9398 - val_loss: 2.6492 - val_accuracy: 0.3235\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.9398\n",
      "Epoch 81: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2791 - accuracy: 0.9398 - val_loss: 2.6674 - val_accuracy: 0.2941\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9398\n",
      "Epoch 82: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2679 - accuracy: 0.9398 - val_loss: 2.6840 - val_accuracy: 0.2941\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9398\n",
      "Epoch 83: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2622 - accuracy: 0.9398 - val_loss: 2.7037 - val_accuracy: 0.2941\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9398\n",
      "Epoch 84: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2583 - accuracy: 0.9398 - val_loss: 2.7289 - val_accuracy: 0.2941\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9474\n",
      "Epoch 85: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2499 - accuracy: 0.9474 - val_loss: 2.7515 - val_accuracy: 0.2941\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9474\n",
      "Epoch 86: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2393 - accuracy: 0.9474 - val_loss: 2.7633 - val_accuracy: 0.2941\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9474\n",
      "Epoch 87: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2312 - accuracy: 0.9474 - val_loss: 2.7771 - val_accuracy: 0.2941\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9474\n",
      "Epoch 88: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2279 - accuracy: 0.9474 - val_loss: 2.7971 - val_accuracy: 0.2941\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9474\n",
      "Epoch 89: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2219 - accuracy: 0.9474 - val_loss: 2.8169 - val_accuracy: 0.2941\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9474\n",
      "Epoch 90: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2135 - accuracy: 0.9474 - val_loss: 2.8545 - val_accuracy: 0.2647\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9549\n",
      "Epoch 91: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2067 - accuracy: 0.9549 - val_loss: 2.8874 - val_accuracy: 0.2647\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9549\n",
      "Epoch 92: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2027 - accuracy: 0.9549 - val_loss: 2.8899 - val_accuracy: 0.2647\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9549\n",
      "Epoch 93: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1948 - accuracy: 0.9549 - val_loss: 2.9026 - val_accuracy: 0.2647\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9549\n",
      "Epoch 94: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1899 - accuracy: 0.9549 - val_loss: 2.9296 - val_accuracy: 0.2941\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9549\n",
      "Epoch 95: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1850 - accuracy: 0.9549 - val_loss: 2.9581 - val_accuracy: 0.2941\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9624\n",
      "Epoch 96: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1814 - accuracy: 0.9624 - val_loss: 2.9777 - val_accuracy: 0.2941\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9549\n",
      "Epoch 97: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1750 - accuracy: 0.9549 - val_loss: 3.0070 - val_accuracy: 0.2941\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9549\n",
      "Epoch 98: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1708 - accuracy: 0.9549 - val_loss: 3.0403 - val_accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9624\n",
      "Epoch 99: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1663 - accuracy: 0.9624 - val_loss: 3.0475 - val_accuracy: 0.2941\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9624\n",
      "Epoch 100: val_loss did not improve from 1.38667\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1618 - accuracy: 0.9624 - val_loss: 3.0489 - val_accuracy: 0.2647\n",
      "Training completed in time:  0:00:42.935128\n",
      "Training Accuracy:  0.9624060392379761\n",
      "Testing Accuracy:  0.2647058963775635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional , Input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a function to extract MFCC features from audio files\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    return mfccs_processed\n",
    "\n",
    "# Define the dataset directory and the labels\n",
    "data_dir = '/content/drive/MyDrive/New folder/T5/sounds final'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "                data.append(mel_spectrogram_resized)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Encode the labels to integers\n",
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(64))\n",
    "#model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(64)(input_layer)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPSMHvMm3Y99"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
