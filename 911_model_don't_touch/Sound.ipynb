{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced69965-eadc-44bd-b1d2-582a011f5f17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 08:28:07.737145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8eefc75-7f6c-4d16-8d77-cd30f1c5dc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/fahad/Desktop/sounds final  2'\n",
    "classes = ['Civil', 'Police', 'Trafic', 'ambulance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18a3a3a8-6dff-45da-a48c-3dc3e1809880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(file_path, target_shape=(128, 128)):\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Data Augmentation\n",
    "    pitch_shifted = librosa.effects.pitch_shift(audio_data, sr=sample_rate, n_steps=4)\n",
    "    time_stretched = librosa.effects.time_stretch(audio_data, rate=1.5)\n",
    "\n",
    "    # Original Features\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    # Augmented Features\n",
    "    mel_spectrogram_pitch = librosa.feature.melspectrogram(y=pitch_shifted, sr=sample_rate)\n",
    "    mel_spectrogram_stretch = librosa.feature.melspectrogram(y=time_stretched, sr=sample_rate)\n",
    "\n",
    "    # Resizing\n",
    "    mel_spectrogram_resized = resize(mel_spectrogram, target_shape)\n",
    "    mel_spectrogram_pitch_resized = resize(mel_spectrogram_pitch, target_shape)\n",
    "    mel_spectrogram_stretch_resized = resize(mel_spectrogram_stretch, target_shape)\n",
    "\n",
    "    return mel_spectrogram_resized, mel_spectrogram_pitch_resized, mel_spectrogram_stretch_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dda2d27-c67a-4a2d-a526-05cc24a2f63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                original, pitch, stretch = extract_features(file_path, target_shape)\n",
    "                # Append original features\n",
    "                data.append(original)\n",
    "                labels.append(i)\n",
    "                # Append augmented features\n",
    "                data.append(pitch)\n",
    "                labels.append(i)\n",
    "                data.append(stretch)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87817a23-0785-42a4-8a87-749568ddbb37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "labels = to_categorical(labels, num_classes=len(classes))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ef7b5a-ea8f-4554-be85-db1b13ab7491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, l = load_and_preprocess_data(data_dir, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b51a303d-293b-4805-8914-528240a751cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    132\n",
       "0    129\n",
       "3    129\n",
       "2    111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(l).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32d4f500-0fd7-45dc-b1dd-d205881ab727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(128, 128), activation='relu'))  # Adjust the input_shape according to your data\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(classes), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f84fb84-b8ab-4b86-8b91-de791d9c292a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8ab7050-5dfd-4ef1-9d52-118ee8c20624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128, 256)          33024     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128, 256)          0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128, 192)          49344     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128, 192)          0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128, 128)          24704     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128, 64)           8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128, 64)           0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128, 32)           2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128, 16)           528       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128, 8)            136       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                18688     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137020 (535.23 KB)\n",
      "Trainable params: 137020 (535.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1e83a6-3055-4ac9-a52e-3f89befd3b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate pre-training accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f695d589-5cb5-4d8d-9844-d293dacd0774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training accuracy: 18.8119%\n"
     ]
    }
   ],
   "source": [
    "# Print pre-training accuracy\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "679458f5-e74e-4b7f-a698-632627daa7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.h5',\n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e927d644-2ea5-494e-8087-a07842069de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46345aa7-01f1-442a-852a-671a7608d30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3864 - accuracy: 0.2050\n",
      "Epoch 1: val_loss improved from inf to 1.38716, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 5s 742ms/step - loss: 1.3864 - accuracy: 0.2050 - val_loss: 1.3872 - val_accuracy: 0.1584\n",
      "Epoch 2/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahad/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.3855 - accuracy: 0.2900\n",
      "Epoch 2: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 599ms/step - loss: 1.3855 - accuracy: 0.2900 - val_loss: 1.3892 - val_accuracy: 0.1584\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3843 - accuracy: 0.2900\n",
      "Epoch 3: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 653ms/step - loss: 1.3843 - accuracy: 0.2900 - val_loss: 1.3929 - val_accuracy: 0.1584\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3831 - accuracy: 0.2900\n",
      "Epoch 4: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 636ms/step - loss: 1.3831 - accuracy: 0.2900 - val_loss: 1.3970 - val_accuracy: 0.1584\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3828 - accuracy: 0.2900\n",
      "Epoch 5: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 1.3828 - accuracy: 0.2900 - val_loss: 1.4032 - val_accuracy: 0.1584\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3821 - accuracy: 0.2900\n",
      "Epoch 6: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 1.3821 - accuracy: 0.2900 - val_loss: 1.4083 - val_accuracy: 0.1584\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3812 - accuracy: 0.2900\n",
      "Epoch 7: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 1.3812 - accuracy: 0.2900 - val_loss: 1.4094 - val_accuracy: 0.1584\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3810 - accuracy: 0.2900\n",
      "Epoch 8: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 1.3810 - accuracy: 0.2900 - val_loss: 1.4087 - val_accuracy: 0.1584\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3807 - accuracy: 0.2900\n",
      "Epoch 9: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 1.3807 - accuracy: 0.2900 - val_loss: 1.4090 - val_accuracy: 0.1584\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3797 - accuracy: 0.2900\n",
      "Epoch 10: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 1.3797 - accuracy: 0.2900 - val_loss: 1.4063 - val_accuracy: 0.1584\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.2900\n",
      "Epoch 11: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 1.3783 - accuracy: 0.2900 - val_loss: 1.4026 - val_accuracy: 0.1584\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3759 - accuracy: 0.2900\n",
      "Epoch 12: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 1.3759 - accuracy: 0.2900 - val_loss: 1.4046 - val_accuracy: 0.1584\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3703 - accuracy: 0.2900\n",
      "Epoch 13: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 1.3703 - accuracy: 0.2900 - val_loss: 1.4184 - val_accuracy: 0.1584\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3661 - accuracy: 0.2900\n",
      "Epoch 14: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 1.3661 - accuracy: 0.2900 - val_loss: 1.4241 - val_accuracy: 0.1584\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3586 - accuracy: 0.2900\n",
      "Epoch 15: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 1.3586 - accuracy: 0.2900 - val_loss: 1.4032 - val_accuracy: 0.1584\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3511 - accuracy: 0.2900\n",
      "Epoch 16: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 1.3511 - accuracy: 0.2900 - val_loss: 1.4087 - val_accuracy: 0.1584\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3396 - accuracy: 0.2675\n",
      "Epoch 17: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 528ms/step - loss: 1.3396 - accuracy: 0.2675 - val_loss: 1.4609 - val_accuracy: 0.2574\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3360 - accuracy: 0.3000\n",
      "Epoch 18: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 528ms/step - loss: 1.3360 - accuracy: 0.3000 - val_loss: 1.4112 - val_accuracy: 0.2574\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3218 - accuracy: 0.3300\n",
      "Epoch 19: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 1.3218 - accuracy: 0.3300 - val_loss: 1.4195 - val_accuracy: 0.2277\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3128 - accuracy: 0.3450\n",
      "Epoch 20: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 2s 692ms/step - loss: 1.3128 - accuracy: 0.3450 - val_loss: 1.4274 - val_accuracy: 0.2376\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2993 - accuracy: 0.3275\n",
      "Epoch 21: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 532ms/step - loss: 1.2993 - accuracy: 0.3275 - val_loss: 1.4191 - val_accuracy: 0.2574\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2868 - accuracy: 0.3400\n",
      "Epoch 22: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 1.2868 - accuracy: 0.3400 - val_loss: 1.4546 - val_accuracy: 0.2970\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2772 - accuracy: 0.3650\n",
      "Epoch 23: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 1.2772 - accuracy: 0.3650 - val_loss: 1.4095 - val_accuracy: 0.2772\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2613 - accuracy: 0.3600\n",
      "Epoch 24: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 1.2613 - accuracy: 0.3600 - val_loss: 1.4890 - val_accuracy: 0.3069\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2373 - accuracy: 0.3575\n",
      "Epoch 25: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 1.2373 - accuracy: 0.3575 - val_loss: 1.3894 - val_accuracy: 0.2673\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2531 - accuracy: 0.3425\n",
      "Epoch 26: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 1.2531 - accuracy: 0.3425 - val_loss: 1.4290 - val_accuracy: 0.2871\n",
      "Epoch 27/400\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1988 - accuracy: 0.3672\n",
      "Epoch 27: val_loss did not improve from 1.38716\n",
      "2/2 [==============================] - -1s -1454929us/step - loss: 1.2701 - accuracy: 0.3550 - val_loss: 1.4190 - val_accuracy: 0.2574\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2458 - accuracy: 0.3400\n",
      "Epoch 28: val_loss improved from 1.38716 to 1.35896, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 2s 918ms/step - loss: 1.2458 - accuracy: 0.3400 - val_loss: 1.3590 - val_accuracy: 0.1980\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2992 - accuracy: 0.3100\n",
      "Epoch 29: val_loss improved from 1.35896 to 1.35633, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 2s 802ms/step - loss: 1.2992 - accuracy: 0.3100 - val_loss: 1.3563 - val_accuracy: 0.1782\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2875 - accuracy: 0.3250\n",
      "Epoch 30: val_loss improved from 1.35633 to 1.34338, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 2s 740ms/step - loss: 1.2875 - accuracy: 0.3250 - val_loss: 1.3434 - val_accuracy: 0.2376\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2290 - accuracy: 0.3500\n",
      "Epoch 31: val_loss did not improve from 1.34338\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 1.2290 - accuracy: 0.3500 - val_loss: 1.4367 - val_accuracy: 0.2772\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2255 - accuracy: 0.3525\n",
      "Epoch 32: val_loss did not improve from 1.34338\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 1.2255 - accuracy: 0.3525 - val_loss: 1.4844 - val_accuracy: 0.3564\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2226 - accuracy: 0.3600\n",
      "Epoch 33: val_loss did not improve from 1.34338\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 1.2226 - accuracy: 0.3600 - val_loss: 1.3741 - val_accuracy: 0.3069\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1993 - accuracy: 0.3725\n",
      "Epoch 34: val_loss improved from 1.34338 to 1.33417, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 1s 644ms/step - loss: 1.1993 - accuracy: 0.3725 - val_loss: 1.3342 - val_accuracy: 0.2673\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2186 - accuracy: 0.3650\n",
      "Epoch 35: val_loss improved from 1.33417 to 1.32533, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 1s 656ms/step - loss: 1.2186 - accuracy: 0.3650 - val_loss: 1.3253 - val_accuracy: 0.2475\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2128 - accuracy: 0.3650\n",
      "Epoch 36: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 1.2128 - accuracy: 0.3650 - val_loss: 1.3442 - val_accuracy: 0.3069\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1882 - accuracy: 0.3875\n",
      "Epoch 37: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 1.1882 - accuracy: 0.3875 - val_loss: 1.4455 - val_accuracy: 0.3267\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1955 - accuracy: 0.3500\n",
      "Epoch 38: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 1.1955 - accuracy: 0.3500 - val_loss: 1.5019 - val_accuracy: 0.2970\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1926 - accuracy: 0.3650\n",
      "Epoch 39: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 1.1926 - accuracy: 0.3650 - val_loss: 1.4000 - val_accuracy: 0.3168\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1694 - accuracy: 0.4125\n",
      "Epoch 40: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 1.1694 - accuracy: 0.4125 - val_loss: 1.3630 - val_accuracy: 0.2772\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1680 - accuracy: 0.4125\n",
      "Epoch 41: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 1.1680 - accuracy: 0.4125 - val_loss: 1.3816 - val_accuracy: 0.2970\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1590 - accuracy: 0.4225\n",
      "Epoch 42: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 746ms/step - loss: 1.1590 - accuracy: 0.4225 - val_loss: 1.4460 - val_accuracy: 0.3366\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1390 - accuracy: 0.4275\n",
      "Epoch 43: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 1.1390 - accuracy: 0.4275 - val_loss: 1.4791 - val_accuracy: 0.3267\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1310 - accuracy: 0.4325\n",
      "Epoch 44: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 1.1310 - accuracy: 0.4325 - val_loss: 1.4477 - val_accuracy: 0.3168\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1093 - accuracy: 0.4575\n",
      "Epoch 45: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 1.1093 - accuracy: 0.4575 - val_loss: 1.4518 - val_accuracy: 0.3168\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1032 - accuracy: 0.4650\n",
      "Epoch 46: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 1.1032 - accuracy: 0.4650 - val_loss: 1.4870 - val_accuracy: 0.3168\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0877 - accuracy: 0.4700\n",
      "Epoch 47: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 1.0877 - accuracy: 0.4700 - val_loss: 1.4622 - val_accuracy: 0.3465\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.5050\n",
      "Epoch 48: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 1.0655 - accuracy: 0.5050 - val_loss: 1.4601 - val_accuracy: 0.3366\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0711 - accuracy: 0.4950\n",
      "Epoch 49: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 690ms/step - loss: 1.0711 - accuracy: 0.4950 - val_loss: 1.4747 - val_accuracy: 0.3168\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0507 - accuracy: 0.5125\n",
      "Epoch 50: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 660ms/step - loss: 1.0507 - accuracy: 0.5125 - val_loss: 1.4323 - val_accuracy: 0.3267\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0179 - accuracy: 0.5225\n",
      "Epoch 51: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 1.0179 - accuracy: 0.5225 - val_loss: 1.4339 - val_accuracy: 0.3564\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.5275\n",
      "Epoch 52: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 1.0057 - accuracy: 0.5275 - val_loss: 1.4513 - val_accuracy: 0.3168\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.5400\n",
      "Epoch 53: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.9983 - accuracy: 0.5400 - val_loss: 1.5225 - val_accuracy: 0.3663\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9879 - accuracy: 0.5700\n",
      "Epoch 54: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.9879 - accuracy: 0.5700 - val_loss: 1.4265 - val_accuracy: 0.3663\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.4775\n",
      "Epoch 55: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 1.0234 - accuracy: 0.4775 - val_loss: 1.4176 - val_accuracy: 0.3960\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9576 - accuracy: 0.5500\n",
      "Epoch 56: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.9576 - accuracy: 0.5500 - val_loss: 1.3991 - val_accuracy: 0.3663\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.5675\n",
      "Epoch 57: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.9714 - accuracy: 0.5675 - val_loss: 1.3442 - val_accuracy: 0.4257\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9427 - accuracy: 0.5700\n",
      "Epoch 58: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.9427 - accuracy: 0.5700 - val_loss: 1.3446 - val_accuracy: 0.4356\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9403 - accuracy: 0.5800\n",
      "Epoch 59: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.9403 - accuracy: 0.5800 - val_loss: 1.4087 - val_accuracy: 0.4158\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8978 - accuracy: 0.6075\n",
      "Epoch 60: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.8978 - accuracy: 0.6075 - val_loss: 1.3973 - val_accuracy: 0.4356\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.6100\n",
      "Epoch 61: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.8762 - accuracy: 0.6100 - val_loss: 1.4913 - val_accuracy: 0.4059\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.6000\n",
      "Epoch 62: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.8725 - accuracy: 0.6000 - val_loss: 1.3975 - val_accuracy: 0.4455\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8897 - accuracy: 0.6000\n",
      "Epoch 63: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.8897 - accuracy: 0.6000 - val_loss: 1.4968 - val_accuracy: 0.4158\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8323 - accuracy: 0.6425\n",
      "Epoch 64: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 4s 3s/step - loss: 0.8323 - accuracy: 0.6425 - val_loss: 1.4566 - val_accuracy: 0.4257\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9007 - accuracy: 0.6025\n",
      "Epoch 65: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 898ms/step - loss: 0.9007 - accuracy: 0.6025 - val_loss: 1.7520 - val_accuracy: 0.2871\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.5725\n",
      "Epoch 66: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.9625 - accuracy: 0.5725 - val_loss: 1.4041 - val_accuracy: 0.4554\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9185 - accuracy: 0.5675\n",
      "Epoch 67: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 687ms/step - loss: 0.9185 - accuracy: 0.5675 - val_loss: 1.5878 - val_accuracy: 0.3465\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8818 - accuracy: 0.6150\n",
      "Epoch 68: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.8818 - accuracy: 0.6150 - val_loss: 1.3664 - val_accuracy: 0.4554\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8588 - accuracy: 0.6500\n",
      "Epoch 69: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.8588 - accuracy: 0.6500 - val_loss: 1.3543 - val_accuracy: 0.4653\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.6575\n",
      "Epoch 70: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 0.8275 - accuracy: 0.6575 - val_loss: 1.6673 - val_accuracy: 0.3762\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.5950\n",
      "Epoch 71: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.9085 - accuracy: 0.5950 - val_loss: 1.4327 - val_accuracy: 0.4752\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.5825\n",
      "Epoch 72: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.8853 - accuracy: 0.5825 - val_loss: 1.3966 - val_accuracy: 0.4257\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8035 - accuracy: 0.6525\n",
      "Epoch 73: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.8035 - accuracy: 0.6525 - val_loss: 1.3858 - val_accuracy: 0.4257\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.6450\n",
      "Epoch 74: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.7967 - accuracy: 0.6450 - val_loss: 1.3620 - val_accuracy: 0.5149\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.6600\n",
      "Epoch 75: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 0.7574 - accuracy: 0.6600 - val_loss: 1.5294 - val_accuracy: 0.4257\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.6675\n",
      "Epoch 76: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 177s 176s/step - loss: 0.7976 - accuracy: 0.6675 - val_loss: 1.3761 - val_accuracy: 0.4752\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.6750\n",
      "Epoch 77: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 897ms/step - loss: 0.7498 - accuracy: 0.6750 - val_loss: 1.3970 - val_accuracy: 0.4554\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.7025\n",
      "Epoch 78: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 856ms/step - loss: 0.7276 - accuracy: 0.7025 - val_loss: 1.4372 - val_accuracy: 0.4554\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.7025\n",
      "Epoch 79: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7199 - accuracy: 0.7025 - val_loss: 1.4176 - val_accuracy: 0.4851\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.6750\n",
      "Epoch 80: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7226 - accuracy: 0.6750 - val_loss: 1.4480 - val_accuracy: 0.4455\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7225\n",
      "Epoch 81: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 907ms/step - loss: 0.6874 - accuracy: 0.7225 - val_loss: 1.3524 - val_accuracy: 0.5149\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7125\n",
      "Epoch 82: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 0.6907 - accuracy: 0.7125 - val_loss: 1.4798 - val_accuracy: 0.4554\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.7050\n",
      "Epoch 83: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 608ms/step - loss: 0.6957 - accuracy: 0.7050 - val_loss: 1.3763 - val_accuracy: 0.4950\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7247 - accuracy: 0.7100\n",
      "Epoch 84: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 680ms/step - loss: 0.7247 - accuracy: 0.7100 - val_loss: 1.4481 - val_accuracy: 0.4455\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.7025\n",
      "Epoch 85: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 681ms/step - loss: 0.7241 - accuracy: 0.7025 - val_loss: 1.4071 - val_accuracy: 0.4455\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7125\n",
      "Epoch 86: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 642ms/step - loss: 0.6931 - accuracy: 0.7125 - val_loss: 1.4419 - val_accuracy: 0.4356\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.7025\n",
      "Epoch 87: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 667ms/step - loss: 0.6889 - accuracy: 0.7025 - val_loss: 1.3977 - val_accuracy: 0.4752\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6722 - accuracy: 0.7125\n",
      "Epoch 88: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.6722 - accuracy: 0.7125 - val_loss: 1.5046 - val_accuracy: 0.3861\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.7275\n",
      "Epoch 89: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 768ms/step - loss: 0.6656 - accuracy: 0.7275 - val_loss: 1.4556 - val_accuracy: 0.4455\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.7175\n",
      "Epoch 90: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 776ms/step - loss: 0.6688 - accuracy: 0.7175 - val_loss: 1.5914 - val_accuracy: 0.4356\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.7250\n",
      "Epoch 91: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 736ms/step - loss: 0.6802 - accuracy: 0.7250 - val_loss: 1.5304 - val_accuracy: 0.4455\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6029 - accuracy: 0.7375\n",
      "Epoch 92: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 613ms/step - loss: 0.6029 - accuracy: 0.7375 - val_loss: 1.6956 - val_accuracy: 0.3465\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.7375\n",
      "Epoch 93: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 593ms/step - loss: 0.6303 - accuracy: 0.7375 - val_loss: 1.5059 - val_accuracy: 0.4257\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.7575\n",
      "Epoch 94: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 0.6356 - accuracy: 0.7575 - val_loss: 1.6086 - val_accuracy: 0.3663\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.7525\n",
      "Epoch 95: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 649ms/step - loss: 0.6605 - accuracy: 0.7525 - val_loss: 1.4896 - val_accuracy: 0.4257\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.7550\n",
      "Epoch 96: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 832ms/step - loss: 0.6348 - accuracy: 0.7550 - val_loss: 1.4522 - val_accuracy: 0.4653\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7325\n",
      "Epoch 97: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 728ms/step - loss: 0.6173 - accuracy: 0.7325 - val_loss: 1.5644 - val_accuracy: 0.4158\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7725\n",
      "Epoch 98: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 740ms/step - loss: 0.5794 - accuracy: 0.7725 - val_loss: 1.6878 - val_accuracy: 0.4257\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.7625\n",
      "Epoch 99: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 772ms/step - loss: 0.6212 - accuracy: 0.7625 - val_loss: 1.6940 - val_accuracy: 0.4752\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.7175\n",
      "Epoch 100: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 0.6698 - accuracy: 0.7175 - val_loss: 1.4530 - val_accuracy: 0.4851\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7725\n",
      "Epoch 101: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 648ms/step - loss: 0.5869 - accuracy: 0.7725 - val_loss: 1.5139 - val_accuracy: 0.4356\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 0.7450\n",
      "Epoch 102: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.6074 - accuracy: 0.7450 - val_loss: 1.4726 - val_accuracy: 0.4950\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.7500\n",
      "Epoch 103: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 585ms/step - loss: 0.6046 - accuracy: 0.7500 - val_loss: 1.4470 - val_accuracy: 0.4851\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.7750\n",
      "Epoch 104: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.5803 - accuracy: 0.7750 - val_loss: 1.6558 - val_accuracy: 0.3762\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7950\n",
      "Epoch 105: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.5543 - accuracy: 0.7950 - val_loss: 1.6616 - val_accuracy: 0.3861\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7900\n",
      "Epoch 106: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.5303 - accuracy: 0.7900 - val_loss: 1.6894 - val_accuracy: 0.4158\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7775\n",
      "Epoch 107: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 0.5480 - accuracy: 0.7775 - val_loss: 1.6236 - val_accuracy: 0.4257\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7900\n",
      "Epoch 108: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.5376 - accuracy: 0.7900 - val_loss: 1.5132 - val_accuracy: 0.4554\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7775\n",
      "Epoch 109: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.5616 - accuracy: 0.7775 - val_loss: 1.5477 - val_accuracy: 0.4653\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8075\n",
      "Epoch 110: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.5043 - accuracy: 0.8075 - val_loss: 1.7368 - val_accuracy: 0.4257\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8250\n",
      "Epoch 111: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.4849 - accuracy: 0.8250 - val_loss: 1.6489 - val_accuracy: 0.4356\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.8200\n",
      "Epoch 112: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.4866 - accuracy: 0.8200 - val_loss: 1.5148 - val_accuracy: 0.5446\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.7450\n",
      "Epoch 113: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.6080 - accuracy: 0.7450 - val_loss: 1.5345 - val_accuracy: 0.4851\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7875\n",
      "Epoch 114: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.5632 - accuracy: 0.7875 - val_loss: 1.5426 - val_accuracy: 0.4554\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.8175\n",
      "Epoch 115: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.5056 - accuracy: 0.8175 - val_loss: 1.5792 - val_accuracy: 0.4554\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8300\n",
      "Epoch 116: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 719ms/step - loss: 0.4936 - accuracy: 0.8300 - val_loss: 1.4889 - val_accuracy: 0.5050\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.8150\n",
      "Epoch 117: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 661ms/step - loss: 0.5141 - accuracy: 0.8150 - val_loss: 1.5568 - val_accuracy: 0.4752\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8450\n",
      "Epoch 118: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.4650 - accuracy: 0.8450 - val_loss: 1.5802 - val_accuracy: 0.4455\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8275\n",
      "Epoch 119: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.4675 - accuracy: 0.8275 - val_loss: 1.6308 - val_accuracy: 0.4554\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8450\n",
      "Epoch 120: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.4624 - accuracy: 0.8450 - val_loss: 1.7447 - val_accuracy: 0.4257\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8375\n",
      "Epoch 121: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.4979 - accuracy: 0.8375 - val_loss: 1.5800 - val_accuracy: 0.4455\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8450\n",
      "Epoch 122: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 0.4388 - accuracy: 0.8450 - val_loss: 1.8383 - val_accuracy: 0.4455\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8425\n",
      "Epoch 123: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 0.4357 - accuracy: 0.8425 - val_loss: 1.4024 - val_accuracy: 0.5248\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8425\n",
      "Epoch 124: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 650ms/step - loss: 0.4247 - accuracy: 0.8425 - val_loss: 2.0425 - val_accuracy: 0.3465\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7950\n",
      "Epoch 125: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 0.4899 - accuracy: 0.7950 - val_loss: 1.4857 - val_accuracy: 0.5941\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.8100\n",
      "Epoch 126: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.5172 - accuracy: 0.8100 - val_loss: 1.8664 - val_accuracy: 0.3960\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.8075\n",
      "Epoch 127: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 0.4559 - accuracy: 0.8075 - val_loss: 1.3515 - val_accuracy: 0.5842\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8575\n",
      "Epoch 128: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.4044 - accuracy: 0.8575 - val_loss: 1.9066 - val_accuracy: 0.3960\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8525\n",
      "Epoch 129: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.4221 - accuracy: 0.8525 - val_loss: 1.5903 - val_accuracy: 0.4851\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8550\n",
      "Epoch 130: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 0.3995 - accuracy: 0.8550 - val_loss: 1.7798 - val_accuracy: 0.3861\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8725\n",
      "Epoch 131: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.3838 - accuracy: 0.8725 - val_loss: 1.6194 - val_accuracy: 0.4554\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8800\n",
      "Epoch 132: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.3675 - accuracy: 0.8800 - val_loss: 1.7301 - val_accuracy: 0.4158\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.8450\n",
      "Epoch 133: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 539ms/step - loss: 0.3986 - accuracy: 0.8450 - val_loss: 1.6057 - val_accuracy: 0.4554\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8725\n",
      "Epoch 134: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.3826 - accuracy: 0.8725 - val_loss: 1.8426 - val_accuracy: 0.4158\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.8550\n",
      "Epoch 135: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.4210 - accuracy: 0.8550 - val_loss: 1.9720 - val_accuracy: 0.4059\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8800\n",
      "Epoch 136: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 0.3717 - accuracy: 0.8800 - val_loss: 1.3834 - val_accuracy: 0.6337\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.8325\n",
      "Epoch 137: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.4402 - accuracy: 0.8325 - val_loss: 2.1361 - val_accuracy: 0.3861\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8500\n",
      "Epoch 138: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.3940 - accuracy: 0.8500 - val_loss: 1.4509 - val_accuracy: 0.6337\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.8500\n",
      "Epoch 139: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.4109 - accuracy: 0.8500 - val_loss: 2.1800 - val_accuracy: 0.3861\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.8375\n",
      "Epoch 140: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 2s 670ms/step - loss: 0.4259 - accuracy: 0.8375 - val_loss: 1.4149 - val_accuracy: 0.6139\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.8625\n",
      "Epoch 141: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 531ms/step - loss: 0.3719 - accuracy: 0.8625 - val_loss: 2.3870 - val_accuracy: 0.3564\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8350\n",
      "Epoch 142: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.3911 - accuracy: 0.8350 - val_loss: 1.6751 - val_accuracy: 0.5842\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7150\n",
      "Epoch 143: val_loss did not improve from 1.32533\n",
      "2/2 [==============================] - 1s 622ms/step - loss: 0.6925 - accuracy: 0.7150 - val_loss: 2.2909 - val_accuracy: 0.3762\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7375\n",
      "Epoch 144: val_loss improved from 1.32533 to 1.30251, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 2s 785ms/step - loss: 0.5602 - accuracy: 0.7375 - val_loss: 1.3025 - val_accuracy: 0.5941\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.7325\n",
      "Epoch 145: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.6666 - accuracy: 0.7325 - val_loss: 1.6879 - val_accuracy: 0.4752\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8125\n",
      "Epoch 146: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.4713 - accuracy: 0.8125 - val_loss: 1.9318 - val_accuracy: 0.4059\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8525\n",
      "Epoch 147: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 2s 653ms/step - loss: 0.4116 - accuracy: 0.8525 - val_loss: 1.5718 - val_accuracy: 0.5347\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8425\n",
      "Epoch 148: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.4264 - accuracy: 0.8425 - val_loss: 2.3973 - val_accuracy: 0.3564\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8425\n",
      "Epoch 149: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.3935 - accuracy: 0.8425 - val_loss: 1.8000 - val_accuracy: 0.4851\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8675\n",
      "Epoch 150: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.3422 - accuracy: 0.8675 - val_loss: 1.8800 - val_accuracy: 0.4554\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8900\n",
      "Epoch 151: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 0.3424 - accuracy: 0.8900 - val_loss: 2.1527 - val_accuracy: 0.4059\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8925\n",
      "Epoch 152: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 655ms/step - loss: 0.3254 - accuracy: 0.8925 - val_loss: 1.4659 - val_accuracy: 0.5941\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8725\n",
      "Epoch 153: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 0.4067 - accuracy: 0.8725 - val_loss: 2.0308 - val_accuracy: 0.4257\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8850\n",
      "Epoch 154: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.3508 - accuracy: 0.8850 - val_loss: 1.9873 - val_accuracy: 0.4356\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8900\n",
      "Epoch 155: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 0.3218 - accuracy: 0.8900 - val_loss: 1.6358 - val_accuracy: 0.5644\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.8675\n",
      "Epoch 156: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.3360 - accuracy: 0.8675 - val_loss: 2.1909 - val_accuracy: 0.3861\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.9125\n",
      "Epoch 157: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.2962 - accuracy: 0.9125 - val_loss: 1.7668 - val_accuracy: 0.5050\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9025\n",
      "Epoch 158: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.2861 - accuracy: 0.9025 - val_loss: 1.9595 - val_accuracy: 0.4356\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.9075\n",
      "Epoch 159: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.2827 - accuracy: 0.9075 - val_loss: 1.9039 - val_accuracy: 0.4554\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.9075\n",
      "Epoch 160: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.2804 - accuracy: 0.9075 - val_loss: 1.6116 - val_accuracy: 0.5545\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.9125\n",
      "Epoch 161: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 716ms/step - loss: 0.2672 - accuracy: 0.9125 - val_loss: 1.9552 - val_accuracy: 0.4653\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.9100\n",
      "Epoch 162: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 2s 716ms/step - loss: 0.2845 - accuracy: 0.9100 - val_loss: 1.6155 - val_accuracy: 0.5743\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9125\n",
      "Epoch 163: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 0.2564 - accuracy: 0.9125 - val_loss: 1.6241 - val_accuracy: 0.5842\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.9175\n",
      "Epoch 164: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.2604 - accuracy: 0.9175 - val_loss: 1.9533 - val_accuracy: 0.4455\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9200\n",
      "Epoch 165: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 630ms/step - loss: 0.2715 - accuracy: 0.9200 - val_loss: 1.4700 - val_accuracy: 0.6040\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9225\n",
      "Epoch 166: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.2421 - accuracy: 0.9225 - val_loss: 1.9658 - val_accuracy: 0.4653\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9350\n",
      "Epoch 167: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.2319 - accuracy: 0.9350 - val_loss: 1.8472 - val_accuracy: 0.5347\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.9075\n",
      "Epoch 168: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 539ms/step - loss: 0.2859 - accuracy: 0.9075 - val_loss: 1.5469 - val_accuracy: 0.5644\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9325\n",
      "Epoch 169: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 2s 766ms/step - loss: 0.2331 - accuracy: 0.9325 - val_loss: 1.6690 - val_accuracy: 0.5050\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.9225\n",
      "Epoch 170: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 2s 628ms/step - loss: 0.2397 - accuracy: 0.9225 - val_loss: 1.5980 - val_accuracy: 0.5347\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9325\n",
      "Epoch 171: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.2246 - accuracy: 0.9325 - val_loss: 2.0117 - val_accuracy: 0.4356\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.9150\n",
      "Epoch 172: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.2741 - accuracy: 0.9150 - val_loss: 1.7089 - val_accuracy: 0.5248\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9275\n",
      "Epoch 173: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.2233 - accuracy: 0.9275 - val_loss: 1.6453 - val_accuracy: 0.5248\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9425\n",
      "Epoch 174: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 694ms/step - loss: 0.2214 - accuracy: 0.9425 - val_loss: 1.7314 - val_accuracy: 0.5347\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9450\n",
      "Epoch 175: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.1870 - accuracy: 0.9450 - val_loss: 1.8996 - val_accuracy: 0.5446\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9300\n",
      "Epoch 176: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.2190 - accuracy: 0.9300 - val_loss: 1.8201 - val_accuracy: 0.5347\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9500\n",
      "Epoch 177: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.1864 - accuracy: 0.9500 - val_loss: 1.6389 - val_accuracy: 0.5545\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9550\n",
      "Epoch 178: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.1710 - accuracy: 0.9550 - val_loss: 2.0922 - val_accuracy: 0.4257\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.9375\n",
      "Epoch 179: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.2338 - accuracy: 0.9375 - val_loss: 1.5857 - val_accuracy: 0.5842\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9250\n",
      "Epoch 180: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 0.2083 - accuracy: 0.9250 - val_loss: 2.2945 - val_accuracy: 0.3960\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9175\n",
      "Epoch 181: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.2751 - accuracy: 0.9175 - val_loss: 1.4193 - val_accuracy: 0.6337\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9300\n",
      "Epoch 182: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 531ms/step - loss: 0.2327 - accuracy: 0.9300 - val_loss: 1.6622 - val_accuracy: 0.5446\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9300\n",
      "Epoch 183: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.2016 - accuracy: 0.9300 - val_loss: 1.7063 - val_accuracy: 0.5545\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9450\n",
      "Epoch 184: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.1877 - accuracy: 0.9450 - val_loss: 1.6917 - val_accuracy: 0.5545\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9300\n",
      "Epoch 185: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 2s 692ms/step - loss: 0.2214 - accuracy: 0.9300 - val_loss: 1.4444 - val_accuracy: 0.6436\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9300\n",
      "Epoch 186: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.2125 - accuracy: 0.9300 - val_loss: 1.6580 - val_accuracy: 0.5446\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9400\n",
      "Epoch 187: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 0.1964 - accuracy: 0.9400 - val_loss: 1.7947 - val_accuracy: 0.5644\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9350\n",
      "Epoch 188: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 0.2045 - accuracy: 0.9350 - val_loss: 1.9765 - val_accuracy: 0.4554\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9250\n",
      "Epoch 189: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.2158 - accuracy: 0.9250 - val_loss: 1.3181 - val_accuracy: 0.6238\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9175\n",
      "Epoch 190: val_loss did not improve from 1.30251\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.2108 - accuracy: 0.9175 - val_loss: 1.9598 - val_accuracy: 0.4554\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9175\n",
      "Epoch 191: val_loss improved from 1.30251 to 1.29530, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 1s 753ms/step - loss: 0.2243 - accuracy: 0.9175 - val_loss: 1.2953 - val_accuracy: 0.6832\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.9175\n",
      "Epoch 192: val_loss did not improve from 1.29530\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.2498 - accuracy: 0.9175 - val_loss: 2.2388 - val_accuracy: 0.4356\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9200\n",
      "Epoch 193: val_loss improved from 1.29530 to 1.24536, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 2s 755ms/step - loss: 0.2260 - accuracy: 0.9200 - val_loss: 1.2454 - val_accuracy: 0.6733\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9175\n",
      "Epoch 194: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.2490 - accuracy: 0.9175 - val_loss: 1.9021 - val_accuracy: 0.4851\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9450\n",
      "Epoch 195: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.1766 - accuracy: 0.9450 - val_loss: 1.7585 - val_accuracy: 0.5545\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9750\n",
      "Epoch 196: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 671ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 1.5107 - val_accuracy: 0.6436\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9500\n",
      "Epoch 197: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 0.1561 - accuracy: 0.9500 - val_loss: 1.7509 - val_accuracy: 0.5545\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9700\n",
      "Epoch 198: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.1099 - accuracy: 0.9700 - val_loss: 1.9632 - val_accuracy: 0.4851\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9625\n",
      "Epoch 199: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.1292 - accuracy: 0.9625 - val_loss: 1.7223 - val_accuracy: 0.5545\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9750\n",
      "Epoch 200: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.1032 - accuracy: 0.9750 - val_loss: 1.7936 - val_accuracy: 0.5644\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9700\n",
      "Epoch 201: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.1383 - accuracy: 0.9700 - val_loss: 1.7054 - val_accuracy: 0.5545\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9600\n",
      "Epoch 202: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.1297 - accuracy: 0.9600 - val_loss: 1.6915 - val_accuracy: 0.5941\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9675\n",
      "Epoch 203: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.1142 - accuracy: 0.9675 - val_loss: 1.8612 - val_accuracy: 0.5347\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9600\n",
      "Epoch 204: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 0.1120 - accuracy: 0.9600 - val_loss: 1.8149 - val_accuracy: 0.5347\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9850\n",
      "Epoch 205: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 0.0801 - accuracy: 0.9850 - val_loss: 1.6604 - val_accuracy: 0.6040\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9775\n",
      "Epoch 206: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 0.0917 - accuracy: 0.9775 - val_loss: 1.7300 - val_accuracy: 0.5743\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9675\n",
      "Epoch 207: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 658ms/step - loss: 0.1028 - accuracy: 0.9675 - val_loss: 1.7484 - val_accuracy: 0.5545\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9750\n",
      "Epoch 208: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 2s 684ms/step - loss: 0.0956 - accuracy: 0.9750 - val_loss: 1.6410 - val_accuracy: 0.6040\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9725\n",
      "Epoch 209: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.0881 - accuracy: 0.9725 - val_loss: 1.8157 - val_accuracy: 0.5149\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9725\n",
      "Epoch 210: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.1143 - accuracy: 0.9725 - val_loss: 1.7093 - val_accuracy: 0.5545\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9650\n",
      "Epoch 211: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 0.0954 - accuracy: 0.9650 - val_loss: 2.1393 - val_accuracy: 0.4455\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9675\n",
      "Epoch 212: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.1083 - accuracy: 0.9675 - val_loss: 1.6059 - val_accuracy: 0.6238\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9750\n",
      "Epoch 213: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0792 - accuracy: 0.9750 - val_loss: 1.6762 - val_accuracy: 0.5842\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9650\n",
      "Epoch 214: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 539ms/step - loss: 0.1041 - accuracy: 0.9650 - val_loss: 2.0819 - val_accuracy: 0.4950\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9750\n",
      "Epoch 215: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 0.0967 - accuracy: 0.9750 - val_loss: 1.5129 - val_accuracy: 0.6238\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9600\n",
      "Epoch 216: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.1232 - accuracy: 0.9600 - val_loss: 1.8964 - val_accuracy: 0.5446\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9775\n",
      "Epoch 217: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0984 - accuracy: 0.9775 - val_loss: 1.7933 - val_accuracy: 0.5941\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9650\n",
      "Epoch 218: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 0.1060 - accuracy: 0.9650 - val_loss: 1.6810 - val_accuracy: 0.6139\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9775\n",
      "Epoch 219: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 1.8797 - val_accuracy: 0.5446\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9700\n",
      "Epoch 220: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 1.6336 - val_accuracy: 0.6238\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9700\n",
      "Epoch 221: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.0959 - accuracy: 0.9700 - val_loss: 2.1260 - val_accuracy: 0.5446\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9650\n",
      "Epoch 222: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 573ms/step - loss: 0.1196 - accuracy: 0.9650 - val_loss: 1.7627 - val_accuracy: 0.6238\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9575\n",
      "Epoch 223: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 2s 708ms/step - loss: 0.1386 - accuracy: 0.9575 - val_loss: 1.9592 - val_accuracy: 0.5644\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9625\n",
      "Epoch 224: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.1054 - accuracy: 0.9625 - val_loss: 1.7203 - val_accuracy: 0.6040\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9725\n",
      "Epoch 225: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.0940 - accuracy: 0.9725 - val_loss: 1.7438 - val_accuracy: 0.5941\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9525\n",
      "Epoch 226: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.1347 - accuracy: 0.9525 - val_loss: 1.6185 - val_accuracy: 0.5842\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9625\n",
      "Epoch 227: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0976 - accuracy: 0.9625 - val_loss: 1.4359 - val_accuracy: 0.6634\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9625\n",
      "Epoch 228: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.1229 - accuracy: 0.9625 - val_loss: 2.1623 - val_accuracy: 0.4950\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9725\n",
      "Epoch 229: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 592ms/step - loss: 0.1050 - accuracy: 0.9725 - val_loss: 1.4441 - val_accuracy: 0.6733\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9350\n",
      "Epoch 230: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 2s 674ms/step - loss: 0.1538 - accuracy: 0.9350 - val_loss: 2.5136 - val_accuracy: 0.4257\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9250\n",
      "Epoch 231: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 0.1797 - accuracy: 0.9250 - val_loss: 1.2930 - val_accuracy: 0.7030\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.9325\n",
      "Epoch 232: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.1558 - accuracy: 0.9325 - val_loss: 2.5991 - val_accuracy: 0.4158\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9075\n",
      "Epoch 233: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.2331 - accuracy: 0.9075 - val_loss: 1.4004 - val_accuracy: 0.6832\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8575\n",
      "Epoch 234: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.3503 - accuracy: 0.8575 - val_loss: 2.8701 - val_accuracy: 0.3465\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8875\n",
      "Epoch 235: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.2987 - accuracy: 0.8875 - val_loss: 1.3219 - val_accuracy: 0.7327\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8350\n",
      "Epoch 236: val_loss did not improve from 1.24536\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.4389 - accuracy: 0.8350 - val_loss: 3.3725 - val_accuracy: 0.2772\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.7425\n",
      "Epoch 237: val_loss improved from 1.24536 to 1.19880, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 1s 694ms/step - loss: 0.6948 - accuracy: 0.7425 - val_loss: 1.1988 - val_accuracy: 0.7030\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.7700\n",
      "Epoch 238: val_loss did not improve from 1.19880\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.6816 - accuracy: 0.7700 - val_loss: 2.1955 - val_accuracy: 0.4950\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8925\n",
      "Epoch 239: val_loss did not improve from 1.19880\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.2912 - accuracy: 0.8925 - val_loss: 2.1898 - val_accuracy: 0.4752\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9625\n",
      "Epoch 240: val_loss did not improve from 1.19880\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.1104 - accuracy: 0.9625 - val_loss: 1.3607 - val_accuracy: 0.6832\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8925\n",
      "Epoch 241: val_loss did not improve from 1.19880\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.2726 - accuracy: 0.8925 - val_loss: 2.4066 - val_accuracy: 0.4653\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9425\n",
      "Epoch 242: val_loss did not improve from 1.19880\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.2044 - accuracy: 0.9425 - val_loss: 1.7705 - val_accuracy: 0.5842\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9725\n",
      "Epoch 243: val_loss improved from 1.19880 to 1.17356, saving model to saved_models/weights.best.basic_mlp.h5\n",
      "2/2 [==============================] - 1s 691ms/step - loss: 0.0974 - accuracy: 0.9725 - val_loss: 1.1736 - val_accuracy: 0.7228\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9650\n",
      "Epoch 244: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.1345 - accuracy: 0.9650 - val_loss: 1.6937 - val_accuracy: 0.5842\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9550\n",
      "Epoch 245: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.1181 - accuracy: 0.9550 - val_loss: 2.1177 - val_accuracy: 0.5050\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9550\n",
      "Epoch 246: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 769ms/step - loss: 0.1216 - accuracy: 0.9550 - val_loss: 1.4620 - val_accuracy: 0.6634\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9625\n",
      "Epoch 247: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.1509 - accuracy: 0.9625 - val_loss: 1.5281 - val_accuracy: 0.6436\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9675\n",
      "Epoch 248: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0947 - accuracy: 0.9675 - val_loss: 2.1838 - val_accuracy: 0.5149\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9450\n",
      "Epoch 249: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 634ms/step - loss: 0.1386 - accuracy: 0.9450 - val_loss: 1.6200 - val_accuracy: 0.5743\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9850\n",
      "Epoch 250: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.0711 - accuracy: 0.9850 - val_loss: 1.2672 - val_accuracy: 0.7327\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9575\n",
      "Epoch 251: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 0.1356 - accuracy: 0.9575 - val_loss: 1.7860 - val_accuracy: 0.5545\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9875\n",
      "Epoch 252: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 0.0687 - accuracy: 0.9875 - val_loss: 2.2136 - val_accuracy: 0.4950\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9625\n",
      "Epoch 253: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 703ms/step - loss: 0.1220 - accuracy: 0.9625 - val_loss: 1.5109 - val_accuracy: 0.6832\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9625\n",
      "Epoch 254: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 640ms/step - loss: 0.1038 - accuracy: 0.9625 - val_loss: 1.5117 - val_accuracy: 0.6634\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9700\n",
      "Epoch 255: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.0789 - accuracy: 0.9700 - val_loss: 1.9855 - val_accuracy: 0.5248\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9575\n",
      "Epoch 256: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 0.1155 - accuracy: 0.9575 - val_loss: 1.7098 - val_accuracy: 0.5941\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9700\n",
      "Epoch 257: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.1005 - accuracy: 0.9700 - val_loss: 1.4327 - val_accuracy: 0.6931\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9850\n",
      "Epoch 258: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.0800 - accuracy: 0.9850 - val_loss: 1.7345 - val_accuracy: 0.5842\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9750\n",
      "Epoch 259: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 1.8803 - val_accuracy: 0.5842\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9925\n",
      "Epoch 260: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.0585 - accuracy: 0.9925 - val_loss: 1.7121 - val_accuracy: 0.6337\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9925\n",
      "Epoch 261: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0508 - accuracy: 0.9925 - val_loss: 1.5657 - val_accuracy: 0.6535\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9950\n",
      "Epoch 262: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.0485 - accuracy: 0.9950 - val_loss: 1.5591 - val_accuracy: 0.6535\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9900\n",
      "Epoch 263: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.0592 - accuracy: 0.9900 - val_loss: 1.6696 - val_accuracy: 0.6337\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9875\n",
      "Epoch 264: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0504 - accuracy: 0.9875 - val_loss: 1.5716 - val_accuracy: 0.6238\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9825\n",
      "Epoch 265: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 619ms/step - loss: 0.0639 - accuracy: 0.9825 - val_loss: 1.5700 - val_accuracy: 0.6337\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9875\n",
      "Epoch 266: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.0595 - accuracy: 0.9875 - val_loss: 1.6026 - val_accuracy: 0.6238\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9900\n",
      "Epoch 267: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0514 - accuracy: 0.9900 - val_loss: 1.6065 - val_accuracy: 0.6436\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9900\n",
      "Epoch 268: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 714ms/step - loss: 0.0422 - accuracy: 0.9900 - val_loss: 1.6815 - val_accuracy: 0.6238\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9850\n",
      "Epoch 269: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 673ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 1.6887 - val_accuracy: 0.6139\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9875\n",
      "Epoch 270: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 0.0519 - accuracy: 0.9875 - val_loss: 1.7477 - val_accuracy: 0.6337\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9850\n",
      "Epoch 271: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0543 - accuracy: 0.9850 - val_loss: 1.5336 - val_accuracy: 0.6832\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9925\n",
      "Epoch 272: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.0437 - accuracy: 0.9925 - val_loss: 1.4918 - val_accuracy: 0.6634\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9825\n",
      "Epoch 273: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 0.0663 - accuracy: 0.9825 - val_loss: 1.6468 - val_accuracy: 0.6040\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9875\n",
      "Epoch 274: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 0.0449 - accuracy: 0.9875 - val_loss: 1.5413 - val_accuracy: 0.6634\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9875\n",
      "Epoch 275: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.0440 - accuracy: 0.9875 - val_loss: 1.6681 - val_accuracy: 0.6436\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9875\n",
      "Epoch 276: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 0.0472 - accuracy: 0.9875 - val_loss: 1.8620 - val_accuracy: 0.6238\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9950\n",
      "Epoch 277: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 651ms/step - loss: 0.0361 - accuracy: 0.9950 - val_loss: 1.6510 - val_accuracy: 0.6436\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9950\n",
      "Epoch 278: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.0367 - accuracy: 0.9950 - val_loss: 1.4836 - val_accuracy: 0.6535\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9850\n",
      "Epoch 279: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.0552 - accuracy: 0.9850 - val_loss: 1.5715 - val_accuracy: 0.6436\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9875\n",
      "Epoch 280: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.0454 - accuracy: 0.9875 - val_loss: 1.5627 - val_accuracy: 0.6238\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9850\n",
      "Epoch 281: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0660 - accuracy: 0.9850 - val_loss: 1.6036 - val_accuracy: 0.6238\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9925\n",
      "Epoch 282: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 1.7476 - val_accuracy: 0.5941\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9875\n",
      "Epoch 283: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.0541 - accuracy: 0.9875 - val_loss: 1.8134 - val_accuracy: 0.5941\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9850\n",
      "Epoch 284: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.0388 - accuracy: 0.9850 - val_loss: 1.7898 - val_accuracy: 0.6139\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9900\n",
      "Epoch 285: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 1.5371 - val_accuracy: 0.6733\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9900\n",
      "Epoch 286: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 1.7061 - val_accuracy: 0.6238\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9950\n",
      "Epoch 287: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0325 - accuracy: 0.9950 - val_loss: 1.7795 - val_accuracy: 0.5941\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9900\n",
      "Epoch 288: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 1.6517 - val_accuracy: 0.6733\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9925\n",
      "Epoch 289: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 1.5341 - val_accuracy: 0.7030\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9850\n",
      "Epoch 290: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.0567 - accuracy: 0.9850 - val_loss: 1.9667 - val_accuracy: 0.5545\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9875\n",
      "Epoch 291: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 754ms/step - loss: 0.0559 - accuracy: 0.9875 - val_loss: 1.7707 - val_accuracy: 0.6436\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9900\n",
      "Epoch 292: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 677ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 1.4094 - val_accuracy: 0.7426\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9725\n",
      "Epoch 293: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0767 - accuracy: 0.9725 - val_loss: 1.8406 - val_accuracy: 0.6337\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9875\n",
      "Epoch 294: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.0527 - accuracy: 0.9875 - val_loss: 1.9672 - val_accuracy: 0.5842\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9850\n",
      "Epoch 295: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.0577 - accuracy: 0.9850 - val_loss: 1.4844 - val_accuracy: 0.6931\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9900\n",
      "Epoch 296: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0461 - accuracy: 0.9900 - val_loss: 1.6530 - val_accuracy: 0.6337\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9900\n",
      "Epoch 297: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 1.9555 - val_accuracy: 0.5743\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9900\n",
      "Epoch 298: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.0433 - accuracy: 0.9900 - val_loss: 1.7156 - val_accuracy: 0.6337\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9875\n",
      "Epoch 299: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 715ms/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 1.4564 - val_accuracy: 0.7030\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9875\n",
      "Epoch 300: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 592ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 1.5810 - val_accuracy: 0.6634\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 301: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.9463 - val_accuracy: 0.5941\n",
      "Epoch 302/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9875\n",
      "Epoch 302: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0444 - accuracy: 0.9875 - val_loss: 1.8298 - val_accuracy: 0.6040\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9975\n",
      "Epoch 303: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 638ms/step - loss: 0.0192 - accuracy: 0.9975 - val_loss: 1.5939 - val_accuracy: 0.6733\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9875\n",
      "Epoch 304: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.0530 - accuracy: 0.9875 - val_loss: 1.7000 - val_accuracy: 0.6337\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9900\n",
      "Epoch 305: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 2.2504 - val_accuracy: 0.5248\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9850\n",
      "Epoch 306: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 1.7738 - val_accuracy: 0.6238\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9950\n",
      "Epoch 307: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 0.0319 - accuracy: 0.9950 - val_loss: 1.3938 - val_accuracy: 0.7327\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9675\n",
      "Epoch 308: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 0.0812 - accuracy: 0.9675 - val_loss: 2.6405 - val_accuracy: 0.4554\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9225\n",
      "Epoch 309: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.1748 - accuracy: 0.9225 - val_loss: 1.3934 - val_accuracy: 0.7426\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9625\n",
      "Epoch 310: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 630ms/step - loss: 0.1160 - accuracy: 0.9625 - val_loss: 1.7185 - val_accuracy: 0.6634\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9950\n",
      "Epoch 311: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 2.3025 - val_accuracy: 0.5941\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9800\n",
      "Epoch 312: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0489 - accuracy: 0.9800 - val_loss: 1.6379 - val_accuracy: 0.7129\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9675\n",
      "Epoch 313: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.0719 - accuracy: 0.9675 - val_loss: 1.6975 - val_accuracy: 0.6535\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9900\n",
      "Epoch 314: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 691ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 2.3379 - val_accuracy: 0.5545\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9600\n",
      "Epoch 315: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 626ms/step - loss: 0.0940 - accuracy: 0.9600 - val_loss: 1.5682 - val_accuracy: 0.6832\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9875\n",
      "Epoch 316: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.0432 - accuracy: 0.9875 - val_loss: 1.4063 - val_accuracy: 0.7129\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9775\n",
      "Epoch 317: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 2.2190 - val_accuracy: 0.5545\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9800\n",
      "Epoch 318: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 2.0525 - val_accuracy: 0.5941\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 319: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 1.6366 - val_accuracy: 0.7129\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9950\n",
      "Epoch 320: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.0280 - accuracy: 0.9950 - val_loss: 1.8274 - val_accuracy: 0.6535\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9950\n",
      "Epoch 321: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0308 - accuracy: 0.9950 - val_loss: 2.2254 - val_accuracy: 0.5842\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9925\n",
      "Epoch 322: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0401 - accuracy: 0.9925 - val_loss: 2.0181 - val_accuracy: 0.6040\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9975\n",
      "Epoch 323: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 1.6752 - val_accuracy: 0.6436\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9975\n",
      "Epoch 324: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.0196 - accuracy: 0.9975 - val_loss: 1.7348 - val_accuracy: 0.6337\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 325: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 648ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 1.9750 - val_accuracy: 0.5644\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9850\n",
      "Epoch 326: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 615ms/step - loss: 0.0364 - accuracy: 0.9850 - val_loss: 1.6651 - val_accuracy: 0.6634\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9950\n",
      "Epoch 327: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.0250 - accuracy: 0.9950 - val_loss: 1.6094 - val_accuracy: 0.6931\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 328: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 1.9740 - val_accuracy: 0.5644\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9900\n",
      "Epoch 329: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 720ms/step - loss: 0.0251 - accuracy: 0.9900 - val_loss: 1.9605 - val_accuracy: 0.5941\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9925\n",
      "Epoch 330: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 651ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 1.5000 - val_accuracy: 0.7228\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9850\n",
      "Epoch 331: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 0.0372 - accuracy: 0.9850 - val_loss: 1.7189 - val_accuracy: 0.6238\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9950\n",
      "Epoch 332: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 1.8543 - val_accuracy: 0.6238\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9900\n",
      "Epoch 333: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0211 - accuracy: 0.9900 - val_loss: 1.7532 - val_accuracy: 0.6535\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 334: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.9205 - val_accuracy: 0.6337\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9975\n",
      "Epoch 335: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 1.9722 - val_accuracy: 0.6238\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9925\n",
      "Epoch 336: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 685ms/step - loss: 0.0188 - accuracy: 0.9925 - val_loss: 1.8953 - val_accuracy: 0.6436\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 337: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 715ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.8828 - val_accuracy: 0.6337\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 338: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.9306 - val_accuracy: 0.6238\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9950\n",
      "Epoch 339: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 1.8598 - val_accuracy: 0.6337\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9950\n",
      "Epoch 340: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 1.7545 - val_accuracy: 0.6535\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9975\n",
      "Epoch 341: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 1.7731 - val_accuracy: 0.6337\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 342: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.9053 - val_accuracy: 0.6337\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 343: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 2.0457 - val_accuracy: 0.6139\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 344: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.0786 - val_accuracy: 0.6139\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 345: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 1.8693 - val_accuracy: 0.6436\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9975\n",
      "Epoch 346: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 0.0159 - accuracy: 0.9975 - val_loss: 1.7467 - val_accuracy: 0.6634\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 347: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 1.9735 - val_accuracy: 0.6337\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9925\n",
      "Epoch 348: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 2.2043 - val_accuracy: 0.6040\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9950\n",
      "Epoch 349: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 1.9866 - val_accuracy: 0.6436\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9925\n",
      "Epoch 350: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0366 - accuracy: 0.9925 - val_loss: 1.7670 - val_accuracy: 0.6832\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9975\n",
      "Epoch 351: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 723ms/step - loss: 0.0236 - accuracy: 0.9975 - val_loss: 1.8239 - val_accuracy: 0.6733\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 352: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 662ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.1367 - val_accuracy: 0.6238\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 353: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 2.1844 - val_accuracy: 0.6238\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 354: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 1.6484 - val_accuracy: 0.7030\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9925\n",
      "Epoch 355: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 1.5803 - val_accuracy: 0.7327\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 356: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 1.8266 - val_accuracy: 0.6535\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9975\n",
      "Epoch 357: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 2.1300 - val_accuracy: 0.5743\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 358: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 684ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 1.8042 - val_accuracy: 0.6634\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9875\n",
      "Epoch 359: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 0.0275 - accuracy: 0.9875 - val_loss: 1.5216 - val_accuracy: 0.7525\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9950\n",
      "Epoch 360: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 640ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 1.8547 - val_accuracy: 0.6634\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9875\n",
      "Epoch 361: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 628ms/step - loss: 0.0268 - accuracy: 0.9875 - val_loss: 2.3019 - val_accuracy: 0.5941\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9850\n",
      "Epoch 362: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0461 - accuracy: 0.9850 - val_loss: 1.9056 - val_accuracy: 0.6337\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 363: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 1.6507 - val_accuracy: 0.6931\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9900\n",
      "Epoch 364: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 1.7986 - val_accuracy: 0.6634\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 365: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 1.9256 - val_accuracy: 0.6436\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9850\n",
      "Epoch 366: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 0.0341 - accuracy: 0.9850 - val_loss: 1.7654 - val_accuracy: 0.6931\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9950\n",
      "Epoch 367: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 1.8224 - val_accuracy: 0.6733\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9950\n",
      "Epoch 368: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 2.1978 - val_accuracy: 0.6139\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9825\n",
      "Epoch 369: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.0674 - accuracy: 0.9825 - val_loss: 1.8561 - val_accuracy: 0.6436\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 370: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 650ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 1.6118 - val_accuracy: 0.6931\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9975\n",
      "Epoch 371: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 573ms/step - loss: 0.0213 - accuracy: 0.9975 - val_loss: 1.6686 - val_accuracy: 0.6832\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9900\n",
      "Epoch 372: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 573ms/step - loss: 0.0214 - accuracy: 0.9900 - val_loss: 1.9309 - val_accuracy: 0.6139\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9875\n",
      "Epoch 373: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 736ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 1.7362 - val_accuracy: 0.6733\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9950\n",
      "Epoch 374: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 626ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 1.8768 - val_accuracy: 0.6238\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9950\n",
      "Epoch 375: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.0249 - accuracy: 0.9950 - val_loss: 2.1092 - val_accuracy: 0.6238\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9850\n",
      "Epoch 376: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 647ms/step - loss: 0.0448 - accuracy: 0.9850 - val_loss: 1.9188 - val_accuracy: 0.6337\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9925\n",
      "Epoch 377: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 1.9841 - val_accuracy: 0.6436\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 378: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 1.9186 - val_accuracy: 0.6535\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9950\n",
      "Epoch 379: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 642ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 1.6866 - val_accuracy: 0.6634\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9975\n",
      "Epoch 380: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 0.0206 - accuracy: 0.9975 - val_loss: 1.7045 - val_accuracy: 0.6634\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9975\n",
      "Epoch 381: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 656ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 1.8323 - val_accuracy: 0.6535\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9975\n",
      "Epoch 382: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 1.9371 - val_accuracy: 0.6238\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9975\n",
      "Epoch 383: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 644ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 1.9869 - val_accuracy: 0.6040\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9950\n",
      "Epoch 384: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 1.8693 - val_accuracy: 0.6337\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 385: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7891 - val_accuracy: 0.6535\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9950\n",
      "Epoch 386: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 0.0314 - accuracy: 0.9950 - val_loss: 1.8228 - val_accuracy: 0.6535\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9975\n",
      "Epoch 387: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 1.7648 - val_accuracy: 0.6535\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9950\n",
      "Epoch 388: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.7037 - val_accuracy: 0.6832\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9950\n",
      "Epoch 389: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 1.8750 - val_accuracy: 0.6634\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 390: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9580 - val_accuracy: 0.6535\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 391: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.9550 - val_accuracy: 0.6535\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 392: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 1.9708 - val_accuracy: 0.6634\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9975\n",
      "Epoch 393: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 621ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 2.0132 - val_accuracy: 0.6634\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 394: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.6634\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 395: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.9560 - val_accuracy: 0.6436\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9975\n",
      "Epoch 396: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 697ms/step - loss: 0.0174 - accuracy: 0.9975 - val_loss: 2.0867 - val_accuracy: 0.6238\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 397: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 2s 663ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 2.1067 - val_accuracy: 0.6238\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9975\n",
      "Epoch 398: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 2.1707 - val_accuracy: 0.6238\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 399: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 652ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 1.9922 - val_accuracy: 0.6436\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9925\n",
      "Epoch 400: val_loss did not improve from 1.17356\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 2.0512 - val_accuracy: 0.6436\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=400, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf2c01-a83c-4e2a-aa4b-f49c3726c26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85192b-aee3-4fbf-b208-38c0630545a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293cbc7-e01b-4fad-8cd9-cc00c051796a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86723eec-285e-4ac8-bae8-01f1a2c789ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('911_class_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac9183-a9be-490d-8376-6877b7690788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_audio_class(file_path, model, classes):\n",
    "    # Assuming the extract_features function is defined as above\n",
    "    features = extract_features(file_path)[0]  # Use the original features for prediction\n",
    "    features = np.expand_dims(features, axis=0)  # Reshaping to match model input\n",
    "\n",
    "    # Make the prediction\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return classes[predicted_class[0]]\n",
    "\n",
    "# Usage\n",
    "#model = load_model(\"/Users/irk2w/Desktop/T5/911_model_don't_touch/911_class_test.h5\")  # Load your model\n",
    "audio_file_path = '/Users/irk2w/Downloads/civil1.wav'\n",
    "predicted_class_name = predict_audio_class(audio_file_path, model, classes)\n",
    "print(f\"The model predicts that the audio file is a {predicted_class_name} sound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a4407-8e19-434f-9c8e-ca3dbb17ea3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train.argmax(axis = 1), model.predict(X_train).argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafcf59-bfff-46a7-9653-7024b83966b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.argmax(axis = 1), model.predict(X_test).argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb2d0e-9beb-4530-a808-f91ff76ca6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_train.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af93ba8-55af-4dc4-a326-4fce87184589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3aeec4-3709-472e-8a61-363cf8c218c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
